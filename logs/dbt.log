[0m18:42:05.840251 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:05.955944 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:05.985620 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m18:42:05.990963 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:42:05.991657 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp184204929546"
            where (
                
                    "dim_market__dbt_tmp184204929546".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp184204929546".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m18:42:06.351314 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:06.352919 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:42:06.353927 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp184204929546"
    )
[0m18:42:06.429980 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:06.478800 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m18:42:06.479953 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:42:06.480620 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m18:42:07.065847 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:42:07.072309 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 18:42:04.883340 => 18:42:07.071269
[0m18:42:07.074096 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m18:42:07.080083 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98f20528-4217-46b8-8028-6fcf5b1cde1c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8121b869a0>]}
[0m18:42:07.085665 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.21s]
[0m18:42:07.088917 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m18:42:07.096558 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:07.097871 [debug] [MainThread]: On master: BEGIN
[0m18:42:07.101115 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:42:07.109019 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:07.109953 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:07.429888 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:07.431192 [debug] [MainThread]: On master: COMMIT
[0m18:42:07.432603 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:07.434230 [debug] [MainThread]: On master: COMMIT
[0m18:42:07.484354 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:07.486088 [debug] [MainThread]: On master: Close
[0m18:42:07.488777 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:07.489845 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m18:42:07.491324 [info ] [MainThread]: 
[0m18:42:07.492508 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.28 seconds (4.28s).
[0m18:42:07.494975 [debug] [MainThread]: Command end result
[0m18:42:07.526885 [info ] [MainThread]: 
[0m18:42:07.527888 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:07.528591 [info ] [MainThread]: 
[0m18:42:07.529367 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:42:07.535993 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.294739, "process_user_time": 4.54361, "process_kernel_time": 0.459652, "process_mem_max_rss": "119209984", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:42:07.539058 [debug] [MainThread]: Command `dbt run` succeeded at 18:42:07.538676 after 5.30 seconds
[0m18:42:07.541074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f811089d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81116f7670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8111600d00>]}
[0m18:42:07.541818 [debug] [MainThread]: Flushing usage events
[0m18:42:14.137581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8890fbdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8891a4cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8891a38ac0>]}


============================== 18:42:14.143741 | 81b58059-dcad-4c1b-9500-8b1b50dd9653 ==============================
[0m18:42:14.143741 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:42:14.144522 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_event', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:42:14.543511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '81b58059-dcad-4c1b-9500-8b1b50dd9653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8891a21400>]}
[0m18:42:14.661603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '81b58059-dcad-4c1b-9500-8b1b50dd9653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8891b90130>]}
[0m18:42:14.663163 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:42:14.678831 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:42:14.748460 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:42:14.749115 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:42:14.759009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '81b58059-dcad-4c1b-9500-8b1b50dd9653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88800efe50>]}
[0m18:42:14.773627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '81b58059-dcad-4c1b-9500-8b1b50dd9653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a24076a0>]}
[0m18:42:14.774319 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:42:14.774818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '81b58059-dcad-4c1b-9500-8b1b50dd9653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a2407610>]}
[0m18:42:14.776719 [info ] [MainThread]: 
[0m18:42:14.777774 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:42:14.779226 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:42:14.803544 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:42:14.804077 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:42:14.804520 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:14.808966 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:14.809482 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:15.311053 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m18:42:15.317780 [debug] [ThreadPool]: On list_dev: Close
[0m18:42:15.325962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:42:15.345969 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:15.346674 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:42:15.347114 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:42:15.347821 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:15.348283 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:15.682408 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:15.684213 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:15.685316 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:42:15.747968 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:15.753884 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:42:15.804919 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:42:15.845558 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:15.846495 [debug] [MainThread]: On master: BEGIN
[0m18:42:15.847136 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:42:15.848105 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:15.848794 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:16.240788 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:16.242106 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:16.243185 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:42:16.343230 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:16.347838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '81b58059-dcad-4c1b-9500-8b1b50dd9653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8891cd5d30>]}
[0m18:42:16.349524 [debug] [MainThread]: On master: ROLLBACK
[0m18:42:16.415463 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:16.417675 [debug] [MainThread]: On master: BEGIN
[0m18:42:16.442329 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:16.444035 [debug] [MainThread]: On master: COMMIT
[0m18:42:16.445259 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:16.446217 [debug] [MainThread]: On master: COMMIT
[0m18:42:16.494376 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:16.496006 [debug] [MainThread]: On master: Close
[0m18:42:16.498535 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:42:16.500022 [info ] [MainThread]: 
[0m18:42:16.506680 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m18:42:16.509232 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m18:42:16.512197 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m18:42:16.513435 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m18:42:16.527565 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m18:42:16.529577 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 18:42:16.514339 => 18:42:16.528932
[0m18:42:16.530549 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m18:42:16.637891 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:16.638595 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp184216584165"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m18:42:16.639131 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:42:16.639851 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:16.640387 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:17.019419 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:17.063655 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:17.064396 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m18:42:17.108325 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:17.109211 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:17.110368 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp184216584165'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp184216584165'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp184216584165'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:42:17.266063 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:17.314192 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:17.315355 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:17.460942 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:17.512615 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:17.513759 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:17.631134 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:17.680939 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m18:42:17.687281 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:17.687994 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp184216584165"
            where (
                
                    "dim_event__dbt_tmp184216584165".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m18:42:17.798157 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:17.800122 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:17.801398 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp184216584165"
    )
[0m18:42:17.881650 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:17.927593 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m18:42:17.928520 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:42:17.929392 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m18:42:18.535306 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:42:18.538740 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 18:42:16.531124 => 18:42:18.538094
[0m18:42:18.540173 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m18:42:18.543933 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '81b58059-dcad-4c1b-9500-8b1b50dd9653', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8870149fa0>]}
[0m18:42:18.547503 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.03s]
[0m18:42:18.550742 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m18:42:18.555949 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:18.557389 [debug] [MainThread]: On master: BEGIN
[0m18:42:18.558478 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:42:18.560557 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:18.562051 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:18.891106 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:18.892873 [debug] [MainThread]: On master: COMMIT
[0m18:42:18.893966 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:18.894744 [debug] [MainThread]: On master: COMMIT
[0m18:42:18.943032 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:18.945151 [debug] [MainThread]: On master: Close
[0m18:42:18.948419 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:18.949757 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m18:42:18.951454 [info ] [MainThread]: 
[0m18:42:18.952769 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.17 seconds (4.17s).
[0m18:42:18.968143 [debug] [MainThread]: Command end result
[0m18:42:18.984595 [info ] [MainThread]: 
[0m18:42:18.985741 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:18.986577 [info ] [MainThread]: 
[0m18:42:18.987562 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:42:18.992571 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.957449, "process_user_time": 4.426388, "process_kernel_time": 0.382227, "process_mem_max_rss": "118874112", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:42:18.993512 [debug] [MainThread]: Command `dbt run` succeeded at 18:42:18.993305 after 4.96 seconds
[0m18:42:18.994120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8890fbdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88a24076d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8891dc0c70>]}
[0m18:42:18.994705 [debug] [MainThread]: Flushing usage events
[0m18:42:25.556863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff510f316d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5210e7340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5210e7640>]}


============================== 18:42:25.563179 | 222dd8b5-15df-4fc9-8e33-4de3f8730d01 ==============================
[0m18:42:25.563179 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:42:25.563979 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_participant', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:42:25.984527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '222dd8b5-15df-4fc9-8e33-4de3f8730d01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5210a3ca0>]}
[0m18:42:26.104362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '222dd8b5-15df-4fc9-8e33-4de3f8730d01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff511de92b0>]}
[0m18:42:26.106501 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:42:26.122507 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:42:26.191627 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:42:26.192214 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:42:26.201737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '222dd8b5-15df-4fc9-8e33-4de3f8730d01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5212ffd60>]}
[0m18:42:26.216492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '222dd8b5-15df-4fc9-8e33-4de3f8730d01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff511f15700>]}
[0m18:42:26.217192 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:42:26.217693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '222dd8b5-15df-4fc9-8e33-4de3f8730d01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff511f15610>]}
[0m18:42:26.219649 [info ] [MainThread]: 
[0m18:42:26.220755 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:42:26.222348 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:42:26.247050 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:42:26.247657 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:42:26.248112 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:26.252623 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:26.253149 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:26.736438 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:26.741544 [debug] [ThreadPool]: On list_dev: Close
[0m18:42:26.748040 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:42:26.770539 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:26.771172 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:42:26.771598 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:42:26.772282 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:26.772730 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:27.096466 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:27.098151 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:27.100427 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:42:27.167197 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:27.169726 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:42:27.220450 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:42:27.238444 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:27.239072 [debug] [MainThread]: On master: BEGIN
[0m18:42:27.239501 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:42:27.240173 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:27.240636 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:27.565051 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:27.566405 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:27.567690 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:42:27.665055 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:27.669857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '222dd8b5-15df-4fc9-8e33-4de3f8730d01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5212b85e0>]}
[0m18:42:27.672043 [debug] [MainThread]: On master: ROLLBACK
[0m18:42:27.740425 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:27.741685 [debug] [MainThread]: On master: BEGIN
[0m18:42:27.766239 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:27.767879 [debug] [MainThread]: On master: COMMIT
[0m18:42:27.769018 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:27.769840 [debug] [MainThread]: On master: COMMIT
[0m18:42:27.815755 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:27.817227 [debug] [MainThread]: On master: Close
[0m18:42:27.820002 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:42:27.821025 [info ] [MainThread]: 
[0m18:42:27.828571 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m18:42:27.830175 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m18:42:27.832497 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m18:42:27.833988 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m18:42:27.842255 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m18:42:27.843776 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 18:42:27.834849 => 18:42:27.843379
[0m18:42:27.844350 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m18:42:27.941130 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:27.941883 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp184227888687"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m18:42:27.942462 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:42:27.943209 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:27.943742 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:28.340121 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:28.382686 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:28.383407 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m18:42:28.433291 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:28.434004 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:28.435438 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp184227888687'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp184227888687'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp184227888687'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:42:28.589448 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:28.633007 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:28.634200 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:28.781147 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:28.823742 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:28.824682 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:28.940050 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:28.982851 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m18:42:28.987468 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:28.988067 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp184227888687"
            where (
                
                    "dim_participant__dbt_tmp184227888687".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp184227888687".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m18:42:29.100555 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:29.102873 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:29.104358 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp184227888687"
    )
[0m18:42:29.183617 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:29.218747 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m18:42:29.219636 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:42:29.220242 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m18:42:29.799629 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:42:29.803455 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 18:42:27.844665 => 18:42:29.802647
[0m18:42:29.804975 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m18:42:29.810653 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '222dd8b5-15df-4fc9-8e33-4de3f8730d01', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5212b8f10>]}
[0m18:42:29.814179 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 1.98s]
[0m18:42:29.817623 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m18:42:29.822304 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:29.823559 [debug] [MainThread]: On master: BEGIN
[0m18:42:29.824364 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:42:29.826791 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:29.828004 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:30.154188 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:30.156669 [debug] [MainThread]: On master: COMMIT
[0m18:42:30.158222 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:30.159077 [debug] [MainThread]: On master: COMMIT
[0m18:42:30.207582 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:30.209036 [debug] [MainThread]: On master: Close
[0m18:42:30.212625 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:30.214766 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m18:42:30.216434 [info ] [MainThread]: 
[0m18:42:30.218225 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.00 seconds (4.00s).
[0m18:42:30.220905 [debug] [MainThread]: Command end result
[0m18:42:30.272426 [info ] [MainThread]: 
[0m18:42:30.274089 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:30.275305 [info ] [MainThread]: 
[0m18:42:30.276908 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:42:30.325379 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8718767, "process_user_time": 4.427877, "process_kernel_time": 0.38221, "process_mem_max_rss": "123957248", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:42:30.332374 [debug] [MainThread]: Command `dbt run` succeeded at 18:42:30.330840 after 4.88 seconds
[0m18:42:30.340818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff510f316d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff521217970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff4f0d88850>]}
[0m18:42:30.345053 [debug] [MainThread]: Flushing usage events
[0m18:42:39.489853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a117d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b194d2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b1959370>]}


============================== 18:42:39.496581 | 8a0be904-087c-4c58-a41d-199feac86e79 ==============================
[0m18:42:39.496581 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:42:39.497488 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_event_dtls', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:42:40.117797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a0be904-087c-4c58-a41d-199feac86e79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb590510fa0>]}
[0m18:42:40.236900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8a0be904-087c-4c58-a41d-199feac86e79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b19930a0>]}
[0m18:42:40.239009 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:42:40.254784 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:42:40.325993 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:42:40.326546 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:42:40.335929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a0be904-087c-4c58-a41d-199feac86e79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b1cffe20>]}
[0m18:42:40.351109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a0be904-087c-4c58-a41d-199feac86e79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a1f67760>]}
[0m18:42:40.351816 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:42:40.352310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a0be904-087c-4c58-a41d-199feac86e79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a1f676a0>]}
[0m18:42:40.354239 [info ] [MainThread]: 
[0m18:42:40.355314 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:42:40.356765 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:42:40.381262 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:42:40.381794 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:42:40.382232 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:40.386645 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:40.387186 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:40.867054 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:40.874325 [debug] [ThreadPool]: On list_dev: Close
[0m18:42:40.884913 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:42:40.911658 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:40.912321 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:42:40.912771 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:42:40.913851 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:40.915332 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:41.271026 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:41.272552 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:41.273712 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:42:41.346055 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:41.352179 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:42:41.407236 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:42:41.435229 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:41.435829 [debug] [MainThread]: On master: BEGIN
[0m18:42:41.436252 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:42:41.436914 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:41.437362 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:41.755851 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:41.757399 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:41.758380 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:42:41.854634 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:41.859400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a0be904-087c-4c58-a41d-199feac86e79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a1d87850>]}
[0m18:42:41.860896 [debug] [MainThread]: On master: ROLLBACK
[0m18:42:41.933772 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:41.935391 [debug] [MainThread]: On master: BEGIN
[0m18:42:41.959817 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:41.971796 [debug] [MainThread]: On master: COMMIT
[0m18:42:41.973296 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:41.974214 [debug] [MainThread]: On master: COMMIT
[0m18:42:42.026554 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:42.027849 [debug] [MainThread]: On master: Close
[0m18:42:42.030244 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:42:42.031384 [info ] [MainThread]: 
[0m18:42:42.039109 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m18:42:42.041303 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m18:42:42.043482 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m18:42:42.044778 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m18:42:42.052968 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m18:42:42.054268 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 18:42:42.045480 => 18:42:42.053895
[0m18:42:42.054814 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m18:42:42.152681 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:42.153401 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp184242099527"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m18:42:42.153996 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:42:42.154736 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:42.155270 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:42.526885 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:42.583107 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:42.584002 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m18:42:42.633763 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:42.634706 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:42.636161 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp184242099527'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp184242099527'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp184242099527'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:42:42.848002 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:42.890728 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:42.891842 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:43.038808 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:43.069039 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:43.070012 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:43.191336 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:43.231738 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m18:42:43.236515 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:43.237206 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp184242099527"
            where (
                
                    "dim_event_dtls__dbt_tmp184242099527".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m18:42:43.349696 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:43.352409 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:43.354706 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp184242099527"
    )
[0m18:42:43.432583 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:43.470418 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m18:42:43.471193 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:42:43.471771 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m18:42:44.034271 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:42:44.039253 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 18:42:42.055133 => 18:42:44.038102
[0m18:42:44.041133 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m18:42:44.045397 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a0be904-087c-4c58-a41d-199feac86e79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5801c6bb0>]}
[0m18:42:44.049353 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.00s]
[0m18:42:44.052644 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m18:42:44.058538 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:44.059858 [debug] [MainThread]: On master: BEGIN
[0m18:42:44.060889 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:42:44.062374 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:44.063218 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:44.417839 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:44.419100 [debug] [MainThread]: On master: COMMIT
[0m18:42:44.420167 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:44.420957 [debug] [MainThread]: On master: COMMIT
[0m18:42:44.468452 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:44.469789 [debug] [MainThread]: On master: Close
[0m18:42:44.472448 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:44.473468 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m18:42:44.474589 [info ] [MainThread]: 
[0m18:42:44.475627 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m18:42:44.477405 [debug] [MainThread]: Command end result
[0m18:42:44.492505 [info ] [MainThread]: 
[0m18:42:44.493186 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:44.493641 [info ] [MainThread]: 
[0m18:42:44.494151 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:42:44.497257 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.1310987, "process_user_time": 4.46901, "process_kernel_time": 0.402404, "process_mem_max_rss": "116850688", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:42:44.498096 [debug] [MainThread]: Command `dbt run` succeeded at 18:42:44.497906 after 5.13 seconds
[0m18:42:44.498635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a117d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5905d5b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5905d5e80>]}
[0m18:42:44.499196 [debug] [MainThread]: Flushing usage events
[0m18:42:51.296351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe580e716d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe581819c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5817eb2b0>]}


============================== 18:42:51.302548 | e2ace325-0e6a-4cd4-ab56-2c0982abdade ==============================
[0m18:42:51.302548 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:42:51.303343 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_group', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:42:51.709056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e2ace325-0e6a-4cd4-ab56-2c0982abdade', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5817f5070>]}
[0m18:42:51.832722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e2ace325-0e6a-4cd4-ab56-2c0982abdade', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5717f3220>]}
[0m18:42:51.835033 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:42:51.850750 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:42:51.919849 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:42:51.920466 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:42:51.930112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e2ace325-0e6a-4cd4-ab56-2c0982abdade', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57192feb0>]}
[0m18:42:51.945236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e2ace325-0e6a-4cd4-ab56-2c0982abdade', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe581bf67f0>]}
[0m18:42:51.945925 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:42:51.946428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e2ace325-0e6a-4cd4-ab56-2c0982abdade', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe581bf6730>]}
[0m18:42:51.948293 [info ] [MainThread]: 
[0m18:42:51.949373 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:42:51.950799 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:42:51.975140 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:42:51.975675 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:42:51.976135 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:42:51.980629 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:51.981129 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:52.449781 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:52.455426 [debug] [ThreadPool]: On list_dev: Close
[0m18:42:52.464968 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:42:52.489653 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:52.490621 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:42:52.491288 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:42:52.492338 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:52.493048 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:52.820283 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:52.821669 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:42:52.822627 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:42:52.887429 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:52.894881 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:42:52.947222 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:42:52.974594 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:52.975303 [debug] [MainThread]: On master: BEGIN
[0m18:42:52.975855 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:42:52.976728 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:52.977322 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:53.342994 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:53.344266 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:53.345446 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:42:53.443835 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:53.447738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e2ace325-0e6a-4cd4-ab56-2c0982abdade', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe57184e910>]}
[0m18:42:53.450044 [debug] [MainThread]: On master: ROLLBACK
[0m18:42:53.519198 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:53.520296 [debug] [MainThread]: On master: BEGIN
[0m18:42:53.544750 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:53.545931 [debug] [MainThread]: On master: COMMIT
[0m18:42:53.546970 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:53.547798 [debug] [MainThread]: On master: COMMIT
[0m18:42:53.597992 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:53.599264 [debug] [MainThread]: On master: Close
[0m18:42:53.601925 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:42:53.603031 [info ] [MainThread]: 
[0m18:42:53.609238 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m18:42:53.610821 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m18:42:53.612929 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m18:42:53.614073 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m18:42:53.626702 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m18:42:53.628817 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 18:42:53.614710 => 18:42:53.628160
[0m18:42:53.629816 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m18:42:53.734346 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:53.735010 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp184253682521"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m18:42:53.735568 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:42:53.736291 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:53.736850 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:54.115785 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:54.165716 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:54.166608 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m18:42:54.213599 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:54.214538 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:54.215889 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp184253682521'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp184253682521'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp184253682521'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:42:54.367802 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:54.414101 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:54.415285 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:54.560858 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:54.615576 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:54.616753 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:42:54.736783 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:54.793677 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m18:42:54.799119 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:54.800082 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp184253682521"
            where (
                
                    "dim_group__dbt_tmp184253682521".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp184253682521".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m18:42:54.921983 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:54.923651 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:54.924671 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp184253682521"
    )
[0m18:42:54.998014 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:55.031682 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m18:42:55.032592 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:42:55.033109 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m18:42:55.604767 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:42:55.609674 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 18:42:53.630403 => 18:42:55.608297
[0m18:42:55.611732 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m18:42:55.615887 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e2ace325-0e6a-4cd4-ab56-2c0982abdade', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5719afc40>]}
[0m18:42:55.620333 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.00s]
[0m18:42:55.622717 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m18:42:55.627809 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:55.629254 [debug] [MainThread]: On master: BEGIN
[0m18:42:55.630223 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:42:55.633178 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:42:55.634602 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:42:55.982733 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:55.984054 [debug] [MainThread]: On master: COMMIT
[0m18:42:55.985149 [debug] [MainThread]: Using redshift connection "master"
[0m18:42:55.986138 [debug] [MainThread]: On master: COMMIT
[0m18:42:56.033088 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:42:56.035032 [debug] [MainThread]: On master: Close
[0m18:42:56.038839 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:42:56.040226 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m18:42:56.042091 [info ] [MainThread]: 
[0m18:42:56.043471 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.09 seconds (4.09s).
[0m18:42:56.046180 [debug] [MainThread]: Command end result
[0m18:42:56.072430 [info ] [MainThread]: 
[0m18:42:56.073301 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:42:56.073939 [info ] [MainThread]: 
[0m18:42:56.074632 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:42:56.079310 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.888268, "process_user_time": 4.51347, "process_kernel_time": 0.391197, "process_mem_max_rss": "124088320", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:42:56.080647 [debug] [MainThread]: Command `dbt run` succeeded at 18:42:56.080401 after 4.89 seconds
[0m18:42:56.081349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe580e716d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5719af730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5719afc40>]}
[0m18:42:56.082018 [debug] [MainThread]: Flushing usage events
[0m18:43:02.896117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98c126dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98c1c76c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98c1c6df70>]}


============================== 18:43:02.902273 | c788dc68-875c-411e-9716-7a3c450d856e ==============================
[0m18:43:02.902273 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:43:02.904143 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:43:03.420215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c788dc68-875c-411e-9716-7a3c450d856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98c1c63f10>]}
[0m18:43:03.540237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c788dc68-875c-411e-9716-7a3c450d856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98c1c92f10>]}
[0m18:43:03.541958 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:43:03.557447 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:43:03.622616 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:43:03.623199 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:43:03.632577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c788dc68-875c-411e-9716-7a3c450d856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98c1d7fe80>]}
[0m18:43:03.647252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c788dc68-875c-411e-9716-7a3c450d856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d19507c0>]}
[0m18:43:03.647950 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:43:03.648452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c788dc68-875c-411e-9716-7a3c450d856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d1950700>]}
[0m18:43:03.650421 [info ] [MainThread]: 
[0m18:43:03.651501 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:43:03.653015 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:43:03.678692 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:43:03.679221 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:43:03.679675 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:43:03.684047 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:43:03.684540 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:43:04.202620 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m18:43:04.209640 [debug] [ThreadPool]: On list_dev: Close
[0m18:43:04.216483 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:43:04.245014 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:43:04.246095 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:43:04.246818 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:43:04.247853 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:43:04.248535 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:43:04.597397 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:04.598106 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:43:04.598628 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:43:04.662754 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:04.665654 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:43:04.719448 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:43:04.740113 [debug] [MainThread]: Using redshift connection "master"
[0m18:43:04.740678 [debug] [MainThread]: On master: BEGIN
[0m18:43:04.741097 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:43:04.741732 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:43:04.742181 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:43:05.058551 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:05.060435 [debug] [MainThread]: Using redshift connection "master"
[0m18:43:05.061574 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:43:05.161380 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:05.167207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c788dc68-875c-411e-9716-7a3c450d856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d1715520>]}
[0m18:43:05.169143 [debug] [MainThread]: On master: ROLLBACK
[0m18:43:05.235861 [debug] [MainThread]: Using redshift connection "master"
[0m18:43:05.237508 [debug] [MainThread]: On master: BEGIN
[0m18:43:05.259859 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:05.261271 [debug] [MainThread]: On master: COMMIT
[0m18:43:05.262891 [debug] [MainThread]: Using redshift connection "master"
[0m18:43:05.264078 [debug] [MainThread]: On master: COMMIT
[0m18:43:05.312241 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:05.313726 [debug] [MainThread]: On master: Close
[0m18:43:05.316880 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:43:05.318778 [info ] [MainThread]: 
[0m18:43:05.326007 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m18:43:05.327633 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m18:43:05.329533 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m18:43:05.330713 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m18:43:05.341737 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m18:43:05.343546 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 18:43:05.331418 => 18:43:05.343006
[0m18:43:05.344388 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m18:43:05.447597 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:05.448304 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp184305393085"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m18:43:05.448845 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:43:05.449610 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:43:05.450141 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:43:05.854396 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:05.904190 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:05.905244 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m18:43:05.952801 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:05.954299 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:05.955670 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp184305393085'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp184305393085'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp184305393085'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:43:06.107525 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:06.154924 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:06.156425 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:43:06.310551 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:06.352839 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:06.353864 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:43:06.470401 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:06.518715 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m18:43:06.526091 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:06.526821 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp184305393085"
            where (
                
                    "dim_outcome__dbt_tmp184305393085".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp184305393085".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp184305393085".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m18:43:06.647294 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:06.648899 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:06.650170 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp184305393085"
    )
[0m18:43:06.734395 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:06.785361 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m18:43:06.786534 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:43:06.787382 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m18:43:07.298209 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:43:07.302945 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 18:43:05.344867 => 18:43:07.302053
[0m18:43:07.304463 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m18:43:07.307815 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c788dc68-875c-411e-9716-7a3c450d856e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98a03f0e80>]}
[0m18:43:07.310649 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 1.98s]
[0m18:43:07.312651 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m18:43:07.317473 [debug] [MainThread]: Using redshift connection "master"
[0m18:43:07.318690 [debug] [MainThread]: On master: BEGIN
[0m18:43:07.319502 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:43:07.320964 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:43:07.321800 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:43:07.670539 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:07.671272 [debug] [MainThread]: On master: COMMIT
[0m18:43:07.671879 [debug] [MainThread]: Using redshift connection "master"
[0m18:43:07.672320 [debug] [MainThread]: On master: COMMIT
[0m18:43:07.718652 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:43:07.719373 [debug] [MainThread]: On master: Close
[0m18:43:07.720619 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:43:07.721062 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m18:43:07.721650 [info ] [MainThread]: 
[0m18:43:07.722154 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.07 seconds (4.07s).
[0m18:43:07.723206 [debug] [MainThread]: Command end result
[0m18:43:07.737985 [info ] [MainThread]: 
[0m18:43:07.738635 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:43:07.739091 [info ] [MainThread]: 
[0m18:43:07.739594 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:43:07.742867 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9516554, "process_user_time": 4.504327, "process_kernel_time": 0.393782, "process_mem_max_rss": "119533568", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:43:07.743787 [debug] [MainThread]: Command `dbt run` succeeded at 18:43:07.743585 after 4.95 seconds
[0m18:43:07.744360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98c126dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d1a38700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f98d19503d0>]}
[0m18:43:07.744919 [debug] [MainThread]: Flushing usage events
[0m18:51:50.862199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faee132a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef03e1c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec17022b0>]}


============================== 18:51:50.869440 | 843f8bf5-1f9b-492c-b111-5629f1fd6731 ==============================
[0m18:51:50.869440 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:51:50.870292 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_market', 'send_anonymous_usage_stats': 'True'}
[0m18:51:51.430654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '843f8bf5-1f9b-492c-b111-5629f1fd6731', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef03bc070>]}
[0m18:51:51.554158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '843f8bf5-1f9b-492c-b111-5629f1fd6731', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faed0594220>]}
[0m18:51:51.556461 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:51:51.573740 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:51:51.648326 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:51:51.648932 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:51:51.658923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '843f8bf5-1f9b-492c-b111-5629f1fd6731', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faed06cfeb0>]}
[0m18:51:51.678162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '843f8bf5-1f9b-492c-b111-5629f1fd6731', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef07287f0>]}
[0m18:51:51.678943 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:51:51.679451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '843f8bf5-1f9b-492c-b111-5629f1fd6731', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef0728730>]}
[0m18:51:51.681349 [info ] [MainThread]: 
[0m18:51:51.682450 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:51:51.684270 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:51:51.711983 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:51:51.712648 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:51:51.713214 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:51:51.718357 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:51:51.719290 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:51:52.202416 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:52.204835 [debug] [ThreadPool]: On list_dev: Close
[0m18:51:52.207741 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:51:52.219474 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:51:52.220161 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:51:52.220592 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:51:52.221273 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:51:52.221745 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:51:52.551836 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:52.553661 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:51:52.555064 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:51:52.626391 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:52.634203 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:51:52.685179 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:51:52.719694 [debug] [MainThread]: Using redshift connection "master"
[0m18:51:52.720395 [debug] [MainThread]: On master: BEGIN
[0m18:51:52.720838 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:51:52.721758 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:51:52.722229 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:51:53.053731 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:53.055856 [debug] [MainThread]: Using redshift connection "master"
[0m18:51:53.056877 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:51:53.168273 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:53.172590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '843f8bf5-1f9b-492c-b111-5629f1fd6731', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef05ae0a0>]}
[0m18:51:53.173976 [debug] [MainThread]: On master: ROLLBACK
[0m18:51:53.243621 [debug] [MainThread]: Using redshift connection "master"
[0m18:51:53.244919 [debug] [MainThread]: On master: BEGIN
[0m18:51:53.272770 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:53.275338 [debug] [MainThread]: On master: COMMIT
[0m18:51:53.276940 [debug] [MainThread]: Using redshift connection "master"
[0m18:51:53.277935 [debug] [MainThread]: On master: COMMIT
[0m18:51:53.328989 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:53.330440 [debug] [MainThread]: On master: Close
[0m18:51:53.333597 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:51:53.334967 [info ] [MainThread]: 
[0m18:51:53.342174 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m18:51:53.344335 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m18:51:53.347308 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m18:51:53.348578 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m18:51:53.356139 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m18:51:53.358234 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 18:51:53.349081 => 18:51:53.357706
[0m18:51:53.358932 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m18:51:53.463027 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:53.463762 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp185153408350"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m18:51:53.464309 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:51:53.465053 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:51:53.465581 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:51:53.836814 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:53.883655 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:53.884407 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m18:51:53.933393 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:53.934944 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:53.936590 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp185153408350'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp185153408350'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp185153408350'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:51:54.083250 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:54.126352 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:54.127512 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:51:54.275873 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:54.319669 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:54.320745 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:51:54.436829 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:54.474436 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m18:51:54.479432 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:54.480097 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp185153408350"
            where (
                
                    "dim_market__dbt_tmp185153408350".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp185153408350".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m18:51:54.600732 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:54.603249 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:54.605374 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp185153408350"
    )
[0m18:51:54.684870 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:54.732679 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m18:51:54.733514 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m18:51:54.734036 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m18:51:55.264580 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:51:55.269836 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 18:51:53.359308 => 18:51:55.269083
[0m18:51:55.271110 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m18:51:55.273934 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '843f8bf5-1f9b-492c-b111-5629f1fd6731', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faee1f09790>]}
[0m18:51:55.276782 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 1.93s]
[0m18:51:55.279874 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m18:51:55.284466 [debug] [MainThread]: Using redshift connection "master"
[0m18:51:55.285644 [debug] [MainThread]: On master: BEGIN
[0m18:51:55.286526 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:51:55.287779 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:51:55.288640 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:51:55.608797 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:55.611755 [debug] [MainThread]: On master: COMMIT
[0m18:51:55.614183 [debug] [MainThread]: Using redshift connection "master"
[0m18:51:55.615986 [debug] [MainThread]: On master: COMMIT
[0m18:51:55.661581 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:51:55.664233 [debug] [MainThread]: On master: Close
[0m18:51:55.669264 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:51:55.671063 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m18:51:55.673450 [info ] [MainThread]: 
[0m18:51:55.675507 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.99 seconds (3.99s).
[0m18:51:55.679327 [debug] [MainThread]: Command end result
[0m18:51:55.709510 [info ] [MainThread]: 
[0m18:51:55.710502 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:51:55.711191 [info ] [MainThread]: 
[0m18:51:55.711974 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:51:55.716289 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9718924, "process_user_time": 4.569534, "process_kernel_time": 0.41791, "process_mem_max_rss": "115867648", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:51:55.717390 [debug] [MainThread]: Command `dbt run` succeeded at 18:51:55.717147 after 4.97 seconds
[0m18:51:55.718096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faee132a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef0728760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faef0728400>]}
[0m18:51:55.718801 [debug] [MainThread]: Flushing usage events
[0m18:52:02.239385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb1125d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb2115ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb20ff5b0>]}


============================== 18:52:02.245634 | facf35f3-e237-42a5-95fd-02178fe45946 ==============================
[0m18:52:02.245634 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:52:02.246431 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_event', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:52:02.655695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'facf35f3-e237-42a5-95fd-02178fe45946', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb20eb700>]}
[0m18:52:02.774712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'facf35f3-e237-42a5-95fd-02178fe45946', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb20f4ac0>]}
[0m18:52:02.776032 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:52:02.791479 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:52:02.857819 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:52:02.858396 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:52:02.867795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'facf35f3-e237-42a5-95fd-02178fe45946', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafc169fdf0>]}
[0m18:52:02.882610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'facf35f3-e237-42a5-95fd-02178fe45946', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb263f790>]}
[0m18:52:02.883293 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:52:02.883807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'facf35f3-e237-42a5-95fd-02178fe45946', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb263f6a0>]}
[0m18:52:02.885673 [info ] [MainThread]: 
[0m18:52:02.886731 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:52:02.888166 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:52:02.912627 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:52:02.913139 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:52:02.913591 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:52:02.918071 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:02.918567 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:03.405574 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:03.414473 [debug] [ThreadPool]: On list_dev: Close
[0m18:52:03.422770 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:52:03.444396 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:03.445261 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:52:03.445900 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:52:03.446838 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:03.447428 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:03.771539 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:03.777093 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:03.779361 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:52:03.845386 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:03.855941 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:52:03.905120 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:52:03.949329 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:03.950211 [debug] [MainThread]: On master: BEGIN
[0m18:52:03.950847 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:52:03.951851 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:03.952538 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:04.281934 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:04.284240 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:04.285867 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:52:04.386270 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:04.393099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'facf35f3-e237-42a5-95fd-02178fe45946', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafa03e0f40>]}
[0m18:52:04.395326 [debug] [MainThread]: On master: ROLLBACK
[0m18:52:04.463729 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:04.466136 [debug] [MainThread]: On master: BEGIN
[0m18:52:04.488924 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:04.490043 [debug] [MainThread]: On master: COMMIT
[0m18:52:04.491073 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:04.491878 [debug] [MainThread]: On master: COMMIT
[0m18:52:04.536487 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:04.537335 [debug] [MainThread]: On master: Close
[0m18:52:04.539439 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:52:04.540321 [info ] [MainThread]: 
[0m18:52:04.545409 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m18:52:04.546682 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m18:52:04.548453 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m18:52:04.549357 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m18:52:04.558182 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m18:52:04.559549 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 18:52:04.549879 => 18:52:04.559105
[0m18:52:04.560252 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m18:52:04.658913 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:04.659635 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp185204606791"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m18:52:04.660188 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:52:04.660913 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:04.661425 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:05.054038 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:05.107825 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:05.108778 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m18:52:05.156758 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:05.157919 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:05.159313 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp185204606791'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp185204606791'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp185204606791'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:52:05.307628 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:05.361968 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:05.363211 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:05.513993 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:05.555284 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:05.556265 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:05.672349 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:05.719447 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m18:52:05.724533 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:05.725172 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp185204606791"
            where (
                
                    "dim_event__dbt_tmp185204606791".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m18:52:05.842366 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:05.845053 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:05.847257 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp185204606791"
    )
[0m18:52:05.928215 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:05.983125 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m18:52:05.984029 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m18:52:05.984702 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m18:52:06.631841 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:52:06.638400 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 18:52:04.560677 => 18:52:06.637378
[0m18:52:06.640258 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m18:52:06.644298 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'facf35f3-e237-42a5-95fd-02178fe45946', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb27f2cd0>]}
[0m18:52:06.647608 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.10s]
[0m18:52:06.649758 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m18:52:06.654482 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:06.655768 [debug] [MainThread]: On master: BEGIN
[0m18:52:06.656689 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:52:06.657968 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:06.658841 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:06.985185 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:06.987341 [debug] [MainThread]: On master: COMMIT
[0m18:52:06.989380 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:06.991011 [debug] [MainThread]: On master: COMMIT
[0m18:52:07.038023 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:07.040671 [debug] [MainThread]: On master: Close
[0m18:52:07.045592 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:52:07.047443 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m18:52:07.049814 [info ] [MainThread]: 
[0m18:52:07.051511 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.16 seconds (4.16s).
[0m18:52:07.054335 [debug] [MainThread]: Command end result
[0m18:52:07.084100 [info ] [MainThread]: 
[0m18:52:07.085042 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:52:07.085691 [info ] [MainThread]: 
[0m18:52:07.086330 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:52:07.090494 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.95715, "process_user_time": 4.510728, "process_kernel_time": 0.3967, "process_mem_max_rss": "124817408", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:52:07.091581 [debug] [MainThread]: Command `dbt run` succeeded at 18:52:07.091335 after 4.96 seconds
[0m18:52:07.092294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb1125d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb27f2ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fafb263f0a0>]}
[0m18:52:07.093011 [debug] [MainThread]: Flushing usage events
[0m18:52:13.497121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa169691bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16a7c5ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16a7ae5b0>]}


============================== 18:52:13.503339 | faeb68fc-a396-4779-851b-4f5a9143047b ==============================
[0m18:52:13.503339 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:52:13.504142 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_participant', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:52:13.920397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'faeb68fc-a396-4779-851b-4f5a9143047b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16a79c700>]}
[0m18:52:14.041063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'faeb68fc-a396-4779-851b-4f5a9143047b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16a7a4ac0>]}
[0m18:52:14.042735 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:52:14.058400 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:52:14.127998 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:52:14.128572 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:52:14.138137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'faeb68fc-a396-4779-851b-4f5a9143047b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1796c7df0>]}
[0m18:52:14.152544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'faeb68fc-a396-4779-851b-4f5a9143047b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16ac0f790>]}
[0m18:52:14.153194 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:52:14.153689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'faeb68fc-a396-4779-851b-4f5a9143047b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16ac0f6a0>]}
[0m18:52:14.155570 [info ] [MainThread]: 
[0m18:52:14.156606 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:52:14.158038 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:52:14.182812 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:52:14.183324 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:52:14.183782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:52:14.188301 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:14.188815 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:14.681691 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:14.688103 [debug] [ThreadPool]: On list_dev: Close
[0m18:52:14.693864 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:52:14.711110 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:14.711797 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:52:14.712349 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:52:14.713163 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:14.713750 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:15.048166 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:15.050152 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:15.051463 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:52:15.117622 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:15.128116 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:52:15.182368 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:52:15.224924 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:15.225843 [debug] [MainThread]: On master: BEGIN
[0m18:52:15.226506 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:52:15.227502 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:15.228210 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:15.571009 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:15.572393 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:15.573405 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:52:15.668270 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:15.677089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'faeb68fc-a396-4779-851b-4f5a9143047b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1794f8f40>]}
[0m18:52:15.679960 [debug] [MainThread]: On master: ROLLBACK
[0m18:52:15.745355 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:15.746361 [debug] [MainThread]: On master: BEGIN
[0m18:52:15.768073 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:15.768907 [debug] [MainThread]: On master: COMMIT
[0m18:52:15.769852 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:15.770625 [debug] [MainThread]: On master: COMMIT
[0m18:52:15.820716 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:15.822992 [debug] [MainThread]: On master: Close
[0m18:52:15.827638 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:52:15.829103 [info ] [MainThread]: 
[0m18:52:15.837300 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m18:52:15.839023 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m18:52:15.840975 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m18:52:15.842273 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m18:52:15.853812 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m18:52:15.855456 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 18:52:15.843233 => 18:52:15.854892
[0m18:52:15.856271 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m18:52:15.958695 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:15.959342 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp185215906323"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m18:52:15.959875 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:52:15.960588 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:15.961107 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:16.333390 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:16.389247 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:16.390086 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m18:52:16.434466 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:16.435453 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:16.436851 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp185215906323'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp185215906323'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp185215906323'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:52:16.583660 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:16.638555 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:16.639644 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:16.782323 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:16.813262 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:16.814072 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:16.932358 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:16.973800 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m18:52:16.978921 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:16.979500 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp185215906323"
            where (
                
                    "dim_participant__dbt_tmp185215906323".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp185215906323".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m18:52:17.092987 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:17.095370 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:17.096980 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp185215906323"
    )
[0m18:52:17.175298 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:17.229560 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m18:52:17.230677 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m18:52:17.231365 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m18:52:17.822707 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:52:17.824915 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 18:52:15.856757 => 18:52:17.824411
[0m18:52:17.825751 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m18:52:17.827524 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faeb68fc-a396-4779-851b-4f5a9143047b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16adc06a0>]}
[0m18:52:17.829495 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 1.99s]
[0m18:52:17.830634 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m18:52:17.832844 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:17.833415 [debug] [MainThread]: On master: BEGIN
[0m18:52:17.833962 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:52:17.834870 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:17.835499 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:18.153353 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:18.155571 [debug] [MainThread]: On master: COMMIT
[0m18:52:18.157356 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:18.158679 [debug] [MainThread]: On master: COMMIT
[0m18:52:18.207330 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:18.209682 [debug] [MainThread]: On master: Close
[0m18:52:18.213692 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:52:18.216787 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m18:52:18.218643 [info ] [MainThread]: 
[0m18:52:18.220152 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.06 seconds (4.06s).
[0m18:52:18.223277 [debug] [MainThread]: Command end result
[0m18:52:18.251659 [info ] [MainThread]: 
[0m18:52:18.252670 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:52:18.253356 [info ] [MainThread]: 
[0m18:52:18.254115 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:52:18.258413 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8673663, "process_user_time": 4.479849, "process_kernel_time": 0.385262, "process_mem_max_rss": "120004608", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:52:18.259457 [debug] [MainThread]: Command `dbt run` succeeded at 18:52:18.259212 after 4.87 seconds
[0m18:52:18.260159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa169691bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16aae8b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa16ac0f0a0>]}
[0m18:52:18.260864 [debug] [MainThread]: Flushing usage events
[0m18:52:27.148179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd40cd5670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd408cfd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd20181580>]}


============================== 18:52:27.159877 | 227d3192-1dac-4f15-afcd-95cdfbd610fe ==============================
[0m18:52:27.159877 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:52:27.161355 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_event_dtls', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m18:52:27.917850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '227d3192-1dac-4f15-afcd-95cdfbd610fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd2017c550>]}
[0m18:52:28.095456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '227d3192-1dac-4f15-afcd-95cdfbd610fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd202caf40>]}
[0m18:52:28.098346 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:52:28.116924 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:52:28.189538 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:52:28.190158 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:52:28.199849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '227d3192-1dac-4f15-afcd-95cdfbd610fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd524b7dc0>]}
[0m18:52:28.216784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '227d3192-1dac-4f15-afcd-95cdfbd610fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd523cd760>]}
[0m18:52:28.217502 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:52:28.218120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '227d3192-1dac-4f15-afcd-95cdfbd610fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd523cd670>]}
[0m18:52:28.220246 [info ] [MainThread]: 
[0m18:52:28.221435 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:52:28.231613 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:52:28.257669 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:52:28.258289 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:52:28.258773 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:52:28.263463 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:28.264022 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:28.774311 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m18:52:28.780693 [debug] [ThreadPool]: On list_dev: Close
[0m18:52:28.788169 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:52:28.812716 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:28.813648 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:52:28.814315 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:52:28.815329 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:28.816194 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:29.144440 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:29.145862 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:29.146767 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:52:29.210740 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:29.217080 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:52:29.270014 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:52:29.308068 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:29.309069 [debug] [MainThread]: On master: BEGIN
[0m18:52:29.309730 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:52:29.310778 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:29.311476 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:29.660010 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:29.661951 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:29.663246 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:52:29.770773 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:29.778534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '227d3192-1dac-4f15-afcd-95cdfbd610fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd203ac3d0>]}
[0m18:52:29.780765 [debug] [MainThread]: On master: ROLLBACK
[0m18:52:29.844537 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:29.846439 [debug] [MainThread]: On master: BEGIN
[0m18:52:29.870392 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:29.872040 [debug] [MainThread]: On master: COMMIT
[0m18:52:29.873596 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:29.874861 [debug] [MainThread]: On master: COMMIT
[0m18:52:29.922386 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:29.924205 [debug] [MainThread]: On master: Close
[0m18:52:29.928432 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:52:29.929904 [info ] [MainThread]: 
[0m18:52:29.938451 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m18:52:29.940861 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m18:52:29.944206 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m18:52:29.945528 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m18:52:29.960147 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m18:52:29.962355 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 18:52:29.946298 => 18:52:29.961660
[0m18:52:29.963385 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m18:52:30.067210 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:30.067907 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp185230014960"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m18:52:30.068460 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:52:30.069175 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:30.069731 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:30.454832 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:30.512719 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:30.513588 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m18:52:30.560283 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:30.561241 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:30.562625 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp185230014960'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp185230014960'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp185230014960'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:52:30.712082 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:30.759588 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:30.760976 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:30.909664 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:30.965285 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:30.966679 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:31.085754 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:31.127665 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m18:52:31.131983 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:31.132574 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp185230014960"
            where (
                
                    "dim_event_dtls__dbt_tmp185230014960".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m18:52:31.253563 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:31.254942 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:31.255964 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp185230014960"
    )
[0m18:52:31.339317 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:31.391144 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m18:52:31.392108 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m18:52:31.392770 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m18:52:31.925735 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:52:31.930404 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 18:52:29.963920 => 18:52:31.929469
[0m18:52:31.932258 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m18:52:31.936725 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '227d3192-1dac-4f15-afcd-95cdfbd610fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd4198c700>]}
[0m18:52:31.939085 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 1.99s]
[0m18:52:31.940860 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m18:52:31.945999 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:31.947355 [debug] [MainThread]: On master: BEGIN
[0m18:52:31.948331 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:52:31.949962 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:31.951031 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:32.298750 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:32.300906 [debug] [MainThread]: On master: COMMIT
[0m18:52:32.304446 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:32.305530 [debug] [MainThread]: On master: COMMIT
[0m18:52:32.356190 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:32.358157 [debug] [MainThread]: On master: Close
[0m18:52:32.362119 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:52:32.363406 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m18:52:32.365088 [info ] [MainThread]: 
[0m18:52:32.367110 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.14 seconds (4.14s).
[0m18:52:32.370908 [debug] [MainThread]: Command end result
[0m18:52:32.399173 [info ] [MainThread]: 
[0m18:52:32.400202 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:52:32.400938 [info ] [MainThread]: 
[0m18:52:32.401707 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:52:32.406718 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.5397735, "process_user_time": 4.775936, "process_kernel_time": 0.459984, "process_mem_max_rss": "101437440", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:52:32.408120 [debug] [MainThread]: Command `dbt run` succeeded at 18:52:32.407821 after 5.54 seconds
[0m18:52:32.408972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd40cd5670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd523cd610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd4194f910>]}
[0m18:52:32.409713 [debug] [MainThread]: Flushing usage events
[0m18:52:38.773280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c8d6dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba38cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba379be0>]}


============================== 18:52:38.779451 | 34ffbca9-42ac-4e59-8fc3-e5da719b9550 ==============================
[0m18:52:38.779451 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:52:38.780251 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_group', 'send_anonymous_usage_stats': 'True'}
[0m18:52:39.186180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '34ffbca9-42ac-4e59-8fc3-e5da719b9550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba363370>]}
[0m18:52:39.305483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '34ffbca9-42ac-4e59-8fc3-e5da719b9550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c994af10>]}
[0m18:52:39.307047 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:52:39.322712 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:52:39.389406 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:52:39.389988 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:52:39.399425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '34ffbca9-42ac-4e59-8fc3-e5da719b9550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c99bfe50>]}
[0m18:52:39.414306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '34ffbca9-42ac-4e59-8fc3-e5da719b9550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba817790>]}
[0m18:52:39.415000 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:52:39.415482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '34ffbca9-42ac-4e59-8fc3-e5da719b9550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba8176d0>]}
[0m18:52:39.417371 [info ] [MainThread]: 
[0m18:52:39.418427 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:52:39.419868 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:52:39.444323 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:52:39.444855 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:52:39.445321 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:52:39.449731 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:39.450235 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:39.938622 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:39.948482 [debug] [ThreadPool]: On list_dev: Close
[0m18:52:39.957125 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:52:39.979871 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:39.980773 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:52:39.981420 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:52:39.982408 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:39.983133 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:40.317691 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:40.318599 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:40.319375 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:52:40.381574 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:40.387198 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:52:40.441855 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:52:40.483743 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:40.484533 [debug] [MainThread]: On master: BEGIN
[0m18:52:40.485174 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:52:40.486151 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:40.486729 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:40.819456 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:40.821592 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:40.823109 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:52:40.925151 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:40.932566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '34ffbca9-42ac-4e59-8fc3-e5da719b9550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c996cf70>]}
[0m18:52:40.935234 [debug] [MainThread]: On master: ROLLBACK
[0m18:52:41.003499 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:41.005260 [debug] [MainThread]: On master: BEGIN
[0m18:52:41.029057 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:41.030653 [debug] [MainThread]: On master: COMMIT
[0m18:52:41.032481 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:41.033840 [debug] [MainThread]: On master: COMMIT
[0m18:52:41.081325 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:41.083837 [debug] [MainThread]: On master: Close
[0m18:52:41.089463 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:52:41.091126 [info ] [MainThread]: 
[0m18:52:41.099128 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m18:52:41.101247 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m18:52:41.104220 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m18:52:41.105471 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m18:52:41.117286 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m18:52:41.119632 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 18:52:41.106218 => 18:52:41.119164
[0m18:52:41.120233 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m18:52:41.222370 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:41.223046 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp185241170738"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m18:52:41.223590 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:52:41.224319 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:41.224845 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:41.610381 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:41.667414 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:41.668282 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m18:52:41.713033 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:41.713958 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:41.715223 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp185241170738'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp185241170738'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp185241170738'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:52:41.870252 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:41.922889 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:41.924042 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:42.072020 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:42.132241 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:42.133306 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:42.250510 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:42.287921 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m18:52:42.293261 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:42.293824 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp185241170738"
            where (
                
                    "dim_group__dbt_tmp185241170738".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp185241170738".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m18:52:42.404257 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:42.405199 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:42.406001 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp185241170738"
    )
[0m18:52:42.482554 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:42.533275 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m18:52:42.534194 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m18:52:42.534855 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m18:52:43.087797 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:52:43.093444 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 18:52:41.120585 => 18:52:43.092351
[0m18:52:43.095803 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m18:52:43.100058 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '34ffbca9-42ac-4e59-8fc3-e5da719b9550', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba8cc610>]}
[0m18:52:43.104057 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.00s]
[0m18:52:43.106820 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m18:52:43.111658 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:43.112697 [debug] [MainThread]: On master: BEGIN
[0m18:52:43.113468 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:52:43.114901 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:43.116296 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:43.453956 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:43.455193 [debug] [MainThread]: On master: COMMIT
[0m18:52:43.456442 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:43.457444 [debug] [MainThread]: On master: COMMIT
[0m18:52:43.501415 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:43.503244 [debug] [MainThread]: On master: Close
[0m18:52:43.506421 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:52:43.507493 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m18:52:43.508948 [info ] [MainThread]: 
[0m18:52:43.510100 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.09 seconds (4.09s).
[0m18:52:43.512301 [debug] [MainThread]: Command end result
[0m18:52:43.539495 [info ] [MainThread]: 
[0m18:52:43.540387 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:52:43.541055 [info ] [MainThread]: 
[0m18:52:43.541787 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:52:43.546636 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.879418, "process_user_time": 4.46524, "process_kernel_time": 0.392692, "process_mem_max_rss": "121131008", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:52:43.547791 [debug] [MainThread]: Command `dbt run` succeeded at 18:52:43.547543 after 4.88 seconds
[0m18:52:43.548479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c8d6dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba817160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3ba9f8940>]}
[0m18:52:43.549192 [debug] [MainThread]: Flushing usage events
[0m18:52:50.205500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec396e5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec189aec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec189a5f70>]}


============================== 18:52:50.212283 | 9f5a6867-2bcf-4b24-8e9a-3543a66605df ==============================
[0m18:52:50.212283 [info ] [MainThread]: Running with dbt=1.7.0
[0m18:52:50.213140 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_outcome', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:52:50.672990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9f5a6867-2bcf-4b24-8e9a-3543a66605df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec48f23f10>]}
[0m18:52:50.797740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9f5a6867-2bcf-4b24-8e9a-3543a66605df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec189caf10>]}
[0m18:52:50.799370 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m18:52:50.817091 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m18:52:50.892422 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:52:50.893028 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:52:50.903739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f5a6867-2bcf-4b24-8e9a-3543a66605df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec4903fe80>]}
[0m18:52:50.922374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f5a6867-2bcf-4b24-8e9a-3543a66605df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec18c407c0>]}
[0m18:52:50.923222 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m18:52:50.924005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f5a6867-2bcf-4b24-8e9a-3543a66605df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec18c40700>]}
[0m18:52:50.926300 [info ] [MainThread]: 
[0m18:52:50.927575 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m18:52:50.929215 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m18:52:50.970773 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m18:52:50.971465 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m18:52:50.971964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:52:50.976898 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:50.977527 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:51.484350 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m18:52:51.487576 [debug] [ThreadPool]: On list_dev: Close
[0m18:52:51.491337 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m18:52:51.507095 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:51.507829 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m18:52:51.508330 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:52:51.509072 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:51.509591 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:51.842066 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:51.844824 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m18:52:51.846771 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m18:52:51.912850 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:51.920481 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m18:52:51.978318 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m18:52:52.015037 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:52.015884 [debug] [MainThread]: On master: BEGIN
[0m18:52:52.016398 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:52:52.017310 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:52.018202 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:52.331555 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:52.333064 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:52.334208 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m18:52:52.432703 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:52.437745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f5a6867-2bcf-4b24-8e9a-3543a66605df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec283ad520>]}
[0m18:52:52.439616 [debug] [MainThread]: On master: ROLLBACK
[0m18:52:52.509348 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:52.511426 [debug] [MainThread]: On master: BEGIN
[0m18:52:52.536951 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:52.538764 [debug] [MainThread]: On master: COMMIT
[0m18:52:52.540793 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:52.542493 [debug] [MainThread]: On master: COMMIT
[0m18:52:52.589057 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:52.590377 [debug] [MainThread]: On master: Close
[0m18:52:52.592901 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:52:52.593958 [info ] [MainThread]: 
[0m18:52:52.601609 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m18:52:52.603509 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m18:52:52.606452 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m18:52:52.608236 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m18:52:52.620214 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m18:52:52.621664 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 18:52:52.609269 => 18:52:52.621221
[0m18:52:52.622259 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m18:52:52.722500 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:52.723244 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp185252669425"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m18:52:52.723825 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m18:52:52.724692 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:52.725227 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:53.109071 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:53.160384 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:53.161402 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m18:52:53.208744 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:53.209808 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:53.211180 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp185252669425'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp185252669425'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp185252669425'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m18:52:53.364949 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:53.412298 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:53.413564 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:53.559883 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:53.602264 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:53.603247 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m18:52:53.718454 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:53.759951 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m18:52:53.766585 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:53.767254 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp185252669425"
            where (
                
                    "dim_outcome__dbt_tmp185252669425".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp185252669425".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp185252669425".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m18:52:53.885195 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:53.887218 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:53.888311 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp185252669425"
    )
[0m18:52:53.972376 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:54.022357 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m18:52:54.023263 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m18:52:54.023810 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m18:52:54.659978 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m18:52:54.664995 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 18:52:52.622592 => 18:52:54.664243
[0m18:52:54.666182 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m18:52:54.669393 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f5a6867-2bcf-4b24-8e9a-3543a66605df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec18dc11f0>]}
[0m18:52:54.672560 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.06s]
[0m18:52:54.675351 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m18:52:54.680373 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:54.681577 [debug] [MainThread]: On master: BEGIN
[0m18:52:54.682431 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:52:54.685106 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m18:52:54.686651 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m18:52:55.080137 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:55.082022 [debug] [MainThread]: On master: COMMIT
[0m18:52:55.083785 [debug] [MainThread]: Using redshift connection "master"
[0m18:52:55.084811 [debug] [MainThread]: On master: COMMIT
[0m18:52:55.131231 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m18:52:55.132498 [debug] [MainThread]: On master: Close
[0m18:52:55.134857 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:52:55.135646 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m18:52:55.136863 [info ] [MainThread]: 
[0m18:52:55.137831 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.21 seconds (4.21s).
[0m18:52:55.139747 [debug] [MainThread]: Command end result
[0m18:52:55.191009 [info ] [MainThread]: 
[0m18:52:55.191734 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:52:55.192216 [info ] [MainThread]: 
[0m18:52:55.192799 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:52:55.204951 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.134583, "process_user_time": 4.615949, "process_kernel_time": 0.431441, "process_mem_max_rss": "108048384", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m18:52:55.211974 [debug] [MainThread]: Command `dbt run` succeeded at 18:52:55.211616 after 5.14 seconds
[0m18:52:55.212947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec396e5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec18c40730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec18c407f0>]}
[0m18:52:55.213818 [debug] [MainThread]: Flushing usage events
[0m19:01:42.825384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd610975670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd621855d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd62183ee20>]}


============================== 19:01:42.831921 | a1bb2fa3-acd9-4bb7-8177-b42e84d31a46 ==============================
[0m19:01:42.831921 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:01:42.832736 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_market', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:01:43.374480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a1bb2fa3-acd9-4bb7-8177-b42e84d31a46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61190b7f0>]}
[0m19:01:43.494376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a1bb2fa3-acd9-4bb7-8177-b42e84d31a46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd611b125e0>]}
[0m19:01:43.496412 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:01:43.512322 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:01:43.584509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:01:43.585066 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:01:43.594596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a1bb2fa3-acd9-4bb7-8177-b42e84d31a46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd621cdfe20>]}
[0m19:01:43.610814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a1bb2fa3-acd9-4bb7-8177-b42e84d31a46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd621bf77c0>]}
[0m19:01:43.611516 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:01:43.612034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a1bb2fa3-acd9-4bb7-8177-b42e84d31a46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd621bf76d0>]}
[0m19:01:43.613892 [info ] [MainThread]: 
[0m19:01:43.614925 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:01:43.616371 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:01:43.640636 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:01:43.641159 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:01:43.641627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:43.646128 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:01:43.646626 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:01:44.124128 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:44.133889 [debug] [ThreadPool]: On list_dev: Close
[0m19:01:44.141991 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:01:44.164554 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:01:44.165460 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:01:44.166112 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:01:44.167136 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:01:44.167878 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:01:44.508197 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:44.510880 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:01:44.512145 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:01:44.577482 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:44.583816 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:01:44.638474 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:01:44.676363 [debug] [MainThread]: Using redshift connection "master"
[0m19:01:44.677330 [debug] [MainThread]: On master: BEGIN
[0m19:01:44.677994 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:01:44.679031 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:01:44.679755 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:01:45.009262 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:45.011010 [debug] [MainThread]: Using redshift connection "master"
[0m19:01:45.012142 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:01:45.110865 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:45.117707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a1bb2fa3-acd9-4bb7-8177-b42e84d31a46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd621acee50>]}
[0m19:01:45.119583 [debug] [MainThread]: On master: ROLLBACK
[0m19:01:45.183709 [debug] [MainThread]: Using redshift connection "master"
[0m19:01:45.184815 [debug] [MainThread]: On master: BEGIN
[0m19:01:45.210747 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:45.212248 [debug] [MainThread]: On master: COMMIT
[0m19:01:45.213491 [debug] [MainThread]: Using redshift connection "master"
[0m19:01:45.214732 [debug] [MainThread]: On master: COMMIT
[0m19:01:45.258211 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:45.259832 [debug] [MainThread]: On master: Close
[0m19:01:45.262778 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:01:45.263753 [info ] [MainThread]: 
[0m19:01:45.270042 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m19:01:45.271628 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m19:01:45.274388 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m19:01:45.275925 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m19:01:45.287257 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m19:01:45.288609 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 19:01:45.277459 => 19:01:45.288193
[0m19:01:45.289233 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m19:01:45.392828 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:45.393573 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp190145338290"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m19:01:45.394130 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:01:45.394851 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:01:45.395378 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:01:45.985394 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:01:46.034195 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:46.035058 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m19:01:46.085145 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:46.085955 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:46.086698 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp190145338290'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp190145338290'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp190145338290'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:01:46.234771 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:46.281843 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:46.283003 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:01:46.430355 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:46.486673 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:46.487849 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:01:46.605080 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:46.663644 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m19:01:46.670131 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:46.670798 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp190145338290"
            where (
                
                    "dim_market__dbt_tmp190145338290".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp190145338290".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m19:01:50.629072 [debug] [Thread-1  ]: SQL status: SUCCESS in 4.0 seconds
[0m19:01:50.630691 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:50.631783 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp190145338290"
    )
[0m19:01:51.158310 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:01:51.192858 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:01:51.193605 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:01:51.194112 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:01:51.756287 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:01:51.761605 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 19:01:45.289610 => 19:01:51.760476
[0m19:01:51.763132 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m19:01:51.767601 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1bb2fa3-acd9-4bb7-8177-b42e84d31a46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd611c5e1f0>]}
[0m19:01:51.770797 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 6.49s]
[0m19:01:51.774144 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m19:01:51.781348 [debug] [MainThread]: Using redshift connection "master"
[0m19:01:51.783124 [debug] [MainThread]: On master: BEGIN
[0m19:01:51.784342 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:01:51.787659 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:01:51.789114 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:01:52.142369 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:52.144416 [debug] [MainThread]: On master: COMMIT
[0m19:01:52.146782 [debug] [MainThread]: Using redshift connection "master"
[0m19:01:52.147796 [debug] [MainThread]: On master: COMMIT
[0m19:01:52.197323 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:01:52.198264 [debug] [MainThread]: On master: Close
[0m19:01:52.199994 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:01:52.200663 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m19:01:52.201544 [info ] [MainThread]: 
[0m19:01:52.202311 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.59 seconds (8.59s).
[0m19:01:52.203774 [debug] [MainThread]: Command end result
[0m19:01:52.226595 [info ] [MainThread]: 
[0m19:01:52.227295 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:01:52.227753 [info ] [MainThread]: 
[0m19:01:52.228273 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:01:52.232026 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.51477, "process_user_time": 4.496163, "process_kernel_time": 0.408889, "process_mem_max_rss": "118136832", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:01:52.233131 [debug] [MainThread]: Command `dbt run` succeeded at 19:01:52.232923 after 9.52 seconds
[0m19:01:52.233758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd610975670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd621a471f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd621cad460>]}
[0m19:01:52.234344 [debug] [MainThread]: Flushing usage events
[0m19:01:59.041045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadf8ba9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea46cca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea4555b0>]}


============================== 19:01:59.047067 | 1ead7aa1-e3e5-4290-b08c-85d023600fbe ==============================
[0m19:01:59.047067 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:01:59.047854 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_event', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:01:59.455529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1ead7aa1-e3e5-4290-b08c-85d023600fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea443700>]}
[0m19:01:59.575437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1ead7aa1-e3e5-4290-b08c-85d023600fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea44cac0>]}
[0m19:01:59.576999 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:01:59.593615 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:01:59.662199 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:01:59.662808 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:01:59.672586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1ead7aa1-e3e5-4290-b08c-85d023600fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadf9607df0>]}
[0m19:01:59.688143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1ead7aa1-e3e5-4290-b08c-85d023600fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea7b7790>]}
[0m19:01:59.688837 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:01:59.689359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ead7aa1-e3e5-4290-b08c-85d023600fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea7b76a0>]}
[0m19:01:59.691297 [info ] [MainThread]: 
[0m19:01:59.692338 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:01:59.693799 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:01:59.718219 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:01:59.718756 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:01:59.719213 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:59.723702 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:01:59.724198 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:00.205037 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:00.211972 [debug] [ThreadPool]: On list_dev: Close
[0m19:02:00.220814 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:02:00.244934 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:00.245870 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:02:00.246511 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:02:00.247509 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:00.248196 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:00.573624 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:00.574744 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:00.575692 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:02:00.641806 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:00.650167 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:02:00.700343 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:02:00.741903 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:00.742781 [debug] [MainThread]: On master: BEGIN
[0m19:02:00.743431 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:02:00.744425 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:00.745118 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:01.053638 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:01.055938 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:01.057563 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:02:01.158370 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:01.163355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1ead7aa1-e3e5-4290-b08c-85d023600fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadf9478f40>]}
[0m19:02:01.165096 [debug] [MainThread]: On master: ROLLBACK
[0m19:02:01.235927 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:01.238059 [debug] [MainThread]: On master: BEGIN
[0m19:02:01.262211 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:01.264268 [debug] [MainThread]: On master: COMMIT
[0m19:02:01.266278 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:01.267571 [debug] [MainThread]: On master: COMMIT
[0m19:02:01.313374 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:01.316193 [debug] [MainThread]: On master: Close
[0m19:02:01.324239 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:02:01.326626 [info ] [MainThread]: 
[0m19:02:01.332672 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m19:02:01.334232 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m19:02:01.336698 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m19:02:01.337872 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m19:02:01.349452 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m19:02:01.351407 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 19:02:01.338508 => 19:02:01.350814
[0m19:02:01.352224 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m19:02:01.456480 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:01.457135 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp190201403410"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m19:02:01.457668 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:02:01.458371 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:01.458884 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:01.846131 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:01.905514 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:01.906412 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m19:02:01.955473 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:01.956416 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:01.957804 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp190201403410'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp190201403410'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp190201403410'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:02:02.108852 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:02.157795 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:02.158893 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:02.305025 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:02.362767 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:02.363750 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:02.482052 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:02.524351 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m19:02:02.529098 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:02.529722 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp190201403410"
            where (
                
                    "dim_event__dbt_tmp190201403410".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m19:02:02.641041 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:02.642329 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:02.643310 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp190201403410"
    )
[0m19:02:02.721902 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:02.770939 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:02:02.771939 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:02:02.772508 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:02:03.327893 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:03.334455 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 19:02:01.352698 => 19:02:03.333163
[0m19:02:03.336479 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m19:02:03.339453 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1ead7aa1-e3e5-4290-b08c-85d023600fbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea7b7100>]}
[0m19:02:03.341867 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.00s]
[0m19:02:03.343480 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m19:02:03.347737 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:03.348761 [debug] [MainThread]: On master: BEGIN
[0m19:02:03.349589 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:02:03.350938 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:03.352309 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:03.666544 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:03.668623 [debug] [MainThread]: On master: COMMIT
[0m19:02:03.670326 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:03.671527 [debug] [MainThread]: On master: COMMIT
[0m19:02:03.720843 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:03.722817 [debug] [MainThread]: On master: Close
[0m19:02:03.726084 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:02:03.727828 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m19:02:03.729983 [info ] [MainThread]: 
[0m19:02:03.731588 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.04 seconds (4.04s).
[0m19:02:03.734364 [debug] [MainThread]: Command end result
[0m19:02:03.762749 [info ] [MainThread]: 
[0m19:02:03.763687 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:02:03.764357 [info ] [MainThread]: 
[0m19:02:03.765092 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:02:03.768930 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8365684, "process_user_time": 4.50058, "process_kernel_time": 0.379838, "process_mem_max_rss": "122601472", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:02:03.769959 [debug] [MainThread]: Command `dbt run` succeeded at 19:02:03.769718 after 4.84 seconds
[0m19:02:03.770641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadf8ba9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadea669d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadf9688670>]}
[0m19:02:03.771326 [debug] [MainThread]: Flushing usage events
[0m19:02:10.263147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1e8fa5670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1ea1d42e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1ea1eb370>]}


============================== 19:02:10.269305 | d1cc7915-847a-43ed-8b5e-a498b93cda83 ==============================
[0m19:02:10.269305 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:02:10.270101 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_participant', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:02:10.704665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd1cc7915-847a-43ed-8b5e-a498b93cda83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1f97bffa0>]}
[0m19:02:10.826323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd1cc7915-847a-43ed-8b5e-a498b93cda83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1ea21a0a0>]}
[0m19:02:10.828581 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:02:10.844157 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:02:10.912440 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:02:10.913020 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:02:10.922469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd1cc7915-847a-43ed-8b5e-a498b93cda83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1f991fe20>]}
[0m19:02:10.936808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd1cc7915-847a-43ed-8b5e-a498b93cda83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1ea65f760>]}
[0m19:02:10.937457 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:02:10.937948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1cc7915-847a-43ed-8b5e-a498b93cda83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1ea65f6a0>]}
[0m19:02:10.939789 [info ] [MainThread]: 
[0m19:02:10.940810 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:02:10.942283 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:02:10.966980 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:02:10.967511 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:02:10.967968 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:02:10.972508 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:10.973018 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:11.483088 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:11.491058 [debug] [ThreadPool]: On list_dev: Close
[0m19:02:11.499785 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:02:11.523265 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:11.524235 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:02:11.524881 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:02:11.525944 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:11.526670 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:11.862444 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:11.864760 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:11.866224 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:02:11.939179 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:11.947778 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:02:12.001399 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:02:12.040222 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:12.041112 [debug] [MainThread]: On master: BEGIN
[0m19:02:12.041753 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:02:12.042721 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:12.043426 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:12.365915 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:12.367597 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:12.368619 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:02:12.465294 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:12.474176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd1cc7915-847a-43ed-8b5e-a498b93cda83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1f9817850>]}
[0m19:02:12.476976 [debug] [MainThread]: On master: ROLLBACK
[0m19:02:12.542601 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:12.544229 [debug] [MainThread]: On master: BEGIN
[0m19:02:12.569026 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:12.570118 [debug] [MainThread]: On master: COMMIT
[0m19:02:12.571125 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:12.571927 [debug] [MainThread]: On master: COMMIT
[0m19:02:12.620247 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:12.621292 [debug] [MainThread]: On master: Close
[0m19:02:12.623502 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:02:12.624445 [info ] [MainThread]: 
[0m19:02:12.629090 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m19:02:12.630424 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m19:02:12.632173 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m19:02:12.633049 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m19:02:12.641563 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m19:02:12.643063 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 19:02:12.633575 => 19:02:12.642531
[0m19:02:12.643897 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m19:02:12.744833 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:12.745537 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp190212691463"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m19:02:12.746074 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:02:12.746794 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:12.747322 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:13.126322 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:13.179449 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:13.180342 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m19:02:13.228764 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:13.229736 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:13.231120 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp190212691463'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp190212691463'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp190212691463'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:02:13.384893 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:13.435067 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:13.436276 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:13.579915 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:13.629075 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:13.630087 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:13.748904 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:13.800741 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m19:02:13.805943 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:13.806685 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp190212691463"
            where (
                
                    "dim_participant__dbt_tmp190212691463".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp190212691463".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m19:02:13.932049 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:13.935307 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:13.938760 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp190212691463"
    )
[0m19:02:14.045236 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:14.096749 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:02:14.097885 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:02:14.098663 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:02:14.692473 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:14.698061 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 19:02:12.644368 => 19:02:14.697237
[0m19:02:14.699482 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m19:02:14.702999 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd1cc7915-847a-43ed-8b5e-a498b93cda83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1f99c8310>]}
[0m19:02:14.706420 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 2.07s]
[0m19:02:14.708498 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m19:02:14.711721 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:14.712698 [debug] [MainThread]: On master: BEGIN
[0m19:02:14.713504 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:02:14.714701 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:14.715566 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:15.033679 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:15.035386 [debug] [MainThread]: On master: COMMIT
[0m19:02:15.036814 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:15.037642 [debug] [MainThread]: On master: COMMIT
[0m19:02:15.086098 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:15.087557 [debug] [MainThread]: On master: Close
[0m19:02:15.091103 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:02:15.092408 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m19:02:15.094219 [info ] [MainThread]: 
[0m19:02:15.095954 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.15 seconds (4.15s).
[0m19:02:15.099665 [debug] [MainThread]: Command end result
[0m19:02:15.129811 [info ] [MainThread]: 
[0m19:02:15.130914 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:02:15.131608 [info ] [MainThread]: 
[0m19:02:15.132403 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:02:15.137171 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9807196, "process_user_time": 4.480293, "process_kernel_time": 0.381628, "process_mem_max_rss": "124317696", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:02:15.138579 [debug] [MainThread]: Command `dbt run` succeeded at 19:02:15.138307 after 4.98 seconds
[0m19:02:15.139297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1e8fa5670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1ea788c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa1f9934370>]}
[0m19:02:15.140032 [debug] [MainThread]: Flushing usage events
[0m19:02:23.516268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d90fa96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d80d20d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d81c124f0>]}


============================== 19:02:23.522359 | f64eebec-afd0-4d69-9f61-9970ebadfe8a ==============================
[0m19:02:23.522359 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:02:23.523189 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_event_dtls', 'send_anonymous_usage_stats': 'True'}
[0m19:02:24.053829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f64eebec-afd0-4d69-9f61-9970ebadfe8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d81c0e550>]}
[0m19:02:24.173746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f64eebec-afd0-4d69-9f61-9970ebadfe8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d80098fd0>]}
[0m19:02:24.175878 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:02:24.191375 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:02:24.262629 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:02:24.263239 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:02:24.273007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f64eebec-afd0-4d69-9f61-9970ebadfe8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d91ce7dc0>]}
[0m19:02:24.288228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f64eebec-afd0-4d69-9f61-9970ebadfe8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d820d7760>]}
[0m19:02:24.288933 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:02:24.289450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f64eebec-afd0-4d69-9f61-9970ebadfe8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d820d7670>]}
[0m19:02:24.291377 [info ] [MainThread]: 
[0m19:02:24.292438 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:02:24.293888 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:02:24.318203 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:02:24.318729 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:02:24.319190 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:02:24.323724 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:24.324224 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:24.811708 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:24.821287 [debug] [ThreadPool]: On list_dev: Close
[0m19:02:24.831948 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:02:24.854459 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:24.855427 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:02:24.856084 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:02:24.857131 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:24.857860 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:25.183325 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:25.186202 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:25.188276 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:02:25.256032 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:25.267009 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:02:25.317834 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:02:25.358756 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:25.359659 [debug] [MainThread]: On master: BEGIN
[0m19:02:25.360320 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:02:25.361362 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:25.362069 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:25.701903 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:25.704520 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:25.706705 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:02:25.805340 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:25.813090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f64eebec-afd0-4d69-9f61-9970ebadfe8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d81efef10>]}
[0m19:02:25.815531 [debug] [MainThread]: On master: ROLLBACK
[0m19:02:25.881418 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:25.882780 [debug] [MainThread]: On master: BEGIN
[0m19:02:25.909277 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:25.910138 [debug] [MainThread]: On master: COMMIT
[0m19:02:25.911125 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:25.911901 [debug] [MainThread]: On master: COMMIT
[0m19:02:25.963251 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:25.965035 [debug] [MainThread]: On master: Close
[0m19:02:25.969535 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:02:25.971286 [info ] [MainThread]: 
[0m19:02:25.980393 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m19:02:25.982345 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m19:02:25.985190 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m19:02:25.986508 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m19:02:25.998219 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m19:02:26.000332 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 19:02:25.987497 => 19:02:25.999662
[0m19:02:26.001370 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m19:02:26.104178 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:26.104920 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp190226052175"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m19:02:26.105512 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:02:26.106244 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:26.106794 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:26.489746 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:26.547710 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:26.548589 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m19:02:26.600678 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:26.601647 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:26.603464 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp190226052175'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp190226052175'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp190226052175'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:02:26.751813 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:26.798588 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:26.799753 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:26.946910 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:26.984896 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:26.985886 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:27.148801 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:27.206495 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m19:02:27.211879 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:27.212546 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp190226052175"
            where (
                
                    "dim_event_dtls__dbt_tmp190226052175".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m19:02:27.331555 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:27.334279 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:27.336400 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp190226052175"
    )
[0m19:02:27.416211 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:27.472955 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:02:27.473883 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:02:27.474567 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:02:28.006856 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:28.011723 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 19:02:26.001970 => 19:02:28.010931
[0m19:02:28.013012 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m19:02:28.016419 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f64eebec-afd0-4d69-9f61-9970ebadfe8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d600d0b50>]}
[0m19:02:28.019951 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.03s]
[0m19:02:28.022004 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m19:02:28.025208 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:28.026114 [debug] [MainThread]: On master: BEGIN
[0m19:02:28.026902 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:02:28.028146 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:28.029018 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:28.349464 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:28.351342 [debug] [MainThread]: On master: COMMIT
[0m19:02:28.353070 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:28.354320 [debug] [MainThread]: On master: COMMIT
[0m19:02:28.399982 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:28.402090 [debug] [MainThread]: On master: Close
[0m19:02:28.406154 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:02:28.407495 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m19:02:28.409131 [info ] [MainThread]: 
[0m19:02:28.410623 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m19:02:28.413402 [debug] [MainThread]: Command end result
[0m19:02:28.441536 [info ] [MainThread]: 
[0m19:02:28.442447 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:02:28.443113 [info ] [MainThread]: 
[0m19:02:28.443861 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:02:28.447923 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0379972, "process_user_time": 4.501755, "process_kernel_time": 0.392471, "process_mem_max_rss": "122728448", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:02:28.449080 [debug] [MainThread]: Command `dbt run` succeeded at 19:02:28.448817 after 5.04 seconds
[0m19:02:28.449850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d90fa96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d820d7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d8218d820>]}
[0m19:02:28.450573 [debug] [MainThread]: Flushing usage events
[0m19:02:35.059460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4d0c55d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e0516c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e050df70>]}


============================== 19:02:35.065616 | 1caadb47-89a2-42e1-bf98-ca65118909e7 ==============================
[0m19:02:35.065616 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:02:35.066416 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_group', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:02:35.474962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1caadb47-89a2-42e1-bf98-ca65118909e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e0502f10>]}
[0m19:02:35.595522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1caadb47-89a2-42e1-bf98-ca65118909e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e0531f10>]}
[0m19:02:35.597183 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:02:35.613087 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:02:35.679664 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:02:35.680223 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:02:35.689635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1caadb47-89a2-42e1-bf98-ca65118909e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4d1bd7e80>]}
[0m19:02:35.705079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1caadb47-89a2-42e1-bf98-ca65118909e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e06787c0>]}
[0m19:02:35.705801 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:02:35.706310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1caadb47-89a2-42e1-bf98-ca65118909e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e0678700>]}
[0m19:02:35.708261 [info ] [MainThread]: 
[0m19:02:35.709348 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:02:35.710796 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:02:35.737098 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:02:35.737738 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:02:35.738214 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:02:35.742887 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:35.743419 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:36.387949 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:36.391778 [debug] [ThreadPool]: On list_dev: Close
[0m19:02:36.395871 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:02:36.411187 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:36.411900 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:02:36.412544 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:02:36.413918 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:36.414487 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:36.729458 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:36.731447 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:36.732981 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:02:36.797107 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:36.805758 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:02:36.858654 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:02:36.904740 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:36.905544 [debug] [MainThread]: On master: BEGIN
[0m19:02:36.906408 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:02:36.907672 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:36.908515 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:37.253405 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:37.254633 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:37.255633 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:02:37.353833 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:37.360110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1caadb47-89a2-42e1-bf98-ca65118909e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e05bd520>]}
[0m19:02:37.363072 [debug] [MainThread]: On master: ROLLBACK
[0m19:02:37.431459 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:37.433317 [debug] [MainThread]: On master: BEGIN
[0m19:02:37.461081 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:37.463107 [debug] [MainThread]: On master: COMMIT
[0m19:02:37.464623 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:37.465943 [debug] [MainThread]: On master: COMMIT
[0m19:02:37.518497 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:37.519829 [debug] [MainThread]: On master: Close
[0m19:02:37.522414 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:02:37.523503 [info ] [MainThread]: 
[0m19:02:37.530039 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m19:02:37.531803 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m19:02:37.534760 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m19:02:37.536151 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m19:02:37.551268 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m19:02:37.554838 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 19:02:37.536798 => 19:02:37.553318
[0m19:02:37.555948 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m19:02:37.663675 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:37.664400 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp190237607432"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m19:02:37.664961 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:02:37.665776 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:37.666345 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:38.042609 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:38.090856 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:38.091764 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m19:02:38.145154 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:38.146268 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:38.147676 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp190237607432'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp190237607432'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp190237607432'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:02:38.296794 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:38.334969 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:38.336163 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:38.476765 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:38.527884 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:38.529087 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:38.646088 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:38.694118 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m19:02:38.701126 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:38.702438 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp190237607432"
            where (
                
                    "dim_group__dbt_tmp190237607432".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp190237607432".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m19:02:38.813093 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:38.815707 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:38.818169 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp190237607432"
    )
[0m19:02:38.897073 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:38.943962 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:02:38.945102 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:02:38.945784 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:02:39.474874 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:39.479258 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 19:02:37.556471 => 19:02:39.478616
[0m19:02:39.480383 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m19:02:39.483673 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1caadb47-89a2-42e1-bf98-ca65118909e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc501bf6700>]}
[0m19:02:39.486744 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 1.95s]
[0m19:02:39.488584 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m19:02:39.493710 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:39.494800 [debug] [MainThread]: On master: BEGIN
[0m19:02:39.495730 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:02:39.497179 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:39.498055 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:39.815497 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:39.817042 [debug] [MainThread]: On master: COMMIT
[0m19:02:39.818872 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:39.820474 [debug] [MainThread]: On master: COMMIT
[0m19:02:39.864282 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:39.865643 [debug] [MainThread]: On master: Close
[0m19:02:39.868354 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:02:39.869293 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m19:02:39.870375 [info ] [MainThread]: 
[0m19:02:39.871321 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.16 seconds (4.16s).
[0m19:02:39.873099 [debug] [MainThread]: Command end result
[0m19:02:39.901787 [info ] [MainThread]: 
[0m19:02:39.902776 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:02:39.903469 [info ] [MainThread]: 
[0m19:02:39.904265 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:02:39.909903 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9590487, "process_user_time": 4.652833, "process_kernel_time": 0.42964, "process_mem_max_rss": "114540544", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:02:39.911211 [debug] [MainThread]: Command `dbt run` succeeded at 19:02:39.910928 after 4.96 seconds
[0m19:02:39.912052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4d0c55d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc501b76910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4e06787f0>]}
[0m19:02:39.912888 [debug] [MainThread]: Flushing usage events
[0m19:02:46.814676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87311add00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87408a4c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f874089cf70>]}


============================== 19:02:46.821350 | 69753568-e020-4640-a3e2-f833663f7864 ==============================
[0m19:02:46.821350 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:02:46.822200 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:02:47.242696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '69753568-e020-4640-a3e2-f833663f7864', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731b42f10>]}
[0m19:02:47.372585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '69753568-e020-4640-a3e2-f833663f7864', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87408c1f10>]}
[0m19:02:47.375128 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:02:47.393499 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:02:47.466414 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:02:47.467058 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:02:47.477785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '69753568-e020-4640-a3e2-f833663f7864', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872163fe80>]}
[0m19:02:47.493334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '69753568-e020-4640-a3e2-f833663f7864', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731eb87c0>]}
[0m19:02:47.494126 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:02:47.494636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69753568-e020-4640-a3e2-f833663f7864', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8731eb8700>]}
[0m19:02:47.496587 [info ] [MainThread]: 
[0m19:02:47.497683 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:02:47.499147 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:02:47.525670 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:02:47.526289 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:02:47.526783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:02:47.531353 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:47.531870 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:48.066005 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:48.069670 [debug] [ThreadPool]: On list_dev: Close
[0m19:02:48.073528 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:02:48.089508 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:48.090275 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:02:48.090898 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:02:48.091960 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:48.092508 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:48.428802 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:48.430964 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:02:48.432377 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:02:48.500248 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:48.503470 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:02:48.551017 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:02:48.577861 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:48.578736 [debug] [MainThread]: On master: BEGIN
[0m19:02:48.579319 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:02:48.580212 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:48.580760 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:48.916282 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:48.918343 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:48.919568 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:02:49.027404 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:49.034190 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '69753568-e020-4640-a3e2-f833663f7864', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872159d520>]}
[0m19:02:49.038156 [debug] [MainThread]: On master: ROLLBACK
[0m19:02:49.109695 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:49.111080 [debug] [MainThread]: On master: BEGIN
[0m19:02:49.136005 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:49.137513 [debug] [MainThread]: On master: COMMIT
[0m19:02:49.138839 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:49.139830 [debug] [MainThread]: On master: COMMIT
[0m19:02:49.187917 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:49.189312 [debug] [MainThread]: On master: Close
[0m19:02:49.192331 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:02:49.193390 [info ] [MainThread]: 
[0m19:02:49.201882 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m19:02:49.204152 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m19:02:49.206509 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m19:02:49.207758 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m19:02:49.219737 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m19:02:49.222638 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 19:02:49.208435 => 19:02:49.221906
[0m19:02:49.223439 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m19:02:49.349682 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:49.350962 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp190249281370"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m19:02:49.351922 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:02:49.353376 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:49.354385 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:49.755881 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:49.806609 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:49.807524 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m19:02:49.860662 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:49.861796 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:49.863200 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp190249281370'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp190249281370'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp190249281370'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:02:50.015595 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:50.061076 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:50.062613 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:50.211499 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:50.259714 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:50.260786 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:02:50.380720 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:50.422575 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m19:02:50.429458 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:50.430155 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp190249281370"
            where (
                
                    "dim_outcome__dbt_tmp190249281370".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp190249281370".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp190249281370".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m19:02:50.545955 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:50.549252 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:50.551672 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp190249281370"
    )
[0m19:02:50.642247 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:50.682750 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:02:50.683620 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:02:50.684262 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:02:51.453609 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:02:51.457919 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 19:02:49.223884 => 19:02:51.456897
[0m19:02:51.459622 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m19:02:51.462977 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '69753568-e020-4640-a3e2-f833663f7864', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f870002aca0>]}
[0m19:02:51.466932 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.26s]
[0m19:02:51.469661 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m19:02:51.474389 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:51.475645 [debug] [MainThread]: On master: BEGIN
[0m19:02:51.476729 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:02:51.478707 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:02:51.479898 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:02:51.810878 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:51.812611 [debug] [MainThread]: On master: COMMIT
[0m19:02:51.814186 [debug] [MainThread]: Using redshift connection "master"
[0m19:02:51.815047 [debug] [MainThread]: On master: COMMIT
[0m19:02:51.870793 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:02:51.871485 [debug] [MainThread]: On master: Close
[0m19:02:51.872663 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:02:51.873121 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m19:02:51.873680 [info ] [MainThread]: 
[0m19:02:51.874314 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.38 seconds (4.38s).
[0m19:02:51.875434 [debug] [MainThread]: Command end result
[0m19:02:51.890165 [info ] [MainThread]: 
[0m19:02:51.890960 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:02:51.891460 [info ] [MainThread]: 
[0m19:02:51.891995 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:02:51.895541 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.191911, "process_user_time": 4.601799, "process_kernel_time": 0.406517, "process_mem_max_rss": "118521856", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:02:51.896889 [debug] [MainThread]: Command `dbt run` succeeded at 19:02:51.896614 after 5.19 seconds
[0m19:02:51.897545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87311add00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872158a160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8740a427f0>]}
[0m19:02:51.898222 [debug] [MainThread]: Flushing usage events
[0m19:14:08.406201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83a0ab5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83b07c4c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83b07bcf70>]}


============================== 19:14:08.414730 | e010f2c8-1e58-40b3-9cb9-e5afe026b161 ==============================
[0m19:14:08.414730 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:14:08.415662 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_market', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:14:09.005804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e010f2c8-1e58-40b3-9cb9-e5afe026b161', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83a1432f10>]}
[0m19:14:09.128293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e010f2c8-1e58-40b3-9cb9-e5afe026b161', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83b07e1f10>]}
[0m19:14:09.129826 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:14:09.146558 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:14:09.221247 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:14:09.221832 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:14:09.232336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e010f2c8-1e58-40b3-9cb9-e5afe026b161', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8392017e80>]}
[0m19:14:09.249118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e010f2c8-1e58-40b3-9cb9-e5afe026b161', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83b0ae87c0>]}
[0m19:14:09.249834 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:14:09.250334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e010f2c8-1e58-40b3-9cb9-e5afe026b161', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83b0ae8700>]}
[0m19:14:09.252280 [info ] [MainThread]: 
[0m19:14:09.253368 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:14:09.254908 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:14:09.279422 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:14:09.280007 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:14:09.280459 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:09.285012 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:09.285823 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:09.903579 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:14:09.912587 [debug] [ThreadPool]: On list_dev: Close
[0m19:14:09.921169 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:14:09.945687 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:09.947012 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:14:09.947873 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:14:09.948785 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:09.949419 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:10.292618 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:10.295039 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:10.296637 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:14:10.363275 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:10.368247 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:14:10.417555 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:14:10.448261 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:10.448919 [debug] [MainThread]: On master: BEGIN
[0m19:14:10.449364 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:14:10.452058 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:10.452570 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:10.777579 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:10.779261 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:10.780243 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:14:10.874422 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:10.879407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e010f2c8-1e58-40b3-9cb9-e5afe026b161', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8391f76520>]}
[0m19:14:10.881521 [debug] [MainThread]: On master: ROLLBACK
[0m19:14:10.948371 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:10.949948 [debug] [MainThread]: On master: BEGIN
[0m19:14:10.976382 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:10.978222 [debug] [MainThread]: On master: COMMIT
[0m19:14:10.979476 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:10.980345 [debug] [MainThread]: On master: COMMIT
[0m19:14:11.029679 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:11.031802 [debug] [MainThread]: On master: Close
[0m19:14:11.034905 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:14:11.035878 [info ] [MainThread]: 
[0m19:14:11.043148 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m19:14:11.045315 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m19:14:11.047610 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m19:14:11.048675 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m19:14:11.062295 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m19:14:11.064473 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 19:14:11.049264 => 19:14:11.063782
[0m19:14:11.065476 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m19:14:11.173027 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:11.173715 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp191411120411"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m19:14:11.174257 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:14:11.174982 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:11.175494 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:11.556441 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:11.605783 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:11.606550 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m19:14:11.650998 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:11.651625 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:11.652430 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp191411120411'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp191411120411'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp191411120411'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:14:11.802128 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:11.829783 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:11.831024 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:11.976325 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:12.015348 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:12.016271 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:12.133347 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:12.173073 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m19:14:12.177947 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:12.178524 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp191411120411"
            where (
                
                    "dim_market__dbt_tmp191411120411".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp191411120411".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m19:14:12.291931 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:12.295085 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:12.296844 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp191411120411"
    )
[0m19:14:12.380951 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:12.420122 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:14:12.420856 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:14:12.421352 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:14:12.915635 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:12.920855 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 19:14:11.066058 => 19:14:12.920030
[0m19:14:12.922225 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m19:14:12.925547 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e010f2c8-1e58-40b3-9cb9-e5afe026b161', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83b0be81c0>]}
[0m19:14:12.929086 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 1.88s]
[0m19:14:12.931084 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m19:14:12.936591 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:12.937965 [debug] [MainThread]: On master: BEGIN
[0m19:14:12.939018 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:14:12.940241 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:12.941100 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:13.268840 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:13.270724 [debug] [MainThread]: On master: COMMIT
[0m19:14:13.272293 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:13.274785 [debug] [MainThread]: On master: COMMIT
[0m19:14:13.321159 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:13.322597 [debug] [MainThread]: On master: Close
[0m19:14:13.325835 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:14:13.327489 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m19:14:13.328978 [info ] [MainThread]: 
[0m19:14:13.330134 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.08 seconds (4.08s).
[0m19:14:13.332372 [debug] [MainThread]: Command end result
[0m19:14:13.361279 [info ] [MainThread]: 
[0m19:14:13.362230 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:14:13.362912 [info ] [MainThread]: 
[0m19:14:13.363691 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:14:13.369122 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0829096, "process_user_time": 4.493378, "process_kernel_time": 0.410944, "process_mem_max_rss": "117547008", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:14:13.370304 [debug] [MainThread]: Command `dbt run` succeeded at 19:14:13.370042 after 5.08 seconds
[0m19:14:13.371030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83a0ab5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83b0ae8730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f83a1570700>]}
[0m19:14:13.371763 [debug] [MainThread]: Flushing usage events
[0m19:14:19.892669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5117f96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5114c1d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5012514f0>]}


============================== 19:14:19.899003 | de80dac3-0444-426e-82d0-93784f2248da ==============================
[0m19:14:19.899003 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:14:19.899831 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_event', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:14:20.333819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'de80dac3-0444-426e-82d0-93784f2248da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff50124b550>]}
[0m19:14:20.453681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'de80dac3-0444-426e-82d0-93784f2248da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff50120d520>]}
[0m19:14:20.455208 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:14:20.470688 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:14:20.537070 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:14:20.537637 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:14:20.546974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'de80dac3-0444-426e-82d0-93784f2248da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff501417dc0>]}
[0m19:14:20.562997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'de80dac3-0444-426e-82d0-93784f2248da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51281f700>]}
[0m19:14:20.563712 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:14:20.564229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de80dac3-0444-426e-82d0-93784f2248da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51281f640>]}
[0m19:14:20.566138 [info ] [MainThread]: 
[0m19:14:20.567208 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:14:20.568655 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:14:20.593114 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:14:20.593635 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:14:20.594086 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:20.598668 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:20.599178 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:21.137259 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:14:21.139790 [debug] [ThreadPool]: On list_dev: Close
[0m19:14:21.143957 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:14:21.156240 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:21.157019 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:14:21.157523 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:14:21.158378 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:21.159449 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:21.484900 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:21.486231 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:21.487181 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:14:21.551843 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:21.559997 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:14:21.611256 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:14:21.647304 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:21.648323 [debug] [MainThread]: On master: BEGIN
[0m19:14:21.649035 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:14:21.650079 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:21.650833 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:21.968352 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:21.970396 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:21.971724 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:14:22.072227 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:22.079659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'de80dac3-0444-426e-82d0-93784f2248da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff512646400>]}
[0m19:14:22.081708 [debug] [MainThread]: On master: ROLLBACK
[0m19:14:22.150228 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:22.152383 [debug] [MainThread]: On master: BEGIN
[0m19:14:22.180271 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:22.182587 [debug] [MainThread]: On master: COMMIT
[0m19:14:22.184723 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:22.186463 [debug] [MainThread]: On master: COMMIT
[0m19:14:22.233006 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:22.235753 [debug] [MainThread]: On master: Close
[0m19:14:22.240408 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:14:22.242862 [info ] [MainThread]: 
[0m19:14:22.252057 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m19:14:22.254342 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m19:14:22.256964 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m19:14:22.258895 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m19:14:22.270579 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m19:14:22.272578 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 19:14:22.259959 => 19:14:22.271938
[0m19:14:22.273502 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m19:14:22.381221 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:22.381927 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp191422326071"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m19:14:22.382479 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:14:22.383209 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:22.383735 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:22.760023 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:22.799086 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:22.799818 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m19:14:22.850659 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:22.851564 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:22.852550 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp191422326071'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp191422326071'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp191422326071'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:14:22.998769 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:23.049179 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:23.050566 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:23.222817 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:23.275423 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:23.276585 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:23.393392 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:23.447674 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m19:14:23.453697 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:23.454452 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp191422326071"
            where (
                
                    "dim_event__dbt_tmp191422326071".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m19:14:23.567841 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:23.569794 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:23.571630 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp191422326071"
    )
[0m19:14:23.650798 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:23.699163 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:14:23.700308 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:14:23.700991 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:14:24.239334 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:14:24.240974 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 19:14:22.274030 => 19:14:24.240638
[0m19:14:24.241550 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m19:14:24.242825 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'de80dac3-0444-426e-82d0-93784f2248da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5015477f0>]}
[0m19:14:24.244181 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 1.99s]
[0m19:14:24.245013 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m19:14:24.246812 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:24.247315 [debug] [MainThread]: On master: BEGIN
[0m19:14:24.247749 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:14:24.248404 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:24.248860 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:24.557354 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:24.559827 [debug] [MainThread]: On master: COMMIT
[0m19:14:24.562389 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:24.563963 [debug] [MainThread]: On master: COMMIT
[0m19:14:24.617312 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:24.619567 [debug] [MainThread]: On master: Close
[0m19:14:24.622845 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:14:24.624175 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m19:14:24.626222 [info ] [MainThread]: 
[0m19:14:24.628443 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.06 seconds (4.06s).
[0m19:14:24.631433 [debug] [MainThread]: Command end result
[0m19:14:24.660773 [info ] [MainThread]: 
[0m19:14:24.661631 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:14:24.662221 [info ] [MainThread]: 
[0m19:14:24.662881 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:14:24.666984 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8806562, "process_user_time": 4.487385, "process_kernel_time": 0.36791, "process_mem_max_rss": "121532416", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:14:24.668147 [debug] [MainThread]: Command `dbt run` succeeded at 19:14:24.667891 after 4.88 seconds
[0m19:14:24.668866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5117f96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5129087f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5129085b0>]}
[0m19:14:24.669613 [debug] [MainThread]: Flushing usage events
[0m19:14:31.170058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd460f45670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4508d0d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd461a12580>]}


============================== 19:14:31.176663 | b1e0ebdb-946c-4e17-be32-65b13ca5d831 ==============================
[0m19:14:31.176663 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:14:31.177513 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_participant', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:14:31.604826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1e0ebdb-946c-4e17-be32-65b13ca5d831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd461a0d550>]}
[0m19:14:31.723491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1e0ebdb-946c-4e17-be32-65b13ca5d831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd44078af40>]}
[0m19:14:31.725589 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:14:31.741294 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:14:31.810091 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:14:31.810713 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:14:31.820377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1e0ebdb-946c-4e17-be32-65b13ca5d831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd461c7fdc0>]}
[0m19:14:31.835953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1e0ebdb-946c-4e17-be32-65b13ca5d831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45172d760>]}
[0m19:14:31.836668 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:14:31.837195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1e0ebdb-946c-4e17-be32-65b13ca5d831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45172d670>]}
[0m19:14:31.839220 [info ] [MainThread]: 
[0m19:14:31.840339 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:14:31.841809 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:14:31.866499 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:14:31.867125 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:14:31.867605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:31.872206 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:31.872734 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:32.368118 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:32.373773 [debug] [ThreadPool]: On list_dev: Close
[0m19:14:32.381357 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:14:32.405292 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:32.406180 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:14:32.406830 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:14:32.407806 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:32.408489 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:32.744020 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:32.745487 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:32.746641 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:14:32.812289 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:32.818550 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:14:32.880001 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:14:32.916642 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:32.917556 [debug] [MainThread]: On master: BEGIN
[0m19:14:32.918242 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:14:32.919283 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:32.920112 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:33.257961 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:33.259646 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:33.261799 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:14:33.357065 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:33.360073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1e0ebdb-946c-4e17-be32-65b13ca5d831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd461c241f0>]}
[0m19:14:33.361001 [debug] [MainThread]: On master: ROLLBACK
[0m19:14:33.423156 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:33.423780 [debug] [MainThread]: On master: BEGIN
[0m19:14:33.446749 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:33.447378 [debug] [MainThread]: On master: COMMIT
[0m19:14:33.447965 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:33.448400 [debug] [MainThread]: On master: COMMIT
[0m19:14:33.497034 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:33.498530 [debug] [MainThread]: On master: Close
[0m19:14:33.501878 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:14:33.503388 [info ] [MainThread]: 
[0m19:14:33.508249 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m19:14:33.509389 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m19:14:33.510719 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m19:14:33.511426 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m19:14:33.519041 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m19:14:33.520919 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 19:14:33.511852 => 19:14:33.520382
[0m19:14:33.521724 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m19:14:33.667983 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:33.668889 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp191433570609"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m19:14:33.669652 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:14:33.671086 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:33.672898 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:34.084170 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:34.115858 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:34.116670 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m19:14:34.167579 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:34.168601 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:34.169818 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp191433570609'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp191433570609'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp191433570609'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:14:34.321755 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:34.368283 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:34.369782 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:34.518062 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:34.570609 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:34.571805 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:34.690754 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:34.739544 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m19:14:34.746866 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:34.747928 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp191433570609"
            where (
                
                    "dim_participant__dbt_tmp191433570609".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp191433570609".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m19:14:34.860157 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:34.862468 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:34.864058 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp191433570609"
    )
[0m19:14:34.944160 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:34.990992 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:14:34.992176 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:14:34.992895 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:14:35.648073 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:14:35.652919 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 19:14:33.522206 => 19:14:35.652017
[0m19:14:35.654541 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m19:14:35.658070 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1e0ebdb-946c-4e17-be32-65b13ca5d831', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd4517ddca0>]}
[0m19:14:35.661265 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 2.15s]
[0m19:14:35.663223 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m19:14:35.667098 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:35.668251 [debug] [MainThread]: On master: BEGIN
[0m19:14:35.669243 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:14:35.671412 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:35.672571 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:35.997596 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:35.999354 [debug] [MainThread]: On master: COMMIT
[0m19:14:36.000797 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:36.001655 [debug] [MainThread]: On master: COMMIT
[0m19:14:36.046845 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:36.048179 [debug] [MainThread]: On master: Close
[0m19:14:36.051243 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:14:36.052575 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m19:14:36.054998 [info ] [MainThread]: 
[0m19:14:36.056963 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.21 seconds (4.21s).
[0m19:14:36.060245 [debug] [MainThread]: Command end result
[0m19:14:36.090321 [info ] [MainThread]: 
[0m19:14:36.091500 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:14:36.092262 [info ] [MainThread]: 
[0m19:14:36.093325 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:14:36.097892 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0387206, "process_user_time": 4.536949, "process_kernel_time": 0.391055, "process_mem_max_rss": "121622528", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:14:36.099089 [debug] [MainThread]: Command `dbt run` succeeded at 19:14:36.098836 after 5.04 seconds
[0m19:14:36.099833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd460f45670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd451622f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd45172d610>]}
[0m19:14:36.100585 [debug] [MainThread]: Flushing usage events
[0m19:14:44.874919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e1305d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8d1964c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8d195ceb0>]}


============================== 19:14:44.880975 | 61255803-cdf8-4106-9b41-98e1355726e6 ==============================
[0m19:14:44.880975 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:14:44.881767 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_event_dtls', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:14:45.377785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '61255803-cdf8-4106-9b41-98e1355726e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8d1953b20>]}
[0m19:14:45.495863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '61255803-cdf8-4106-9b41-98e1355726e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8d1981f10>]}
[0m19:14:45.498045 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:14:45.514208 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:14:45.583972 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:14:45.584611 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:14:45.593926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '61255803-cdf8-4106-9b41-98e1355726e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e2217e80>]}
[0m19:14:45.609468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '61255803-cdf8-4106-9b41-98e1355726e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8d1db87c0>]}
[0m19:14:45.610286 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:14:45.610827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '61255803-cdf8-4106-9b41-98e1355726e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8d1db8700>]}
[0m19:14:45.612948 [info ] [MainThread]: 
[0m19:14:45.614179 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:14:45.615850 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:14:45.641979 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:14:45.642617 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:14:45.643100 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:45.647760 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:45.648307 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:46.157045 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:14:46.162834 [debug] [ThreadPool]: On list_dev: Close
[0m19:14:46.168969 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:14:46.193687 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:46.194808 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:14:46.195789 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:14:46.196977 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:46.197713 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:46.521864 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:46.523984 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:46.525527 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:14:46.591499 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:46.601055 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:14:46.652040 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:14:46.691054 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:46.692018 [debug] [MainThread]: On master: BEGIN
[0m19:14:46.692751 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:14:46.693826 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:46.694570 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:47.016745 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:47.018586 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:47.019854 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:14:47.120589 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:47.126192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '61255803-cdf8-4106-9b41-98e1355726e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e20b5520>]}
[0m19:14:47.127733 [debug] [MainThread]: On master: ROLLBACK
[0m19:14:47.196233 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:47.197909 [debug] [MainThread]: On master: BEGIN
[0m19:14:47.220751 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:47.222831 [debug] [MainThread]: On master: COMMIT
[0m19:14:47.224515 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:47.226249 [debug] [MainThread]: On master: COMMIT
[0m19:14:47.272696 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:47.274195 [debug] [MainThread]: On master: Close
[0m19:14:47.277205 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:14:47.278752 [info ] [MainThread]: 
[0m19:14:47.284743 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m19:14:47.286548 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m19:14:47.289029 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m19:14:47.290448 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m19:14:47.301532 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m19:14:47.303379 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 19:14:47.291319 => 19:14:47.302857
[0m19:14:47.304159 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m19:14:47.435925 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:47.436753 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp191447372601"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m19:14:47.437400 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:14:47.438237 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:47.438837 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:47.837099 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:47.889541 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:47.891339 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m19:14:47.940627 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:47.941592 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:47.943039 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp191447372601'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp191447372601'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp191447372601'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:14:48.092117 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:48.141687 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:48.142836 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:48.288589 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:48.344824 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:48.345971 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:48.461574 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:48.501098 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m19:14:48.507075 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:48.507692 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp191447372601"
            where (
                
                    "dim_event_dtls__dbt_tmp191447372601".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m19:14:48.615627 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:48.617429 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:48.618995 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp191447372601"
    )
[0m19:14:48.701104 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:48.755940 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:14:48.757003 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:14:48.757672 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:14:49.268214 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:14:49.275223 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 19:14:47.304605 => 19:14:49.273888
[0m19:14:49.277617 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m19:14:49.282659 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '61255803-cdf8-4106-9b41-98e1355726e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd89001fd90>]}
[0m19:14:49.287390 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 1.99s]
[0m19:14:49.289902 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m19:14:49.294489 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:49.295712 [debug] [MainThread]: On master: BEGIN
[0m19:14:49.296699 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:14:49.298368 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:49.299951 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:49.639331 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:49.640826 [debug] [MainThread]: On master: COMMIT
[0m19:14:49.642104 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:49.643259 [debug] [MainThread]: On master: COMMIT
[0m19:14:49.691294 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:49.693060 [debug] [MainThread]: On master: Close
[0m19:14:49.696898 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:14:49.698749 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m19:14:49.701115 [info ] [MainThread]: 
[0m19:14:49.702793 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.09 seconds (4.09s).
[0m19:14:49.706299 [debug] [MainThread]: Command end result
[0m19:14:49.736983 [info ] [MainThread]: 
[0m19:14:49.738157 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:14:49.739113 [info ] [MainThread]: 
[0m19:14:49.740170 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:14:49.748414 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9782796, "process_user_time": 4.508257, "process_kernel_time": 0.391451, "process_mem_max_rss": "122400768", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:14:49.750636 [debug] [MainThread]: Command `dbt run` succeeded at 19:14:49.750333 after 4.98 seconds
[0m19:14:49.751368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8e1305d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8b00b8ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd8d1db8730>]}
[0m19:14:49.752150 [debug] [MainThread]: Flushing usage events
[0m19:14:56.285739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa370eddd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa381cfdf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa381d01700>]}


============================== 19:14:56.292163 | 83b032b2-737a-4c02-b037-2739f6071d33 ==============================
[0m19:14:56.292163 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:14:56.293069 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_group', 'send_anonymous_usage_stats': 'True'}
[0m19:14:56.749191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '83b032b2-737a-4c02-b037-2739f6071d33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa381cddf70>]}
[0m19:14:56.877342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '83b032b2-737a-4c02-b037-2739f6071d33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa371c7bb20>]}
[0m19:14:56.879690 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:14:56.897178 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:14:56.972584 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:14:56.973195 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:14:56.983453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '83b032b2-737a-4c02-b037-2739f6071d33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa38206fdf0>]}
[0m19:14:56.999184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '83b032b2-737a-4c02-b037-2739f6071d33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa381fc7730>]}
[0m19:14:56.999909 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:14:57.000412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '83b032b2-737a-4c02-b037-2739f6071d33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa381fc7670>]}
[0m19:14:57.002335 [info ] [MainThread]: 
[0m19:14:57.003389 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:14:57.004903 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:14:57.030776 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:14:57.031425 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:14:57.031892 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:14:57.036560 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:57.037070 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:57.537688 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:14:57.543895 [debug] [ThreadPool]: On list_dev: Close
[0m19:14:57.553899 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:14:57.577760 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:57.578658 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:14:57.579344 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:14:57.580368 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:57.581057 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:57.901249 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:57.902517 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:14:57.903433 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:14:57.971151 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:57.976034 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:14:58.028318 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:14:58.064260 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:58.065159 [debug] [MainThread]: On master: BEGIN
[0m19:14:58.065796 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:14:58.066908 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:58.067458 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:58.391109 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:58.392965 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:58.394546 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:14:58.491579 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:58.495759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '83b032b2-737a-4c02-b037-2739f6071d33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa36022de20>]}
[0m19:14:58.497191 [debug] [MainThread]: On master: ROLLBACK
[0m19:14:58.566645 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:58.568898 [debug] [MainThread]: On master: BEGIN
[0m19:14:58.590257 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:58.592139 [debug] [MainThread]: On master: COMMIT
[0m19:14:58.594074 [debug] [MainThread]: Using redshift connection "master"
[0m19:14:58.595050 [debug] [MainThread]: On master: COMMIT
[0m19:14:58.642854 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:58.644710 [debug] [MainThread]: On master: Close
[0m19:14:58.647808 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:14:58.649270 [info ] [MainThread]: 
[0m19:14:58.655100 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m19:14:58.656434 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m19:14:58.658344 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m19:14:58.659345 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m19:14:58.667919 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m19:14:58.669327 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 19:14:58.659833 => 19:14:58.668865
[0m19:14:58.670023 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m19:14:58.770791 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:14:58.771457 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp191458717954"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m19:14:58.771991 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:14:58.772704 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:14:58.773226 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:14:59.149812 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:59.197313 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:14:59.198214 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m19:14:59.242331 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:59.243429 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:14:59.244845 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp191458717954'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp191458717954'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp191458717954'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:14:59.393553 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:59.439427 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:14:59.440992 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:59.583439 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:59.637012 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:14:59.638092 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:14:59.756110 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:59.804180 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m19:14:59.810776 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:14:59.811765 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp191458717954"
            where (
                
                    "dim_group__dbt_tmp191458717954".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp191458717954".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m19:14:59.923013 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:14:59.924584 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:14:59.925930 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp191458717954"
    )
[0m19:15:00.008320 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:00.048182 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:15:00.049072 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:15:00.049790 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:15:00.632797 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:15:00.635893 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 19:14:58.670424 => 19:15:00.635295
[0m19:15:00.636977 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m19:15:00.639346 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83b032b2-737a-4c02-b037-2739f6071d33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3820f0d60>]}
[0m19:15:00.642231 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 1.98s]
[0m19:15:00.644918 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m19:15:00.648609 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:00.649713 [debug] [MainThread]: On master: BEGIN
[0m19:15:00.650490 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:15:00.651877 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:15:00.652834 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:15:00.975374 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:00.976669 [debug] [MainThread]: On master: COMMIT
[0m19:15:00.977928 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:00.979172 [debug] [MainThread]: On master: COMMIT
[0m19:15:01.027637 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:01.029458 [debug] [MainThread]: On master: Close
[0m19:15:01.033016 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:15:01.034446 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m19:15:01.036007 [info ] [MainThread]: 
[0m19:15:01.037604 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.03 seconds (4.03s).
[0m19:15:01.041053 [debug] [MainThread]: Command end result
[0m19:15:01.069050 [info ] [MainThread]: 
[0m19:15:01.070013 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:15:01.070693 [info ] [MainThread]: 
[0m19:15:01.071428 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:15:01.076112 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.905244, "process_user_time": 4.500686, "process_kernel_time": 0.380697, "process_mem_max_rss": "121839616", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:15:01.077424 [debug] [MainThread]: Command `dbt run` succeeded at 19:15:01.077144 after 4.91 seconds
[0m19:15:01.078187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa370eddd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3820f6b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3820f6a00>]}
[0m19:15:01.078959 [debug] [MainThread]: Flushing usage events
[0m19:15:07.696973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e104a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e1e11c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e1de32b0>]}


============================== 19:15:07.703416 | 49bc2df3-a1d9-42d7-a486-136b35d048ed ==============================
[0m19:15:07.703416 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:15:07.704208 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:15:08.132274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '49bc2df3-a1d9-42d7-a486-136b35d048ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e1dec070>]}
[0m19:15:08.273851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '49bc2df3-a1d9-42d7-a486-136b35d048ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e2002220>]}
[0m19:15:08.276236 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:15:08.299435 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:15:08.380491 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:15:08.381127 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:15:08.391535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49bc2df3-a1d9-42d7-a486-136b35d048ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3d041feb0>]}
[0m19:15:08.414299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49bc2df3-a1d9-42d7-a486-136b35d048ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4018987f0>]}
[0m19:15:08.415181 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:15:08.415759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49bc2df3-a1d9-42d7-a486-136b35d048ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc401898730>]}
[0m19:15:08.418031 [info ] [MainThread]: 
[0m19:15:08.419267 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:15:08.420919 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:15:08.452822 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:15:08.453512 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:15:08.454028 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:15:08.460178 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:15:08.461001 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:15:08.978084 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:15:08.983037 [debug] [ThreadPool]: On list_dev: Close
[0m19:15:08.990007 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:15:09.008495 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:15:09.009334 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:15:09.009972 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:15:09.010917 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:15:09.011591 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:15:09.336663 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:09.339433 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:15:09.340785 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:15:09.406883 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:09.413558 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:15:09.468358 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:15:09.510668 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:09.511554 [debug] [MainThread]: On master: BEGIN
[0m19:15:09.512187 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:15:09.513211 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:15:09.513899 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:15:09.866179 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:09.868104 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:09.869086 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:15:09.973183 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:09.977757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49bc2df3-a1d9-42d7-a486-136b35d048ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e205e8b0>]}
[0m19:15:09.979441 [debug] [MainThread]: On master: ROLLBACK
[0m19:15:10.051235 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:10.052441 [debug] [MainThread]: On master: BEGIN
[0m19:15:10.082906 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:10.084064 [debug] [MainThread]: On master: COMMIT
[0m19:15:10.085334 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:10.086622 [debug] [MainThread]: On master: COMMIT
[0m19:15:10.136753 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:10.138067 [debug] [MainThread]: On master: Close
[0m19:15:10.140807 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:15:10.142700 [info ] [MainThread]: 
[0m19:15:10.147363 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m19:15:10.148799 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m19:15:10.151469 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m19:15:10.152577 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m19:15:10.163959 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m19:15:10.165477 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 19:15:10.153313 => 19:15:10.165041
[0m19:15:10.166051 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m19:15:10.271202 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:10.271905 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp191510214449"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m19:15:10.272453 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:15:10.273197 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:15:10.273724 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:15:10.688568 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:10.742580 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:10.743488 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m19:15:10.789338 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:10.790894 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:10.792719 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp191510214449'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp191510214449'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp191510214449'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:15:10.944142 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:10.993265 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:10.994664 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:15:11.146488 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:11.175299 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:11.176278 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:15:11.291115 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:11.317585 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m19:15:11.324557 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:11.325287 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp191510214449"
            where (
                
                    "dim_outcome__dbt_tmp191510214449".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp191510214449".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp191510214449".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m19:15:11.445349 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:11.446807 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:11.447962 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp191510214449"
    )
[0m19:15:11.547205 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:11.592719 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:15:11.593662 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:15:11.594268 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:15:12.306595 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:15:12.310721 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 19:15:10.166392 => 19:15:12.309892
[0m19:15:12.312198 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m19:15:12.315639 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49bc2df3-a1d9-42d7-a486-136b35d048ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3f05b0100>]}
[0m19:15:12.319396 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.17s]
[0m19:15:12.322178 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m19:15:12.328057 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:12.329442 [debug] [MainThread]: On master: BEGIN
[0m19:15:12.330250 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:15:12.331918 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:15:12.333326 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:15:12.672098 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:12.673433 [debug] [MainThread]: On master: COMMIT
[0m19:15:12.674515 [debug] [MainThread]: Using redshift connection "master"
[0m19:15:12.675321 [debug] [MainThread]: On master: COMMIT
[0m19:15:12.726073 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:15:12.727220 [debug] [MainThread]: On master: Close
[0m19:15:12.729550 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:15:12.730405 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m19:15:12.731434 [info ] [MainThread]: 
[0m19:15:12.732445 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.31 seconds (4.31s).
[0m19:15:12.734479 [debug] [MainThread]: Command end result
[0m19:15:12.760664 [info ] [MainThread]: 
[0m19:15:12.761470 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:15:12.762061 [info ] [MainThread]: 
[0m19:15:12.762703 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:15:12.766892 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.1811147, "process_user_time": 4.566659, "process_kernel_time": 0.394891, "process_mem_max_rss": "123408384", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:15:12.768175 [debug] [MainThread]: Command `dbt run` succeeded at 19:15:12.767884 after 5.18 seconds
[0m19:15:12.769000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3e104a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc401950d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4019509a0>]}
[0m19:15:12.769844 [debug] [MainThread]: Flushing usage events
[0m19:24:11.934250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea60d9dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea6194bd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea61935e20>]}


============================== 19:24:11.942693 | 5774bee5-ad5c-41dd-ad21-cc3a9740f41f ==============================
[0m19:24:11.942693 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:24:11.943553 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_market', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:24:12.496455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5774bee5-ad5c-41dd-ad21-cc3a9740f41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea619237f0>]}
[0m19:24:12.619879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5774bee5-ad5c-41dd-ad21-cc3a9740f41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea71f7a5e0>]}
[0m19:24:12.622202 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:24:12.639211 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:24:12.711992 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:24:12.712586 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:24:12.723253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5774bee5-ad5c-41dd-ad21-cc3a9740f41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea505c7e20>]}
[0m19:24:12.741593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5774bee5-ad5c-41dd-ad21-cc3a9740f41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea721257c0>]}
[0m19:24:12.742421 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:24:12.742966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5774bee5-ad5c-41dd-ad21-cc3a9740f41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea721256d0>]}
[0m19:24:12.745238 [info ] [MainThread]: 
[0m19:24:12.746620 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:24:12.748217 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:24:12.776182 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:24:12.777531 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:24:12.778585 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:24:12.783553 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:12.784163 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:13.293779 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:24:13.300189 [debug] [ThreadPool]: On list_dev: Close
[0m19:24:13.306734 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:24:13.329668 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:13.330625 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:24:13.331277 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:24:13.332311 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:13.332915 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:13.664899 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:13.666854 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:13.667836 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:24:13.732053 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:13.738768 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:24:13.789036 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:24:13.816989 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:13.817838 [debug] [MainThread]: On master: BEGIN
[0m19:24:13.818394 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:24:13.819321 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:13.820031 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:14.147593 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:14.149112 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:14.150763 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:24:14.248449 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:14.253655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5774bee5-ad5c-41dd-ad21-cc3a9740f41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea50577880>]}
[0m19:24:14.255633 [debug] [MainThread]: On master: ROLLBACK
[0m19:24:14.318118 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:14.319682 [debug] [MainThread]: On master: BEGIN
[0m19:24:14.341218 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:14.342531 [debug] [MainThread]: On master: COMMIT
[0m19:24:14.343576 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:14.344381 [debug] [MainThread]: On master: COMMIT
[0m19:24:14.389543 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:14.390754 [debug] [MainThread]: On master: Close
[0m19:24:14.393196 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:24:14.394082 [info ] [MainThread]: 
[0m19:24:14.399177 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m19:24:14.400649 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m19:24:14.402669 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m19:24:14.404216 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m19:24:14.418002 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m19:24:14.419542 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 19:24:14.404918 => 19:24:14.419021
[0m19:24:14.420341 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m19:24:14.533785 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:14.534498 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp192414476391"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m19:24:14.535049 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:24:14.535789 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:14.536338 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:14.969012 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:15.005407 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:15.006131 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m19:24:15.052336 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:15.053134 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:15.053963 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp192414476391'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp192414476391'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp192414476391'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:24:15.201832 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:15.237574 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:15.238532 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:15.382194 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:15.434004 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:15.435071 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:15.550838 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:15.577422 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m19:24:15.582258 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:15.582836 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp192414476391"
            where (
                
                    "dim_market__dbt_tmp192414476391".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp192414476391".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m19:24:15.702243 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:15.703040 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:15.705035 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp192414476391"
    )
[0m19:24:15.787480 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:15.830815 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:24:15.831816 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:24:15.832494 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:24:16.466378 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:24:16.470488 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 19:24:14.420928 => 19:24:16.469745
[0m19:24:16.471811 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m19:24:16.474731 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5774bee5-ad5c-41dd-ad21-cc3a9740f41f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea40176cd0>]}
[0m19:24:16.477291 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.07s]
[0m19:24:16.480556 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m19:24:16.484589 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:16.485697 [debug] [MainThread]: On master: BEGIN
[0m19:24:16.486566 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:24:16.488018 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:16.489206 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:16.799220 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:16.800568 [debug] [MainThread]: On master: COMMIT
[0m19:24:16.802013 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:16.803479 [debug] [MainThread]: On master: COMMIT
[0m19:24:16.849275 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:16.851387 [debug] [MainThread]: On master: Close
[0m19:24:16.854792 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:24:16.855766 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m19:24:16.857028 [info ] [MainThread]: 
[0m19:24:16.858135 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.11 seconds (4.11s).
[0m19:24:16.860058 [debug] [MainThread]: Command end result
[0m19:24:16.882889 [info ] [MainThread]: 
[0m19:24:16.883863 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:24:16.884553 [info ] [MainThread]: 
[0m19:24:16.885307 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:24:16.890170 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0786457, "process_user_time": 4.443792, "process_kernel_time": 0.404596, "process_mem_max_rss": "121245696", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:24:16.891666 [debug] [MainThread]: Command `dbt run` succeeded at 19:24:16.891351 after 5.08 seconds
[0m19:24:16.892538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea60d9dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea5056e220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea506a69a0>]}
[0m19:24:16.893284 [debug] [MainThread]: Flushing usage events
[0m19:24:24.206499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc0f65670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcb06e42e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcb06f7370>]}


============================== 19:24:24.214554 | 0ba63b52-62b6-49dc-ad70-f7dad816d63e ==============================
[0m19:24:24.214554 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:24:24.215423 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_event', 'send_anonymous_usage_stats': 'True'}
[0m19:24:24.640618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0ba63b52-62b6-49dc-ad70-f7dad816d63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc916aefa0>]}
[0m19:24:24.762835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0ba63b52-62b6-49dc-ad70-f7dad816d63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc1b6b0a0>]}
[0m19:24:24.764686 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:24:24.781110 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:24:24.851345 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:24:24.851956 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:24:24.861748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ba63b52-62b6-49dc-ad70-f7dad816d63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcb07f7e20>]}
[0m19:24:24.877779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ba63b52-62b6-49dc-ad70-f7dad816d63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc918e7760>]}
[0m19:24:24.878507 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:24:24.879002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ba63b52-62b6-49dc-ad70-f7dad816d63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc918e76a0>]}
[0m19:24:24.880929 [info ] [MainThread]: 
[0m19:24:24.881986 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:24:24.883423 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:24:24.908362 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:24:24.908995 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:24:24.909462 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:24:24.913987 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:24.914495 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:25.396433 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:25.402826 [debug] [ThreadPool]: On list_dev: Close
[0m19:24:25.410017 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:24:25.436395 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:25.437389 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:24:25.438155 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:24:25.439299 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:25.440035 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:25.752920 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:25.754941 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:25.757254 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:24:25.823861 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:25.828759 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:24:25.880333 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:24:25.909890 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:25.910554 [debug] [MainThread]: On master: BEGIN
[0m19:24:25.911025 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:24:25.911701 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:25.912150 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:26.237013 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:26.238295 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:26.239384 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:24:26.336664 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:26.340830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ba63b52-62b6-49dc-ad70-f7dad816d63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc1c6f850>]}
[0m19:24:26.342594 [debug] [MainThread]: On master: ROLLBACK
[0m19:24:26.409632 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:26.411021 [debug] [MainThread]: On master: BEGIN
[0m19:24:26.433699 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:26.434858 [debug] [MainThread]: On master: COMMIT
[0m19:24:26.435918 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:26.436769 [debug] [MainThread]: On master: COMMIT
[0m19:24:26.483216 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:26.484584 [debug] [MainThread]: On master: Close
[0m19:24:26.487086 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:24:26.488530 [info ] [MainThread]: 
[0m19:24:26.493695 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m19:24:26.495154 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m19:24:26.497941 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m19:24:26.499384 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m19:24:26.506381 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m19:24:26.508209 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 19:24:26.500029 => 19:24:26.507830
[0m19:24:26.508752 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m19:24:26.612736 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:26.613477 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp192426557134"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m19:24:26.614036 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:24:26.614751 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:26.615271 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:26.998543 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:27.050728 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:27.051726 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m19:24:27.097539 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:27.098319 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:27.099183 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp192426557134'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp192426557134'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp192426557134'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:24:27.251937 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:27.283720 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:27.285024 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:27.430951 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:27.468605 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:27.469536 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:27.590666 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:27.635526 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m19:24:27.641736 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:27.642569 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp192426557134"
            where (
                
                    "dim_event__dbt_tmp192426557134".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m19:24:27.756799 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:27.758246 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:27.759274 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp192426557134"
    )
[0m19:24:27.843078 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:27.895759 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:24:27.896892 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:24:27.897630 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:24:28.446971 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:24:28.450657 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 19:24:26.509073 => 19:24:28.450039
[0m19:24:28.451711 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m19:24:28.454142 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0ba63b52-62b6-49dc-ad70-f7dad816d63e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcb0839fa0>]}
[0m19:24:28.456721 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 1.96s]
[0m19:24:28.458628 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m19:24:28.462293 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:28.463845 [debug] [MainThread]: On master: BEGIN
[0m19:24:28.464655 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:24:28.466260 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:28.467278 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:28.786136 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:28.787938 [debug] [MainThread]: On master: COMMIT
[0m19:24:28.789864 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:28.791061 [debug] [MainThread]: On master: COMMIT
[0m19:24:28.835569 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:28.837097 [debug] [MainThread]: On master: Close
[0m19:24:28.840266 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:24:28.841426 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m19:24:28.842682 [info ] [MainThread]: 
[0m19:24:28.844036 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.96 seconds (3.96s).
[0m19:24:28.845940 [debug] [MainThread]: Command end result
[0m19:24:28.870894 [info ] [MainThread]: 
[0m19:24:28.871976 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:24:28.872924 [info ] [MainThread]: 
[0m19:24:28.873773 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:24:28.878103 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7872257, "process_user_time": 4.602585, "process_kernel_time": 0.402316, "process_mem_max_rss": "127225856", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:24:28.879373 [debug] [MainThread]: Command `dbt run` succeeded at 19:24:28.879089 after 4.79 seconds
[0m19:24:28.880173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc0f65670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbc918e7130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc1d82c40>]}
[0m19:24:28.881019 [debug] [MainThread]: Flushing usage events
[0m19:24:35.626857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae38f21bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae39c55ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae39c3e5b0>]}


============================== 19:24:35.633376 | 08734c59-e216-46b2-ab7b-b45ff3d18641 ==============================
[0m19:24:35.633376 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:24:35.634173 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_participant', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:24:36.078626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '08734c59-e216-46b2-ab7b-b45ff3d18641', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae39c2c700>]}
[0m19:24:36.197777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '08734c59-e216-46b2-ab7b-b45ff3d18641', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae39c35ac0>]}
[0m19:24:36.199823 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:24:36.215205 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:24:36.284229 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:24:36.284792 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:24:36.294310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '08734c59-e216-46b2-ab7b-b45ff3d18641', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae39ec7df0>]}
[0m19:24:36.309610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '08734c59-e216-46b2-ab7b-b45ff3d18641', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae29baf790>]}
[0m19:24:36.310293 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:24:36.310792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '08734c59-e216-46b2-ab7b-b45ff3d18641', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae29baf6a0>]}
[0m19:24:36.312663 [info ] [MainThread]: 
[0m19:24:36.313723 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:24:36.315186 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:24:36.339430 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:24:36.339947 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:24:36.340398 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:24:36.344913 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:36.345412 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:36.826684 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:36.836163 [debug] [ThreadPool]: On list_dev: Close
[0m19:24:36.844366 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:24:36.866243 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:36.867155 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:24:36.867783 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:24:36.868744 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:36.869429 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:37.193864 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:37.197097 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:37.199155 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:24:37.266187 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:37.276937 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:24:37.330108 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:24:37.351276 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:37.351861 [debug] [MainThread]: On master: BEGIN
[0m19:24:37.352329 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:24:37.353071 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:37.353597 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:37.681375 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:37.684026 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:37.686361 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:24:37.785248 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:37.793910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '08734c59-e216-46b2-ab7b-b45ff3d18641', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae29948f40>]}
[0m19:24:37.796101 [debug] [MainThread]: On master: ROLLBACK
[0m19:24:37.864866 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:37.867592 [debug] [MainThread]: On master: BEGIN
[0m19:24:37.893102 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:37.896001 [debug] [MainThread]: On master: COMMIT
[0m19:24:37.898423 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:37.900257 [debug] [MainThread]: On master: COMMIT
[0m19:24:37.949308 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:37.951731 [debug] [MainThread]: On master: Close
[0m19:24:37.956726 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:24:37.958705 [info ] [MainThread]: 
[0m19:24:37.968370 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m19:24:37.970794 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m19:24:37.973736 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m19:24:37.975095 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m19:24:37.988372 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m19:24:37.990569 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 19:24:37.975839 => 19:24:37.989882
[0m19:24:37.991575 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m19:24:38.095109 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:38.095841 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp192438043220"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m19:24:38.096390 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:24:38.097120 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:38.097655 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:38.489434 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:38.541753 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:38.542629 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m19:24:38.590801 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:38.591766 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:38.592944 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp192438043220'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp192438043220'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp192438043220'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:24:38.748154 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:38.797317 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:38.798561 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:38.949986 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:39.009480 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:39.010590 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:39.127363 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:39.172451 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m19:24:39.178473 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:39.179259 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp192438043220"
            where (
                
                    "dim_participant__dbt_tmp192438043220".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp192438043220".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m19:24:39.304292 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:39.306709 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:39.308195 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp192438043220"
    )
[0m19:24:39.390797 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:39.428788 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:24:39.429777 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:24:39.430364 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:24:40.119507 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:24:40.123043 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 19:24:37.992209 => 19:24:40.122404
[0m19:24:40.124226 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m19:24:40.126848 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '08734c59-e216-46b2-ab7b-b45ff3d18641', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae29a98af0>]}
[0m19:24:40.129393 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 2.15s]
[0m19:24:40.131205 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m19:24:40.134994 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:40.136079 [debug] [MainThread]: On master: BEGIN
[0m19:24:40.137078 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:24:40.139378 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:40.140906 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:40.475403 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:40.476620 [debug] [MainThread]: On master: COMMIT
[0m19:24:40.477684 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:40.478563 [debug] [MainThread]: On master: COMMIT
[0m19:24:40.525235 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:40.526579 [debug] [MainThread]: On master: Close
[0m19:24:40.528968 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:24:40.530039 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m19:24:40.531158 [info ] [MainThread]: 
[0m19:24:40.532262 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.22 seconds (4.22s).
[0m19:24:40.535003 [debug] [MainThread]: Command end result
[0m19:24:40.560812 [info ] [MainThread]: 
[0m19:24:40.561852 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:24:40.562557 [info ] [MainThread]: 
[0m19:24:40.563319 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:24:40.567760 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0476036, "process_user_time": 4.529075, "process_kernel_time": 0.392898, "process_mem_max_rss": "127037440", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:24:40.569122 [debug] [MainThread]: Command `dbt run` succeeded at 19:24:40.568819 after 5.05 seconds
[0m19:24:40.569989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae38f21bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae39edcc40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae39edce20>]}
[0m19:24:40.570852 [debug] [MainThread]: Flushing usage events
[0m19:24:49.895687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d88ef1bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d997d5ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d997be5b0>]}


============================== 19:24:49.901975 | e88ad971-f3da-41ee-b034-88f9f8849b5f ==============================
[0m19:24:49.901975 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:24:49.902763 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_event_dtls', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:24:50.476605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e88ad971-f3da-41ee-b034-88f9f8849b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d997ac700>]}
[0m19:24:50.594991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e88ad971-f3da-41ee-b034-88f9f8849b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d997b5ac0>]}
[0m19:24:50.597235 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:24:50.613118 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:24:50.685080 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:24:50.685698 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:24:50.695513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e88ad971-f3da-41ee-b034-88f9f8849b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d7831fdf0>]}
[0m19:24:50.711970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e88ad971-f3da-41ee-b034-88f9f8849b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d99a1f790>]}
[0m19:24:50.712685 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:24:50.713193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e88ad971-f3da-41ee-b034-88f9f8849b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d99a1f6a0>]}
[0m19:24:50.715075 [info ] [MainThread]: 
[0m19:24:50.716121 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:24:50.717556 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:24:50.742118 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:24:50.742724 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:24:50.743202 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:24:50.747654 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:50.748160 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:51.240642 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:51.242949 [debug] [ThreadPool]: On list_dev: Close
[0m19:24:51.245544 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:24:51.256972 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:51.257661 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:24:51.258111 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:24:51.258777 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:51.259238 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:51.586495 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:51.589282 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:24:51.590744 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:24:51.652828 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:51.656368 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:24:51.706622 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:24:51.738333 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:51.739254 [debug] [MainThread]: On master: BEGIN
[0m19:24:51.739925 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:24:51.740865 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:51.741603 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:52.067519 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:52.069134 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:52.070429 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:24:52.166630 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:52.170355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e88ad971-f3da-41ee-b034-88f9f8849b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d78498f40>]}
[0m19:24:52.171978 [debug] [MainThread]: On master: ROLLBACK
[0m19:24:52.238257 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:52.239399 [debug] [MainThread]: On master: BEGIN
[0m19:24:52.261192 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:52.262437 [debug] [MainThread]: On master: COMMIT
[0m19:24:52.263480 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:52.264965 [debug] [MainThread]: On master: COMMIT
[0m19:24:52.308946 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:52.310206 [debug] [MainThread]: On master: Close
[0m19:24:52.312501 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:24:52.313413 [info ] [MainThread]: 
[0m19:24:52.318558 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m19:24:52.320145 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m19:24:52.322532 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m19:24:52.323779 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m19:24:52.335717 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m19:24:52.337685 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 19:24:52.324406 => 19:24:52.336997
[0m19:24:52.338430 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m19:24:52.441154 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:52.442372 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp192452387823"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m19:24:52.442982 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:24:52.443732 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:52.444268 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:52.824259 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:52.871729 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:52.872889 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m19:24:52.922173 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:52.923295 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:52.924532 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp192452387823'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp192452387823'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp192452387823'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:24:53.076149 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:53.119769 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:53.121861 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:53.291174 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:53.345631 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:53.346891 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:24:53.464175 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:53.515195 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m19:24:53.522616 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:53.523624 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp192452387823"
            where (
                
                    "dim_event_dtls__dbt_tmp192452387823".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m19:24:53.636097 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:53.637833 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:53.639395 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp192452387823"
    )
[0m19:24:53.723067 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:53.759107 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:24:53.760059 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:24:53.760662 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:24:54.355446 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:24:54.359559 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 19:24:52.338791 => 19:24:54.358602
[0m19:24:54.361189 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m19:24:54.364593 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e88ad971-f3da-41ee-b034-88f9f8849b5f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d6859a8e0>]}
[0m19:24:54.367898 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.04s]
[0m19:24:54.370757 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m19:24:54.374671 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:54.375591 [debug] [MainThread]: On master: BEGIN
[0m19:24:54.376529 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:24:54.377380 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:24:54.377861 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:24:54.688128 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:54.689691 [debug] [MainThread]: On master: COMMIT
[0m19:24:54.691103 [debug] [MainThread]: Using redshift connection "master"
[0m19:24:54.692105 [debug] [MainThread]: On master: COMMIT
[0m19:24:54.739395 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:24:54.740499 [debug] [MainThread]: On master: Close
[0m19:24:54.742159 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:24:54.743115 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m19:24:54.743955 [info ] [MainThread]: 
[0m19:24:54.744573 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.03 seconds (4.03s).
[0m19:24:54.745959 [debug] [MainThread]: Command end result
[0m19:24:54.762998 [info ] [MainThread]: 
[0m19:24:54.763761 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:24:54.764287 [info ] [MainThread]: 
[0m19:24:54.765125 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:24:54.768863 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9800076, "process_user_time": 4.487449, "process_kernel_time": 0.406656, "process_mem_max_rss": "120922112", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:24:54.770059 [debug] [MainThread]: Command `dbt run` succeeded at 19:24:54.769799 after 4.98 seconds
[0m19:24:54.771093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d88ef1bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d8a124f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d8a0a5be0>]}
[0m19:24:54.772241 [debug] [MainThread]: Flushing usage events
[0m19:25:01.773963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f030a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f0609c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f05da2b0>]}


============================== 19:25:01.781471 | 5fd08dd1-8a88-4d33-9413-adaccb179e72 ==============================
[0m19:25:01.781471 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:25:01.782407 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_group', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:25:02.456187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5fd08dd1-8a88-4d33-9413-adaccb179e72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f05e4070>]}
[0m19:25:02.581759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5fd08dd1-8a88-4d33-9413-adaccb179e72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f06fb220>]}
[0m19:25:02.583342 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:25:02.600238 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:25:02.671619 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:25:02.672442 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:25:02.682330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fd08dd1-8a88-4d33-9413-adaccb179e72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f0937eb0>]}
[0m19:25:02.699559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fd08dd1-8a88-4d33-9413-adaccb179e72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f08507f0>]}
[0m19:25:02.700302 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:25:02.700805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fd08dd1-8a88-4d33-9413-adaccb179e72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f0850730>]}
[0m19:25:02.702986 [info ] [MainThread]: 
[0m19:25:02.705314 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:25:02.707100 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:25:02.732956 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:25:02.733569 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:25:02.734026 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:25:02.739286 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:02.739965 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:03.251865 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:25:03.257831 [debug] [ThreadPool]: On list_dev: Close
[0m19:25:03.263402 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:25:03.282880 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:25:03.283651 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:25:03.284211 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:25:03.285124 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:03.285733 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:03.620908 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:03.622074 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:25:03.622994 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:25:03.694604 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:03.701922 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:25:03.756649 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:25:03.799447 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:03.800418 [debug] [MainThread]: On master: BEGIN
[0m19:25:03.801070 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:25:03.802100 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:03.802802 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:04.145339 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:04.146761 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:04.147959 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:25:04.244937 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:04.251726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fd08dd1-8a88-4d33-9413-adaccb179e72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f07558b0>]}
[0m19:25:04.253625 [debug] [MainThread]: On master: ROLLBACK
[0m19:25:04.323999 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:04.325635 [debug] [MainThread]: On master: BEGIN
[0m19:25:04.348999 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:04.350772 [debug] [MainThread]: On master: COMMIT
[0m19:25:04.352160 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:04.353203 [debug] [MainThread]: On master: COMMIT
[0m19:25:04.404825 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:04.406113 [debug] [MainThread]: On master: Close
[0m19:25:04.408904 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:25:04.410008 [info ] [MainThread]: 
[0m19:25:04.417631 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m19:25:04.419811 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m19:25:04.422670 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m19:25:04.423938 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m19:25:04.436897 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m19:25:04.438906 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 19:25:04.424585 => 19:25:04.438248
[0m19:25:04.439924 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m19:25:04.544010 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:04.544695 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp192504491829"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m19:25:04.545242 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:25:04.545966 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:04.546483 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:04.927872 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:04.981510 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:04.982468 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m19:25:05.031813 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:05.032843 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:05.034154 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp192504491829'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp192504491829'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp192504491829'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:25:05.184104 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:05.231873 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:05.233093 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:25:05.378602 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:05.435481 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:05.436637 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:25:05.554716 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:05.611773 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m19:25:05.618439 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:05.619095 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp192504491829"
            where (
                
                    "dim_group__dbt_tmp192504491829".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp192504491829".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m19:25:05.739625 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:05.741174 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:05.742185 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp192504491829"
    )
[0m19:25:05.817857 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:05.864578 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:25:05.865593 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:25:05.866265 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:25:06.643780 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:25:06.649087 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 19:25:04.440424 => 19:25:06.647998
[0m19:25:06.650472 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m19:25:06.652390 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fd08dd1-8a88-4d33-9413-adaccb179e72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f0996d00>]}
[0m19:25:06.653817 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.23s]
[0m19:25:06.654672 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m19:25:06.656545 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:06.657049 [debug] [MainThread]: On master: BEGIN
[0m19:25:06.657489 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:25:06.658226 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:06.658745 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:06.986859 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:06.989078 [debug] [MainThread]: On master: COMMIT
[0m19:25:06.990946 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:06.991802 [debug] [MainThread]: On master: COMMIT
[0m19:25:07.040886 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:07.042173 [debug] [MainThread]: On master: Close
[0m19:25:07.044159 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:25:07.044966 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m19:25:07.045924 [info ] [MainThread]: 
[0m19:25:07.046844 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.34 seconds (4.34s).
[0m19:25:07.048499 [debug] [MainThread]: Command end result
[0m19:25:07.066988 [info ] [MainThread]: 
[0m19:25:07.067745 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:25:07.068262 [info ] [MainThread]: 
[0m19:25:07.068829 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:25:07.072703 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.4382544, "process_user_time": 4.877253, "process_kernel_time": 0.423433, "process_mem_max_rss": "121421824", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:25:07.073880 [debug] [MainThread]: Command `dbt run` succeeded at 19:25:07.073671 after 5.44 seconds
[0m19:25:07.074462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f030a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f0850760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f09b86d0>]}
[0m19:25:07.075042 [debug] [MainThread]: Flushing usage events
[0m19:25:14.423169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec985216d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fecb8dd4f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fecb8dc0be0>]}


============================== 19:25:14.430690 | 15b42fbf-98aa-49c1-ad60-acc4b44a29e8 ==============================
[0m19:25:14.430690 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:25:14.431609 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m19:25:15.065795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '15b42fbf-98aa-49c1-ad60-acc4b44a29e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fecb8daa370>]}
[0m19:25:15.277587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '15b42fbf-98aa-49c1-ad60-acc4b44a29e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec98c18130>]}
[0m19:25:15.280377 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:25:15.307205 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:25:15.398537 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:25:15.399192 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:25:15.410665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15b42fbf-98aa-49c1-ad60-acc4b44a29e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fecb8f87e50>]}
[0m19:25:15.428988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '15b42fbf-98aa-49c1-ad60-acc4b44a29e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca9af76a0>]}
[0m19:25:15.429824 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:25:15.430428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15b42fbf-98aa-49c1-ad60-acc4b44a29e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca9af7610>]}
[0m19:25:15.432627 [info ] [MainThread]: 
[0m19:25:15.433823 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:25:15.435569 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:25:15.465355 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:25:15.466033 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:25:15.466550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:25:15.472500 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:15.473481 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:16.018830 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:25:16.022637 [debug] [ThreadPool]: On list_dev: Close
[0m19:25:16.027541 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:25:16.041918 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:25:16.042622 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:25:16.043107 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:25:16.043873 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:16.044398 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:16.380208 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:16.381890 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:25:16.383200 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:25:16.449084 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:16.455271 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:25:16.508890 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:25:16.542929 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:16.543847 [debug] [MainThread]: On master: BEGIN
[0m19:25:16.544443 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:25:16.545482 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:16.546204 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:16.873656 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:16.874955 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:16.875972 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:25:16.970167 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:16.974721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '15b42fbf-98aa-49c1-ad60-acc4b44a29e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fecb8f5c370>]}
[0m19:25:16.976425 [debug] [MainThread]: On master: ROLLBACK
[0m19:25:17.040455 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:17.042319 [debug] [MainThread]: On master: BEGIN
[0m19:25:17.065851 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:17.067374 [debug] [MainThread]: On master: COMMIT
[0m19:25:17.068879 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:17.070429 [debug] [MainThread]: On master: COMMIT
[0m19:25:17.115960 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:17.117436 [debug] [MainThread]: On master: Close
[0m19:25:17.121368 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:25:17.122745 [info ] [MainThread]: 
[0m19:25:17.128489 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m19:25:17.130812 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m19:25:17.133703 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m19:25:17.135191 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m19:25:17.147992 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m19:25:17.149541 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 19:25:17.136214 => 19:25:17.149061
[0m19:25:17.150249 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m19:25:17.266405 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:17.267118 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp192517206707"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m19:25:17.267668 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:25:17.268417 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:17.268969 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:17.666539 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:17.712815 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:17.713805 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m19:25:17.761282 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:17.762733 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:17.764561 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp192517206707'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp192517206707'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp192517206707'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:25:17.915821 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:17.953031 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:17.954159 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:25:18.099781 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:18.148214 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:18.149432 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:25:18.267702 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:18.319350 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m19:25:18.325988 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:18.326670 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp192517206707"
            where (
                
                    "dim_outcome__dbt_tmp192517206707".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp192517206707".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp192517206707".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m19:25:18.443858 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:18.445388 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:18.446771 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp192517206707"
    )
[0m19:25:18.563100 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:18.615171 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:25:18.616263 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:25:18.616937 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:25:19.182300 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:25:19.187427 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 19:25:17.150666 => 19:25:19.186551
[0m19:25:19.189080 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m19:25:19.191977 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15b42fbf-98aa-49c1-ad60-acc4b44a29e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec7003acd0>]}
[0m19:25:19.195077 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.06s]
[0m19:25:19.197003 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m19:25:19.201925 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:19.203743 [debug] [MainThread]: On master: BEGIN
[0m19:25:19.205240 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:25:19.206623 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:25:19.207513 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:25:19.532890 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:19.534979 [debug] [MainThread]: On master: COMMIT
[0m19:25:19.536604 [debug] [MainThread]: Using redshift connection "master"
[0m19:25:19.538319 [debug] [MainThread]: On master: COMMIT
[0m19:25:19.585219 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:25:19.587147 [debug] [MainThread]: On master: Close
[0m19:25:19.590631 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:25:19.591812 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m19:25:19.593220 [info ] [MainThread]: 
[0m19:25:19.594264 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.16 seconds (4.16s).
[0m19:25:19.596511 [debug] [MainThread]: Command end result
[0m19:25:19.625526 [info ] [MainThread]: 
[0m19:25:19.626549 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:25:19.627245 [info ] [MainThread]: 
[0m19:25:19.628002 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:25:19.632536 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3606167, "process_user_time": 5.474624, "process_kernel_time": 0.493138, "process_mem_max_rss": "120274944", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:25:19.633669 [debug] [MainThread]: Command `dbt run` succeeded at 19:25:19.633401 after 5.36 seconds
[0m19:25:19.634387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec985216d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca9af7370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca9af7850>]}
[0m19:25:19.635111 [debug] [MainThread]: Flushing usage events
[0m19:33:55.752115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c913d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b970cd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b96f5e20>]}


============================== 19:33:55.758548 | d39945f5-ace5-4beb-96d1-937d00d6e870 ==============================
[0m19:33:55.758548 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:33:55.759345 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_market', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:33:56.294154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd39945f5-ace5-4beb-96d1-937d00d6e870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b96e47f0>]}
[0m19:33:56.415610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd39945f5-ace5-4beb-96d1-937d00d6e870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b99225e0>]}
[0m19:33:56.417726 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:33:56.433877 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:33:56.505021 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:33:56.505637 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:33:56.515160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd39945f5-ace5-4beb-96d1-937d00d6e870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c9d4fe20>]}
[0m19:33:56.532510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd39945f5-ace5-4beb-96d1-937d00d6e870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c9c657c0>]}
[0m19:33:56.533258 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:33:56.533756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd39945f5-ace5-4beb-96d1-937d00d6e870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c9c656d0>]}
[0m19:33:56.535802 [info ] [MainThread]: 
[0m19:33:56.537048 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:33:56.538637 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:33:56.563479 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:33:56.564071 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:33:56.564536 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:33:56.569126 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:33:56.569717 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:33:57.064329 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:57.067793 [debug] [ThreadPool]: On list_dev: Close
[0m19:33:57.071504 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:33:57.085040 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:33:57.085718 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:33:57.086154 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:33:57.086825 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:33:57.087289 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:33:57.413329 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:57.415501 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:33:57.416726 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:33:57.482880 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:57.488656 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:33:57.538057 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:33:57.579820 [debug] [MainThread]: Using redshift connection "master"
[0m19:33:57.580752 [debug] [MainThread]: On master: BEGIN
[0m19:33:57.581399 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:33:57.582408 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:33:57.583090 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:33:57.929032 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:57.931588 [debug] [MainThread]: Using redshift connection "master"
[0m19:33:57.932934 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:33:58.046151 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:58.050955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd39945f5-ace5-4beb-96d1-937d00d6e870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c9abee50>]}
[0m19:33:58.051969 [debug] [MainThread]: On master: ROLLBACK
[0m19:33:58.121053 [debug] [MainThread]: Using redshift connection "master"
[0m19:33:58.121666 [debug] [MainThread]: On master: BEGIN
[0m19:33:58.147830 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:58.148481 [debug] [MainThread]: On master: COMMIT
[0m19:33:58.149037 [debug] [MainThread]: Using redshift connection "master"
[0m19:33:58.149475 [debug] [MainThread]: On master: COMMIT
[0m19:33:58.195398 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:58.196360 [debug] [MainThread]: On master: Close
[0m19:33:58.198226 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:33:58.198920 [info ] [MainThread]: 
[0m19:33:58.203043 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m19:33:58.203882 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m19:33:58.204880 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m19:33:58.205422 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m19:33:58.212326 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m19:33:58.213572 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 19:33:58.205752 => 19:33:58.213132
[0m19:33:58.214252 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m19:33:58.315276 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:58.316007 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp193358261229"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m19:33:58.316576 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:33:58.317340 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:33:58.317875 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:33:58.695233 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:58.743335 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:58.744218 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m19:33:58.790771 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:58.791733 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:58.792906 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp193358261229'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp193358261229'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp193358261229'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:33:58.941557 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:58.991289 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:58.992675 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:33:59.136214 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:59.187673 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:59.188824 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:33:59.304387 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:59.361070 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m19:33:59.367960 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:59.368646 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp193358261229"
            where (
                
                    "dim_market__dbt_tmp193358261229".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp193358261229".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m19:33:59.490576 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:59.492379 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:59.493759 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp193358261229"
    )
[0m19:33:59.586179 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:33:59.637754 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:33:59.638829 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m19:33:59.639521 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m19:34:00.153345 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:00.158310 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 19:33:58.214655 => 19:34:00.157335
[0m19:34:00.159945 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m19:34:00.163466 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd39945f5-ace5-4beb-96d1-937d00d6e870', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8a86e3c40>]}
[0m19:34:00.166282 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 1.96s]
[0m19:34:00.168028 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m19:34:00.171756 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:00.172814 [debug] [MainThread]: On master: BEGIN
[0m19:34:00.173799 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:00.175021 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:00.175662 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:00.503744 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:00.505456 [debug] [MainThread]: On master: COMMIT
[0m19:34:00.506755 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:00.507569 [debug] [MainThread]: On master: COMMIT
[0m19:34:00.556113 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:00.557903 [debug] [MainThread]: On master: Close
[0m19:34:00.561961 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:00.563899 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m19:34:00.565693 [info ] [MainThread]: 
[0m19:34:00.567160 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.03 seconds (4.03s).
[0m19:34:00.570744 [debug] [MainThread]: Command end result
[0m19:34:00.602759 [info ] [MainThread]: 
[0m19:34:00.603726 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:34:00.604359 [info ] [MainThread]: 
[0m19:34:00.605027 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:34:00.609362 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9628377, "process_user_time": 4.546331, "process_kernel_time": 0.422331, "process_mem_max_rss": "121405440", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:00.610484 [debug] [MainThread]: Command `dbt run` succeeded at 19:34:00.610217 after 4.96 seconds
[0m19:34:00.611200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c913d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b9a5f070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c9d95910>]}
[0m19:34:00.611931 [debug] [MainThread]: Flushing usage events
[0m19:34:07.358313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff640afdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6520aef70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff652099ac0>]}


============================== 19:34:07.364874 | f55eb249-5db7-4a9c-820b-049ad0d871cd ==============================
[0m19:34:07.364874 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:34:07.365719 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_event', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:34:07.779498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f55eb249-5db7-4a9c-820b-049ad0d871cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff652082400>]}
[0m19:34:07.898295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f55eb249-5db7-4a9c-820b-049ad0d871cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff65232af10>]}
[0m19:34:07.899860 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:34:07.915415 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:34:07.981526 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:07.982121 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:07.991705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f55eb249-5db7-4a9c-820b-049ad0d871cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff64167fe50>]}
[0m19:34:08.006747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f55eb249-5db7-4a9c-820b-049ad0d871cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6525b7790>]}
[0m19:34:08.007444 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:34:08.007942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f55eb249-5db7-4a9c-820b-049ad0d871cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6525b76d0>]}
[0m19:34:08.009805 [info ] [MainThread]: 
[0m19:34:08.010853 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:34:08.012267 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:34:08.036585 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:34:08.037144 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:34:08.037616 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:08.042149 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:08.042651 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:08.560789 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:08.568249 [debug] [ThreadPool]: On list_dev: Close
[0m19:34:08.574671 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:34:08.599311 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:08.600199 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:34:08.600836 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:34:08.601798 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:08.602493 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:08.935802 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:08.937820 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:08.939769 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:34:09.011052 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:09.018680 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:34:09.070121 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:34:09.109900 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:09.110904 [debug] [MainThread]: On master: BEGIN
[0m19:34:09.111581 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:09.112588 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:09.113279 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:09.439562 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:09.441422 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:09.442640 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:34:09.544763 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:09.552645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f55eb249-5db7-4a9c-820b-049ad0d871cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff65234c0a0>]}
[0m19:34:09.554492 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:09.624450 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:09.627142 [debug] [MainThread]: On master: BEGIN
[0m19:34:09.651639 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:09.653182 [debug] [MainThread]: On master: COMMIT
[0m19:34:09.654301 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:09.655145 [debug] [MainThread]: On master: COMMIT
[0m19:34:09.702014 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:09.703458 [debug] [MainThread]: On master: Close
[0m19:34:09.706412 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:09.707695 [info ] [MainThread]: 
[0m19:34:09.713157 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m19:34:09.715678 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m19:34:09.718644 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m19:34:09.719960 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m19:34:09.734213 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m19:34:09.736765 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 19:34:09.720584 => 19:34:09.736089
[0m19:34:09.737818 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m19:34:09.842261 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:09.842941 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp193409790669"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m19:34:09.843486 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:34:09.844203 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:09.844735 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:10.224120 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:10.280794 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:10.281708 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m19:34:10.330718 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:10.331928 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:10.333604 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp193409790669'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp193409790669'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp193409790669'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:34:10.483147 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:10.505628 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:10.506559 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:10.655572 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:10.699551 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:10.700546 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:10.819045 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:10.867292 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m19:34:10.872161 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:10.872807 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp193409790669"
            where (
                
                    "dim_event__dbt_tmp193409790669".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m19:34:10.983260 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:10.985222 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:10.986853 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp193409790669"
    )
[0m19:34:11.068888 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:11.117141 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:34:11.118152 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m19:34:11.118826 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m19:34:11.723057 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:11.728823 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 19:34:09.738435 => 19:34:11.727836
[0m19:34:11.730551 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m19:34:11.735297 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f55eb249-5db7-4a9c-820b-049ad0d871cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6417361c0>]}
[0m19:34:11.738398 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.02s]
[0m19:34:11.740135 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m19:34:11.745138 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:11.746713 [debug] [MainThread]: On master: BEGIN
[0m19:34:11.747869 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:11.749728 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:11.751665 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:12.083534 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:12.085779 [debug] [MainThread]: On master: COMMIT
[0m19:34:12.087128 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:12.088013 [debug] [MainThread]: On master: COMMIT
[0m19:34:12.134918 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:12.136715 [debug] [MainThread]: On master: Close
[0m19:34:12.139391 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:12.140479 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m19:34:12.141767 [info ] [MainThread]: 
[0m19:34:12.143457 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.13 seconds (4.13s).
[0m19:34:12.147987 [debug] [MainThread]: Command end result
[0m19:34:12.175849 [info ] [MainThread]: 
[0m19:34:12.176785 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:34:12.177473 [info ] [MainThread]: 
[0m19:34:12.178236 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:34:12.182442 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.937698, "process_user_time": 4.514925, "process_kernel_time": 0.376604, "process_mem_max_rss": "121491456", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:12.183506 [debug] [MainThread]: Command `dbt run` succeeded at 19:34:12.183260 after 4.94 seconds
[0m19:34:12.184234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff640afdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff61004a520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff652710880>]}
[0m19:34:12.184954 [debug] [MainThread]: Flushing usage events
[0m19:34:18.678418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa498a196d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa489131d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4994994f0>]}


============================== 19:34:18.684620 | edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9 ==============================
[0m19:34:18.684620 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:34:18.685439 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_participant', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:34:19.133784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa499494550>]}
[0m19:34:19.253690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa49969d490>]}
[0m19:34:19.255928 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:34:19.271587 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:34:19.339129 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:19.339697 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:19.349156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa499807dc0>]}
[0m19:34:19.365226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48a92f760>]}
[0m19:34:19.365918 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:34:19.366424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48a92f670>]}
[0m19:34:19.368310 [info ] [MainThread]: 
[0m19:34:19.369399 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:34:19.370898 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:34:19.395470 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:34:19.395991 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:34:19.396447 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:19.400900 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:19.401401 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:19.872332 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:19.875821 [debug] [ThreadPool]: On list_dev: Close
[0m19:34:19.881941 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:34:19.908345 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:19.909214 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:34:19.909875 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:34:19.910901 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:19.911624 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:20.235423 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:20.236729 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:20.237657 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:34:20.310148 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:20.319111 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:34:20.369927 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:34:20.407773 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:20.408775 [debug] [MainThread]: On master: BEGIN
[0m19:34:20.409444 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:20.410476 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:20.411178 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:20.742006 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:20.744159 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:20.746272 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:34:20.852980 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:20.858280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa49974cc70>]}
[0m19:34:20.860931 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:20.930784 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:20.932366 [debug] [MainThread]: On master: BEGIN
[0m19:34:20.955115 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:20.956756 [debug] [MainThread]: On master: COMMIT
[0m19:34:20.958079 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:20.958957 [debug] [MainThread]: On master: COMMIT
[0m19:34:21.008460 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:21.010677 [debug] [MainThread]: On master: Close
[0m19:34:21.015369 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:21.016933 [info ] [MainThread]: 
[0m19:34:21.024326 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m19:34:21.026463 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m19:34:21.029124 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m19:34:21.030296 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m19:34:21.042907 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m19:34:21.045450 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 19:34:21.030970 => 19:34:21.044776
[0m19:34:21.046322 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m19:34:21.149095 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:21.149787 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp193421097188"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m19:34:21.150342 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:34:21.151081 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:21.151616 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:21.558787 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:21.599510 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:21.600276 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m19:34:21.648037 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:21.649001 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:21.650389 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp193421097188'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp193421097188'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp193421097188'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:34:21.799973 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:21.847304 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:21.848474 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:21.996639 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:22.051865 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:22.053051 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:22.167919 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:22.201149 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m19:34:22.205751 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:22.206340 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp193421097188"
            where (
                
                    "dim_participant__dbt_tmp193421097188".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp193421097188".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m19:34:22.323949 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:22.325785 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:22.327288 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp193421097188"
    )
[0m19:34:22.405668 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:22.452705 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:34:22.453682 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m19:34:22.454297 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m19:34:23.194680 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:23.199418 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 19:34:21.046805 => 19:34:23.198577
[0m19:34:23.200694 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m19:34:23.203212 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'edfc53a4-544a-4cd4-a04e-5fb4b3ab58e9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa499793eb0>]}
[0m19:34:23.206066 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 2.18s]
[0m19:34:23.207659 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m19:34:23.210816 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:23.211606 [debug] [MainThread]: On master: BEGIN
[0m19:34:23.212274 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:23.213530 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:23.214233 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:23.540957 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:23.543189 [debug] [MainThread]: On master: COMMIT
[0m19:34:23.545217 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:23.546671 [debug] [MainThread]: On master: COMMIT
[0m19:34:23.598320 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:23.601462 [debug] [MainThread]: On master: Close
[0m19:34:23.604507 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:23.605401 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m19:34:23.606652 [info ] [MainThread]: 
[0m19:34:23.607785 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.24 seconds (4.24s).
[0m19:34:23.610303 [debug] [MainThread]: Command end result
[0m19:34:23.634992 [info ] [MainThread]: 
[0m19:34:23.635847 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:34:23.636437 [info ] [MainThread]: 
[0m19:34:23.637106 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:34:23.641186 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.075642, "process_user_time": 4.474001, "process_kernel_time": 0.392353, "process_mem_max_rss": "118906880", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:23.644309 [debug] [MainThread]: Command `dbt run` succeeded at 19:34:23.643993 after 5.08 seconds
[0m19:34:23.645368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa498a196d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa48a813160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa45800bd30>]}
[0m19:34:23.645987 [debug] [MainThread]: Flushing usage events
[0m19:34:32.110974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb338b15d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb349909f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3498f8ac0>]}


============================== 19:34:32.117456 | 5ab5fb31-2d43-4156-a1c9-7d3eff4c223b ==============================
[0m19:34:32.117456 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:34:32.118307 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_event_dtls', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:34:32.650166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ab5fb31-2d43-4156-a1c9-7d3eff4c223b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3498e2400>]}
[0m19:34:32.769283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ab5fb31-2d43-4156-a1c9-7d3eff4c223b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb349b8af10>]}
[0m19:34:32.771544 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:34:32.787451 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:34:32.856891 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:32.857472 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:32.866853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ab5fb31-2d43-4156-a1c9-7d3eff4c223b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb349cbfe50>]}
[0m19:34:32.882579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ab5fb31-2d43-4156-a1c9-7d3eff4c223b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb339c2f790>]}
[0m19:34:32.883280 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:34:32.883783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ab5fb31-2d43-4156-a1c9-7d3eff4c223b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb339c2f6d0>]}
[0m19:34:32.885768 [info ] [MainThread]: 
[0m19:34:32.886828 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:34:32.888267 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:34:32.912518 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:34:32.913038 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:34:32.913484 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:32.917865 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:32.918364 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:33.431169 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:33.438121 [debug] [ThreadPool]: On list_dev: Close
[0m19:34:33.446128 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:34:33.467554 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:33.468408 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:34:33.469054 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:34:33.470036 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:33.470721 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:33.792971 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:33.795776 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:33.797807 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:34:33.863131 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:33.870734 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:34:33.920992 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:34:33.958648 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:33.959579 [debug] [MainThread]: On master: BEGIN
[0m19:34:33.960250 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:33.961302 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:33.961985 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:34.301040 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:34.302943 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:34.304239 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:34:34.404604 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:34.408417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ab5fb31-2d43-4156-a1c9-7d3eff4c223b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb349bac0a0>]}
[0m19:34:34.409605 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:34.478323 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:34.480054 [debug] [MainThread]: On master: BEGIN
[0m19:34:34.510069 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:34.512286 [debug] [MainThread]: On master: COMMIT
[0m19:34:34.514033 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:34.515174 [debug] [MainThread]: On master: COMMIT
[0m19:34:34.559834 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:34.562026 [debug] [MainThread]: On master: Close
[0m19:34:34.565562 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:34.567457 [info ] [MainThread]: 
[0m19:34:34.574511 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m19:34:34.576332 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m19:34:34.579018 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m19:34:34.580396 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m19:34:34.593816 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m19:34:34.596054 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 19:34:34.581233 => 19:34:34.595401
[0m19:34:34.596868 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m19:34:34.699033 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:34.699711 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp193434646743"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m19:34:34.700260 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:34:34.700972 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:34.701488 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:35.106644 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:35.132943 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:35.133619 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m19:34:35.184370 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:35.185049 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:35.185829 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp193434646743'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp193434646743'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp193434646743'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:34:35.335515 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:35.383290 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:35.384455 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:35.530550 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:35.585004 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:35.586173 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:35.703704 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:35.755160 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m19:34:35.760015 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:35.760687 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp193434646743"
            where (
                
                    "dim_event_dtls__dbt_tmp193434646743".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m19:34:35.880575 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:35.882864 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:35.885163 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp193434646743"
    )
[0m19:34:35.967076 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:36.013920 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:34:36.014925 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m19:34:36.015588 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m19:34:36.609759 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:36.615148 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 19:34:34.597345 => 19:34:36.614171
[0m19:34:36.616937 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m19:34:36.620574 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ab5fb31-2d43-4156-a1c9-7d3eff4c223b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb339dd3610>]}
[0m19:34:36.624996 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.04s]
[0m19:34:36.627745 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m19:34:36.633770 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:36.635583 [debug] [MainThread]: On master: BEGIN
[0m19:34:36.636561 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:36.638003 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:36.639537 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:36.969857 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:36.971282 [debug] [MainThread]: On master: COMMIT
[0m19:34:36.972402 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:36.973253 [debug] [MainThread]: On master: COMMIT
[0m19:34:37.027377 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:37.030052 [debug] [MainThread]: On master: Close
[0m19:34:37.034095 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:37.035978 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m19:34:37.037272 [info ] [MainThread]: 
[0m19:34:37.038273 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.15 seconds (4.15s).
[0m19:34:37.040129 [debug] [MainThread]: Command end result
[0m19:34:37.069675 [info ] [MainThread]: 
[0m19:34:37.070638 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:34:37.071223 [info ] [MainThread]: 
[0m19:34:37.071866 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:34:37.076102 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0756865, "process_user_time": 4.466859, "process_kernel_time": 0.400669, "process_mem_max_rss": "114679808", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:37.077316 [debug] [MainThread]: Command `dbt run` succeeded at 19:34:37.077047 after 5.08 seconds
[0m19:34:37.078049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb338b15d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb339ce5cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb339ce5850>]}
[0m19:34:37.078749 [debug] [MainThread]: Flushing usage events
[0m19:34:43.394915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd1335670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd2035d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd201fe20>]}


============================== 19:34:43.401807 | f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1 ==============================
[0m19:34:43.401807 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:34:43.402626 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_group', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:34:43.807100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd200b7f0>]}
[0m19:34:43.925778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd21d25e0>]}
[0m19:34:43.927566 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:34:43.943192 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:34:44.011356 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:44.011922 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:44.021215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce1acfe20>]}
[0m19:34:44.035682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd243d7c0>]}
[0m19:34:44.036381 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:34:44.036883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd243d6d0>]}
[0m19:34:44.038824 [info ] [MainThread]: 
[0m19:34:44.039894 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:34:44.041365 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:34:44.066871 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:34:44.067464 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:34:44.067918 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:44.072599 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:44.073107 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:44.570247 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:44.573671 [debug] [ThreadPool]: On list_dev: Close
[0m19:34:44.577497 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:34:44.593783 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:44.594723 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:34:44.595382 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:34:44.596395 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:44.597085 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:44.935469 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:44.936568 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:44.937533 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:34:45.002641 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:45.008306 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:34:45.060475 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:34:45.101502 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:45.102327 [debug] [MainThread]: On master: BEGIN
[0m19:34:45.102988 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:45.103976 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:45.104682 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:45.439974 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:45.442696 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:45.444302 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:34:45.540418 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:45.548642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd22968b0>]}
[0m19:34:45.551866 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:45.623407 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:45.625260 [debug] [MainThread]: On master: BEGIN
[0m19:34:45.651610 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:45.652852 [debug] [MainThread]: On master: COMMIT
[0m19:34:45.653885 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:45.654699 [debug] [MainThread]: On master: COMMIT
[0m19:34:45.700469 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:45.702271 [debug] [MainThread]: On master: Close
[0m19:34:45.705273 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:45.706254 [info ] [MainThread]: 
[0m19:34:45.712990 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m19:34:45.714777 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m19:34:45.717037 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m19:34:45.718075 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m19:34:45.727823 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m19:34:45.729616 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 19:34:45.718689 => 19:34:45.729072
[0m19:34:45.730428 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m19:34:45.832570 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:45.833233 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp193445780469"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m19:34:45.833762 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:34:45.834471 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:45.834997 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:46.214339 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:46.266471 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:46.267324 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m19:34:46.312669 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:46.313663 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:46.315001 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp193445780469'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp193445780469'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp193445780469'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:34:46.475792 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:46.523423 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:46.524664 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:46.667060 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:46.719282 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:46.720407 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:46.835592 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:46.887154 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m19:34:46.893606 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:46.894277 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp193445780469"
            where (
                
                    "dim_group__dbt_tmp193445780469".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp193445780469".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m19:34:47.013908 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:47.015825 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:47.018020 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp193445780469"
    )
[0m19:34:47.094095 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:47.142918 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:34:47.143978 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m19:34:47.144667 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m19:34:47.768060 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:47.771406 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 19:34:45.730902 => 19:34:47.770731
[0m19:34:47.772603 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m19:34:47.775871 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f48f5076-b6d5-4c3b-8d5d-ca167ccd6cd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd22968b0>]}
[0m19:34:47.778996 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.06s]
[0m19:34:47.780611 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m19:34:47.783734 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:47.784610 [debug] [MainThread]: On master: BEGIN
[0m19:34:47.785390 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:47.786470 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:47.787174 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:48.115400 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:48.117727 [debug] [MainThread]: On master: COMMIT
[0m19:34:48.119542 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:48.120572 [debug] [MainThread]: On master: COMMIT
[0m19:34:48.168947 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:48.170636 [debug] [MainThread]: On master: Close
[0m19:34:48.173851 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:48.174851 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m19:34:48.176485 [info ] [MainThread]: 
[0m19:34:48.179113 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.14 seconds (4.14s).
[0m19:34:48.182305 [debug] [MainThread]: Command end result
[0m19:34:48.213474 [info ] [MainThread]: 
[0m19:34:48.214477 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:34:48.215159 [info ] [MainThread]: 
[0m19:34:48.215920 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:34:48.220435 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.929293, "process_user_time": 4.472851, "process_kernel_time": 0.378051, "process_mem_max_rss": "119164928", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:48.221491 [debug] [MainThread]: Command `dbt run` succeeded at 19:34:48.221236 after 4.93 seconds
[0m19:34:48.222180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd1335670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fccd243d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce1b58730>]}
[0m19:34:48.222884 [debug] [MainThread]: Flushing usage events
[0m19:34:54.703296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc78889a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7891adf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc789195be0>]}


============================== 19:34:54.709876 | 31afc9d5-f709-47ab-a47c-d21f9fc9d5c7 ==============================
[0m19:34:54.709876 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:34:54.710703 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_outcome', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:34:55.141713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '31afc9d5-f709-47ab-a47c-d21f9fc9d5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc789182370>]}
[0m19:34:55.260150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '31afc9d5-f709-47ab-a47c-d21f9fc9d5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc78936af10>]}
[0m19:34:55.262207 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m19:34:55.277919 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:34:55.344900 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:55.345454 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:55.354777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '31afc9d5-f709-47ab-a47c-d21f9fc9d5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc78949fe50>]}
[0m19:34:55.370406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '31afc9d5-f709-47ab-a47c-d21f9fc9d5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77ace7790>]}
[0m19:34:55.371144 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m19:34:55.371657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31afc9d5-f709-47ab-a47c-d21f9fc9d5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77ace76d0>]}
[0m19:34:55.373609 [info ] [MainThread]: 
[0m19:34:55.374705 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m19:34:55.376164 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m19:34:55.400746 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m19:34:55.401355 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m19:34:55.401844 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:55.406419 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:55.406934 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:55.894603 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:55.901004 [debug] [ThreadPool]: On list_dev: Close
[0m19:34:55.906820 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m19:34:55.924090 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:55.924849 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m19:34:55.925415 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:34:55.926360 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:55.926967 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:56.243429 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:56.247300 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m19:34:56.248601 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m19:34:56.317978 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:56.323667 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m19:34:56.375215 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m19:34:56.412230 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:56.413181 [debug] [MainThread]: On master: BEGIN
[0m19:34:56.413833 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:56.414866 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:56.415558 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:56.752549 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:56.753171 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:56.753744 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m19:34:56.849801 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:56.856294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '31afc9d5-f709-47ab-a47c-d21f9fc9d5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc78938cfd0>]}
[0m19:34:56.858429 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:56.922377 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:56.923889 [debug] [MainThread]: On master: BEGIN
[0m19:34:56.949452 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:56.950598 [debug] [MainThread]: On master: COMMIT
[0m19:34:56.951635 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:56.952455 [debug] [MainThread]: On master: COMMIT
[0m19:34:56.997092 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:57.000132 [debug] [MainThread]: On master: Close
[0m19:34:57.003121 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:57.004467 [info ] [MainThread]: 
[0m19:34:57.011283 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m19:34:57.013134 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m19:34:57.015564 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m19:34:57.016696 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m19:34:57.027340 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m19:34:57.028909 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 19:34:57.017312 => 19:34:57.028372
[0m19:34:57.029710 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m19:34:57.130072 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:57.130755 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp193457077937"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m19:34:57.131301 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m19:34:57.132016 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:57.132537 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:57.517255 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:57.566115 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:57.567022 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m19:34:57.613984 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:57.615043 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:57.616428 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp193457077937'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp193457077937'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp193457077937'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m19:34:57.763735 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:57.811957 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:57.813161 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:57.968956 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:58.012148 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:58.013225 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m19:34:58.131345 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:58.165653 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m19:34:58.172605 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:58.173275 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp193457077937"
            where (
                
                    "dim_outcome__dbt_tmp193457077937".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp193457077937".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp193457077937".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m19:34:58.289943 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:58.291680 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:58.292705 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp193457077937"
    )
[0m19:34:58.381273 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:58.431068 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:34:58.432153 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m19:34:58.432853 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m19:34:59.034312 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m19:34:59.038756 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 19:34:57.030185 => 19:34:59.037739
[0m19:34:59.040191 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m19:34:59.042713 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '31afc9d5-f709-47ab-a47c-d21f9fc9d5c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7895fe1c0>]}
[0m19:34:59.045129 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.03s]
[0m19:34:59.046676 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m19:34:59.049864 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:59.050836 [debug] [MainThread]: On master: BEGIN
[0m19:34:59.051621 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:59.052836 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m19:34:59.053543 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m19:34:59.363122 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:59.365007 [debug] [MainThread]: On master: COMMIT
[0m19:34:59.366993 [debug] [MainThread]: Using redshift connection "master"
[0m19:34:59.368643 [debug] [MainThread]: On master: COMMIT
[0m19:34:59.416046 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m19:34:59.418058 [debug] [MainThread]: On master: Close
[0m19:34:59.421056 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:59.422080 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m19:34:59.423447 [info ] [MainThread]: 
[0m19:34:59.424600 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.05 seconds (4.05s).
[0m19:34:59.426901 [debug] [MainThread]: Command end result
[0m19:34:59.454561 [info ] [MainThread]: 
[0m19:34:59.455581 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:34:59.456261 [info ] [MainThread]: 
[0m19:34:59.457019 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:34:59.461659 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.876468, "process_user_time": 4.436097, "process_kernel_time": 0.37973, "process_mem_max_rss": "123564032", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:59.462783 [debug] [MainThread]: Command `dbt run` succeeded at 19:34:59.462532 after 4.88 seconds
[0m19:34:59.463505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc78889a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77ad9dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc77ad9d850>]}
[0m19:34:59.464225 [debug] [MainThread]: Flushing usage events
[0m21:38:25.840851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bc90a0be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bc9fcd7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bc9fa9460>]}


============================== 21:38:25.848072 | a3d2f77f-6752-4fab-ad9f-f03b33d68c24 ==============================
[0m21:38:25.848072 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:38:25.848960 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt clean', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:38:26.194527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3d2f77f-6752-4fab-ad9f-f03b33d68c24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bc9fefb20>]}
[0m21:38:26.207846 [debug] [MainThread]: Resource report: {"command_name": "clean", "command_success": true, "command_wall_clock_time": 0.48925704, "process_user_time": 3.261872, "process_kernel_time": 0.658442, "process_mem_max_rss": "100917248", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:38:26.209498 [debug] [MainThread]: Command `dbt clean` succeeded at 21:38:26.208872 after 0.49 seconds
[0m21:38:26.210514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bc90a0be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b98168fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7bc9fefb20>]}
[0m21:38:26.211265 [debug] [MainThread]: Flushing usage events
[0m21:45:35.046251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe460b15d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4403e9f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4403d8be0>]}


============================== 21:45:35.053424 | 66ca75f3-109a-4c98-9a36-0694182afe03 ==============================
[0m21:45:35.053424 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:45:35.054318 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_market', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:45:35.599787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4614da370>]}
[0m21:45:35.740918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4616c8130>]}
[0m21:45:35.743487 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m21:45:35.760934 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m21:45:35.761928 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m21:45:35.762443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe450824370>]}
[0m21:45:37.505456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe450d28f40>]}
[0m21:45:37.522085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe450c47370>]}
[0m21:45:37.522782 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m21:45:37.523271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe450c479d0>]}
[0m21:45:37.524985 [info ] [MainThread]: 
[0m21:45:37.526027 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:45:37.527380 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m21:45:37.551025 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m21:45:37.551546 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m21:45:37.551995 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:45:37.556442 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:37.557173 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:38.202530 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:45:38.209022 [debug] [ThreadPool]: On list_dev: Close
[0m21:45:38.218258 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m21:45:38.239109 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:45:38.239763 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m21:45:38.240203 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:38.241169 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:38.241977 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:38.554072 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:38.555436 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:45:38.556270 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m21:45:38.626346 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:38.635687 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m21:45:38.689642 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m21:45:38.731352 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:38.732915 [debug] [MainThread]: On master: BEGIN
[0m21:45:38.733600 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:45:38.738814 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:38.739977 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:39.093575 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:39.095111 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:39.097885 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m21:45:39.199122 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:39.204709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe450d3f370>]}
[0m21:45:39.207848 [debug] [MainThread]: On master: ROLLBACK
[0m21:45:39.279775 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:39.281963 [debug] [MainThread]: On master: BEGIN
[0m21:45:39.307316 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:39.309751 [debug] [MainThread]: On master: COMMIT
[0m21:45:39.311278 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:39.312463 [debug] [MainThread]: On master: COMMIT
[0m21:45:39.358508 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:39.360318 [debug] [MainThread]: On master: Close
[0m21:45:39.364950 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:45:39.367837 [info ] [MainThread]: 
[0m21:45:39.391139 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m21:45:39.393323 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m21:45:39.396022 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m21:45:39.397931 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m21:45:39.413036 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m21:45:39.415186 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 21:45:39.398630 => 21:45:39.414591
[0m21:45:39.416143 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m21:45:39.514103 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:39.514785 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp214539462072"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m21:45:39.515329 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:39.516068 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:39.516589 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:39.939779 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:39.986242 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:39.987266 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m21:45:40.036986 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:40.037705 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:40.038438 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp214539462072'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp214539462072'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp214539462072'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m21:45:40.193098 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:40.228354 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:40.229281 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:45:40.379608 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:40.435104 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:40.436315 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:45:40.553531 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:40.605555 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m21:45:40.611829 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:40.612846 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp214539462072"
            where (
                
                    "dim_market__dbt_tmp214539462072".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp214539462072".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m21:45:40.736882 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:40.739907 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:40.742143 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp214539462072"
    )
[0m21:45:40.831959 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:40.877913 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m21:45:40.878842 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m21:45:40.879437 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m21:45:41.548690 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m21:45:41.554458 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 21:45:39.416665 => 21:45:41.553381
[0m21:45:41.556305 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m21:45:41.559824 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '66ca75f3-109a-4c98-9a36-0694182afe03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe450d22dc0>]}
[0m21:45:41.562849 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.16s]
[0m21:45:41.565208 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m21:45:41.569809 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:41.570977 [debug] [MainThread]: On master: BEGIN
[0m21:45:41.572006 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:45:41.573856 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:41.574658 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:41.904859 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:41.905625 [debug] [MainThread]: On master: COMMIT
[0m21:45:41.906243 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:41.906703 [debug] [MainThread]: On master: COMMIT
[0m21:45:41.953724 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:41.954384 [debug] [MainThread]: On master: Close
[0m21:45:41.955546 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:45:41.955976 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m21:45:41.956543 [info ] [MainThread]: 
[0m21:45:41.957063 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.43 seconds (4.43s).
[0m21:45:41.958031 [debug] [MainThread]: Command end result
[0m21:45:41.979443 [info ] [MainThread]: 
[0m21:45:41.980102 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:45:41.980549 [info ] [MainThread]: 
[0m21:45:41.981101 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:45:41.986238 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.0579944, "process_user_time": 6.188776, "process_kernel_time": 0.497187, "process_mem_max_rss": "120291328", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:45:41.987538 [debug] [MainThread]: Command `dbt run` succeeded at 21:45:41.987298 after 7.06 seconds
[0m21:45:41.988391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe460b15d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe450b9f0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe46191ae20>]}
[0m21:45:41.988954 [debug] [MainThread]: Flushing usage events
[0m21:45:49.559793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f0e55d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9e86ec2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9e8703370>]}


============================== 21:45:49.568705 | 8a393379-d23c-4eb6-8727-d976e60ed10c ==============================
[0m21:45:49.568705 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:45:49.570417 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_event', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:45:50.055075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a393379-d23c-4eb6-8727-d976e60ed10c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9c99bf070>]}
[0m21:45:50.181054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8a393379-d23c-4eb6-8727-d976e60ed10c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f162b0a0>]}
[0m21:45:50.182728 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m21:45:50.199210 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m21:45:50.269132 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:45:50.269734 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:45:50.279334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a393379-d23c-4eb6-8727-d976e60ed10c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f1af7e20>]}
[0m21:45:50.294755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a393379-d23c-4eb6-8727-d976e60ed10c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f1a0d760>]}
[0m21:45:50.295486 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m21:45:50.295986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a393379-d23c-4eb6-8727-d976e60ed10c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f1a0d6a0>]}
[0m21:45:50.297935 [info ] [MainThread]: 
[0m21:45:50.299027 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:45:50.300521 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m21:45:50.324937 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m21:45:50.325515 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m21:45:50.325970 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:45:50.330427 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:50.330937 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:50.799229 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:50.804482 [debug] [ThreadPool]: On list_dev: Close
[0m21:45:50.810100 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m21:45:50.829134 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:45:50.829975 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m21:45:50.830607 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:45:50.831492 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:50.832107 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:51.160957 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:51.163427 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:45:51.165333 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m21:45:51.227075 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:51.230360 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m21:45:51.287533 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m21:45:51.304630 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:51.305308 [debug] [MainThread]: On master: BEGIN
[0m21:45:51.305800 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:45:51.306585 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:51.307097 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:51.697372 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:51.698824 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:51.700337 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m21:45:51.804534 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:51.809817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a393379-d23c-4eb6-8727-d976e60ed10c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f186f850>]}
[0m21:45:51.811468 [debug] [MainThread]: On master: ROLLBACK
[0m21:45:51.879091 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:51.880691 [debug] [MainThread]: On master: BEGIN
[0m21:45:51.907441 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:51.909837 [debug] [MainThread]: On master: COMMIT
[0m21:45:51.911574 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:51.913196 [debug] [MainThread]: On master: COMMIT
[0m21:45:51.965780 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:51.967693 [debug] [MainThread]: On master: Close
[0m21:45:51.971925 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:45:51.973467 [info ] [MainThread]: 
[0m21:45:51.982042 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m21:45:51.984353 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m21:45:51.987338 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m21:45:51.988778 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m21:45:52.001452 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m21:45:52.003141 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 21:45:51.989619 => 21:45:52.002595
[0m21:45:52.003963 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m21:45:52.105853 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:52.106613 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp214552053958"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m21:45:52.107259 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:45:52.108084 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:52.108626 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:52.506049 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:52.558995 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:52.560032 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m21:45:52.608523 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:52.609887 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:52.611619 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp214552053958'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp214552053958'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp214552053958'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m21:45:52.775384 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:52.814179 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:52.815422 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:45:52.962012 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:53.008864 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:53.009929 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:45:53.153492 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:53.203527 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m21:45:53.210472 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:53.211301 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp214552053958"
            where (
                
                    "dim_event__dbt_tmp214552053958".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m21:45:53.326417 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:53.327903 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:53.329485 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp214552053958"
    )
[0m21:45:53.424235 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:53.477910 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m21:45:53.479126 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m21:45:53.479789 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m21:45:54.141214 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m21:45:54.146487 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 21:45:52.004449 => 21:45:54.145593
[0m21:45:54.147933 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m21:45:54.151592 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a393379-d23c-4eb6-8727-d976e60ed10c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f1bd6d30>]}
[0m21:45:54.155342 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.17s]
[0m21:45:54.157394 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m21:45:54.161408 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:54.162595 [debug] [MainThread]: On master: BEGIN
[0m21:45:54.163510 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:45:54.165282 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:45:54.166011 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:45:54.483847 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:54.484578 [debug] [MainThread]: On master: COMMIT
[0m21:45:54.485252 [debug] [MainThread]: Using redshift connection "master"
[0m21:45:54.485705 [debug] [MainThread]: On master: COMMIT
[0m21:45:54.533866 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:45:54.534548 [debug] [MainThread]: On master: Close
[0m21:45:54.536010 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:45:54.536478 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m21:45:54.537248 [info ] [MainThread]: 
[0m21:45:54.537786 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.24 seconds (4.24s).
[0m21:45:54.538828 [debug] [MainThread]: Command end result
[0m21:45:54.554324 [info ] [MainThread]: 
[0m21:45:54.554966 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:45:54.555411 [info ] [MainThread]: 
[0m21:45:54.555939 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:45:54.559565 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.121504, "process_user_time": 4.632256, "process_kernel_time": 0.435525, "process_mem_max_rss": "114864128", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:45:54.560616 [debug] [MainThread]: Command `dbt run` succeeded at 21:45:54.560403 after 5.12 seconds
[0m21:45:54.561286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f0e55d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9f1ac58b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9e88d8eb0>]}
[0m21:45:54.561885 [debug] [MainThread]: Flushing usage events
[0m21:46:01.845360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbab1075670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbab1cfc2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbab1d0e370>]}


============================== 21:46:01.851486 | d5d9ddce-d79c-4820-ad9f-e47e675637cc ==============================
[0m21:46:01.851486 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:46:01.852319 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_participant', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:46:02.260197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd5d9ddce-d79c-4820-ad9f-e47e675637cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbab1e30fa0>]}
[0m21:46:02.379003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd5d9ddce-d79c-4820-ad9f-e47e675637cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbaa05020a0>]}
[0m21:46:02.380850 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m21:46:02.396712 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m21:46:02.465209 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:02.465819 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:02.475343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5d9ddce-d79c-4820-ad9f-e47e675637cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac17bfe20>]}
[0m21:46:02.490550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5d9ddce-d79c-4820-ad9f-e47e675637cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbab2027760>]}
[0m21:46:02.491283 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m21:46:02.491801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5d9ddce-d79c-4820-ad9f-e47e675637cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbab20276a0>]}
[0m21:46:02.493725 [info ] [MainThread]: 
[0m21:46:02.494831 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:46:02.496454 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m21:46:02.521202 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m21:46:02.521784 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m21:46:02.522262 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:46:02.526757 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:02.527284 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:03.044285 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:03.055141 [debug] [ThreadPool]: On list_dev: Close
[0m21:46:03.062902 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m21:46:03.086910 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:03.087868 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m21:46:03.088501 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:46:03.089535 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:03.090216 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:03.424916 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:03.427498 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:03.435437 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m21:46:03.510619 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:03.516731 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m21:46:03.569597 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m21:46:03.605960 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:03.606943 [debug] [MainThread]: On master: BEGIN
[0m21:46:03.607775 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:46:03.608974 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:03.609733 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:03.943928 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:03.945033 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:03.945680 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m21:46:04.043394 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:04.049172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5d9ddce-d79c-4820-ad9f-e47e675637cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba905b7850>]}
[0m21:46:04.051370 [debug] [MainThread]: On master: ROLLBACK
[0m21:46:04.117305 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:04.118503 [debug] [MainThread]: On master: BEGIN
[0m21:46:04.142828 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:04.144599 [debug] [MainThread]: On master: COMMIT
[0m21:46:04.146238 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:04.147550 [debug] [MainThread]: On master: COMMIT
[0m21:46:04.199151 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:04.199919 [debug] [MainThread]: On master: Close
[0m21:46:04.201788 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:46:04.202449 [info ] [MainThread]: 
[0m21:46:04.207573 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m21:46:04.208933 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m21:46:04.210323 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m21:46:04.211077 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m21:46:04.219864 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m21:46:04.221235 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 21:46:04.211536 => 21:46:04.220806
[0m21:46:04.221865 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m21:46:04.331026 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:04.332176 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp214604270100"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m21:46:04.332933 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:46:04.334749 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:04.335427 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:04.737741 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:04.782210 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:04.783254 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m21:46:04.833247 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:04.838208 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:04.840217 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp214604270100'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp214604270100'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp214604270100'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m21:46:04.996216 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:05.050460 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:05.051499 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:05.220871 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:05.253502 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:05.254492 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:05.370609 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:05.412641 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m21:46:05.418345 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:05.419046 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp214604270100"
            where (
                
                    "dim_participant__dbt_tmp214604270100".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp214604270100".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m21:46:05.531619 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:05.534446 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:05.536652 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp214604270100"
    )
[0m21:46:05.642008 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:05.688383 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m21:46:05.689406 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m21:46:05.690017 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m21:46:06.225999 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:06.230520 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 21:46:04.222242 => 21:46:06.229710
[0m21:46:06.233305 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m21:46:06.240026 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5d9ddce-d79c-4820-ad9f-e47e675637cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac181ef40>]}
[0m21:46:06.243748 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 2.03s]
[0m21:46:06.248102 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m21:46:06.251625 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:06.252421 [debug] [MainThread]: On master: BEGIN
[0m21:46:06.253018 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:46:06.255116 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:06.255851 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:06.583978 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:06.585862 [debug] [MainThread]: On master: COMMIT
[0m21:46:06.587544 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:06.588832 [debug] [MainThread]: On master: COMMIT
[0m21:46:06.640954 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:06.642585 [debug] [MainThread]: On master: Close
[0m21:46:06.645907 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:46:06.647292 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m21:46:06.649193 [info ] [MainThread]: 
[0m21:46:06.651122 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.15 seconds (4.15s).
[0m21:46:06.654150 [debug] [MainThread]: Command end result
[0m21:46:06.686576 [info ] [MainThread]: 
[0m21:46:06.687607 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:46:06.688366 [info ] [MainThread]: 
[0m21:46:06.689161 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:46:06.694151 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.956575, "process_user_time": 4.562468, "process_kernel_time": 0.450395, "process_mem_max_rss": "111927296", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:46:06.695491 [debug] [MainThread]: Command `dbt run` succeeded at 21:46:06.695227 after 4.96 seconds
[0m21:46:06.696301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbab1075670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac1840640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac18407f0>]}
[0m21:46:06.697048 [debug] [MainThread]: Flushing usage events
[0m21:46:15.956362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8240b09bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82304fcca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82304e65b0>]}


============================== 21:46:15.964406 | 5d82a839-f04c-4894-9af5-9a20b25c954a ==============================
[0m21:46:15.964406 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:46:15.965392 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_event_dtls', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:46:16.560480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5d82a839-f04c-4894-9af5-9a20b25c954a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82304d3700>]}
[0m21:46:16.681557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5d82a839-f04c-4894-9af5-9a20b25c954a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82304dcac0>]}
[0m21:46:16.683773 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m21:46:16.700884 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m21:46:16.787640 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:16.788309 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:16.798710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5d82a839-f04c-4894-9af5-9a20b25c954a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f824177fdf0>]}
[0m21:46:16.822946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5d82a839-f04c-4894-9af5-9a20b25c954a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8221d1f790>]}
[0m21:46:16.829023 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m21:46:16.830071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d82a839-f04c-4894-9af5-9a20b25c954a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8221d1f6a0>]}
[0m21:46:16.832860 [info ] [MainThread]: 
[0m21:46:16.834240 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:46:16.835902 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m21:46:16.862056 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m21:46:16.862707 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m21:46:16.863176 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:46:16.867918 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:16.868465 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:17.372430 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:17.380457 [debug] [ThreadPool]: On list_dev: Close
[0m21:46:17.389406 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m21:46:17.413020 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:17.413924 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m21:46:17.414581 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:46:17.415639 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:17.416345 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:17.752942 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:17.754646 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:17.756504 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m21:46:17.823641 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:17.828924 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m21:46:17.879016 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m21:46:17.909905 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:17.910608 [debug] [MainThread]: On master: BEGIN
[0m21:46:17.911065 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:46:17.911929 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:17.913067 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:18.277037 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:18.278497 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:18.279724 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m21:46:18.376551 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:18.380699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5d82a839-f04c-4894-9af5-9a20b25c954a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8221a78f40>]}
[0m21:46:18.382922 [debug] [MainThread]: On master: ROLLBACK
[0m21:46:18.451749 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:18.453511 [debug] [MainThread]: On master: BEGIN
[0m21:46:18.476058 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:18.477772 [debug] [MainThread]: On master: COMMIT
[0m21:46:18.479299 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:18.480475 [debug] [MainThread]: On master: COMMIT
[0m21:46:18.529921 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:18.533424 [debug] [MainThread]: On master: Close
[0m21:46:18.544370 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:46:18.545992 [info ] [MainThread]: 
[0m21:46:18.553988 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m21:46:18.556214 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m21:46:18.558990 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m21:46:18.560437 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m21:46:18.578308 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m21:46:18.579737 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 21:46:18.561216 => 21:46:18.579299
[0m21:46:18.580340 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m21:46:18.692550 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:18.693359 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp214618630855"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m21:46:18.693998 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:46:18.695109 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:18.695729 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:19.082754 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:19.129075 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:19.130013 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m21:46:19.175336 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:19.176345 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:19.177593 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp214618630855'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp214618630855'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp214618630855'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m21:46:19.339396 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:19.396774 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:19.399348 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:19.556450 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:19.586191 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:19.587190 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:19.708702 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:19.742526 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m21:46:19.747067 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:19.747750 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp214618630855"
            where (
                
                    "dim_event_dtls__dbt_tmp214618630855".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m21:46:19.860684 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:19.861866 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:19.862734 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp214618630855"
    )
[0m21:46:19.955781 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:19.999207 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m21:46:20.000252 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m21:46:20.000946 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m21:46:20.541460 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:20.550832 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 21:46:18.580682 => 21:46:20.549288
[0m21:46:20.552553 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m21:46:20.557678 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5d82a839-f04c-4894-9af5-9a20b25c954a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8221be6f40>]}
[0m21:46:20.562978 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.00s]
[0m21:46:20.565973 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m21:46:20.572019 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:20.572657 [debug] [MainThread]: On master: BEGIN
[0m21:46:20.573129 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:46:20.574797 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:20.575485 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:20.891611 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:20.893801 [debug] [MainThread]: On master: COMMIT
[0m21:46:20.895973 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:20.897712 [debug] [MainThread]: On master: COMMIT
[0m21:46:20.944479 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:20.946863 [debug] [MainThread]: On master: Close
[0m21:46:20.952165 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:46:20.953912 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m21:46:20.955612 [info ] [MainThread]: 
[0m21:46:20.957161 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m21:46:20.960384 [debug] [MainThread]: Command end result
[0m21:46:20.996471 [info ] [MainThread]: 
[0m21:46:20.997503 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:46:20.998229 [info ] [MainThread]: 
[0m21:46:20.999051 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:46:21.004536 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.165766, "process_user_time": 4.633553, "process_kernel_time": 0.490585, "process_mem_max_rss": "101101568", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:46:21.006116 [debug] [MainThread]: Command `dbt run` succeeded at 21:46:21.005844 after 5.17 seconds
[0m21:46:21.006956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8240b09bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8221d1f0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82417aca60>]}
[0m21:46:21.007758 [debug] [MainThread]: Flushing usage events
[0m21:46:28.199292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe00d1dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe0184ec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe01844f70>]}


============================== 21:46:28.205582 | 32151518-72be-40d8-98b1-f365d4c045f6 ==============================
[0m21:46:28.205582 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:46:28.206382 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_group', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:46:28.636226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '32151518-72be-40d8-98b1-f365d4c045f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe0183af10>]}
[0m21:46:28.761999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '32151518-72be-40d8-98b1-f365d4c045f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe0186af10>]}
[0m21:46:28.763780 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m21:46:28.783348 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m21:46:28.861348 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:28.861948 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:28.871947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32151518-72be-40d8-98b1-f365d4c045f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe11fd7e80>]}
[0m21:46:28.887905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32151518-72be-40d8-98b1-f365d4c045f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe11f307c0>]}
[0m21:46:28.888655 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m21:46:28.889160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32151518-72be-40d8-98b1-f365d4c045f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe11f30700>]}
[0m21:46:28.891121 [info ] [MainThread]: 
[0m21:46:28.892226 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:46:28.893756 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m21:46:28.920762 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m21:46:28.921427 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m21:46:28.921900 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:46:28.926854 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:28.927368 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:29.424022 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:29.430250 [debug] [ThreadPool]: On list_dev: Close
[0m21:46:29.437246 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m21:46:29.454829 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:29.455711 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m21:46:29.456289 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:46:29.457156 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:29.457791 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:29.790568 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:29.793321 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:29.795458 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m21:46:29.864298 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:29.868200 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m21:46:29.918089 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m21:46:29.948624 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:29.949378 [debug] [MainThread]: On master: BEGIN
[0m21:46:29.949942 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:46:29.950804 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:29.951396 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:30.273313 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:30.275052 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:30.276231 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m21:46:30.378208 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:30.384141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32151518-72be-40d8-98b1-f365d4c045f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe11d36520>]}
[0m21:46:30.385850 [debug] [MainThread]: On master: ROLLBACK
[0m21:46:30.464387 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:30.466406 [debug] [MainThread]: On master: BEGIN
[0m21:46:30.493449 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:30.495447 [debug] [MainThread]: On master: COMMIT
[0m21:46:30.496899 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:30.498062 [debug] [MainThread]: On master: COMMIT
[0m21:46:30.552048 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:30.553728 [debug] [MainThread]: On master: Close
[0m21:46:30.556517 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:46:30.557675 [info ] [MainThread]: 
[0m21:46:30.564416 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m21:46:30.566674 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m21:46:30.569716 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m21:46:30.571021 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m21:46:30.583986 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m21:46:30.586219 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 21:46:30.571643 => 21:46:30.585448
[0m21:46:30.587280 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m21:46:30.699455 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:30.700571 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp214630642014"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m21:46:30.701208 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:46:30.701973 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:30.702510 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:31.085841 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:31.138065 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:31.139043 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m21:46:31.186758 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:31.187855 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:31.189329 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp214630642014'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp214630642014'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp214630642014'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m21:46:31.338200 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:31.388968 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:31.390342 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:31.539233 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:31.597214 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:31.598448 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:31.717394 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:31.768578 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m21:46:31.774791 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:31.775456 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp214630642014"
            where (
                
                    "dim_group__dbt_tmp214630642014".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp214630642014".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m21:46:31.890347 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:31.891138 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:31.891710 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp214630642014"
    )
[0m21:46:31.966358 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:31.990553 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m21:46:31.991343 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m21:46:31.991867 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m21:46:32.748466 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:32.752019 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 21:46:30.587807 => 21:46:32.751352
[0m21:46:32.754064 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m21:46:32.758026 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32151518-72be-40d8-98b1-f365d4c045f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe11fe4a30>]}
[0m21:46:32.760796 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.19s]
[0m21:46:32.764435 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m21:46:32.769038 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:32.770500 [debug] [MainThread]: On master: BEGIN
[0m21:46:32.771462 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:46:32.773148 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:32.774136 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:33.118169 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:33.119695 [debug] [MainThread]: On master: COMMIT
[0m21:46:33.120899 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:33.121763 [debug] [MainThread]: On master: COMMIT
[0m21:46:33.168172 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:33.169414 [debug] [MainThread]: On master: Close
[0m21:46:33.171831 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:46:33.172661 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m21:46:33.173705 [info ] [MainThread]: 
[0m21:46:33.174667 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.28 seconds (4.28s).
[0m21:46:33.177420 [debug] [MainThread]: Command end result
[0m21:46:33.206025 [info ] [MainThread]: 
[0m21:46:33.206754 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:46:33.207210 [info ] [MainThread]: 
[0m21:46:33.207718 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:46:33.210865 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.120118, "process_user_time": 4.664566, "process_kernel_time": 0.402661, "process_mem_max_rss": "118427648", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:46:33.211788 [debug] [MainThread]: Command `dbt run` succeeded at 21:46:33.211595 after 5.12 seconds
[0m21:46:33.212384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe00d1dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe11f302b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe11f30730>]}
[0m21:46:33.212985 [debug] [MainThread]: Flushing usage events
[0m21:46:40.383683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22092dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2218b4d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22189de20>]}


============================== 21:46:40.389993 | b098faa0-c45e-495c-8e8f-51fb730c1ea7 ==============================
[0m21:46:40.389993 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:46:40.390804 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m21:46:40.802182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b098faa0-c45e-495c-8e8f-51fb730c1ea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22188b7f0>]}
[0m21:46:40.919845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b098faa0-c45e-495c-8e8f-51fb730c1ea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa221b6a5e0>]}
[0m21:46:40.921610 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m21:46:40.937107 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m21:46:41.004892 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:41.005502 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:41.014951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b098faa0-c45e-495c-8e8f-51fb730c1ea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa231c47e20>]}
[0m21:46:41.029593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b098faa0-c45e-495c-8e8f-51fb730c1ea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa221e977c0>]}
[0m21:46:41.030280 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m21:46:41.030780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b098faa0-c45e-495c-8e8f-51fb730c1ea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa221e976d0>]}
[0m21:46:41.032692 [info ] [MainThread]: 
[0m21:46:41.033778 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m21:46:41.035202 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m21:46:41.060915 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m21:46:41.061595 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m21:46:41.062082 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:46:41.067503 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:41.068171 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:41.667582 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:41.673692 [debug] [ThreadPool]: On list_dev: Close
[0m21:46:41.678722 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m21:46:41.692108 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:41.692974 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m21:46:41.693673 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:46:41.695424 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:41.695911 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:42.020313 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:42.022214 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m21:46:42.023454 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m21:46:42.090613 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:42.097534 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m21:46:42.150550 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m21:46:42.185595 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:42.186506 [debug] [MainThread]: On master: BEGIN
[0m21:46:42.187162 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:46:42.188110 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:42.188698 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:42.514887 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:42.516325 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:42.517358 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m21:46:42.619667 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:42.627009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b098faa0-c45e-495c-8e8f-51fb730c1ea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa221ceee50>]}
[0m21:46:42.630117 [debug] [MainThread]: On master: ROLLBACK
[0m21:46:42.701496 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:42.702743 [debug] [MainThread]: On master: BEGIN
[0m21:46:42.728290 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:42.730254 [debug] [MainThread]: On master: COMMIT
[0m21:46:42.731958 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:42.733841 [debug] [MainThread]: On master: COMMIT
[0m21:46:42.778767 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:42.781008 [debug] [MainThread]: On master: Close
[0m21:46:42.785063 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m21:46:42.786441 [info ] [MainThread]: 
[0m21:46:42.792430 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m21:46:42.794551 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m21:46:42.797539 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m21:46:42.799252 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m21:46:42.813467 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m21:46:42.815514 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 21:46:42.800325 => 21:46:42.814885
[0m21:46:42.816341 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m21:46:42.919217 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:42.919911 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp214642867158"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m21:46:42.920459 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m21:46:42.921201 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:42.921722 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:43.307210 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:43.357470 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:43.358329 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m21:46:43.406604 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:43.407751 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:43.409144 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp214642867158'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp214642867158'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp214642867158'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m21:46:43.564533 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:43.606604 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:43.607796 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:43.753730 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:43.807440 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:43.808534 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m21:46:43.928095 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:43.981913 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m21:46:43.988930 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:43.989638 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp214642867158"
            where (
                
                    "dim_outcome__dbt_tmp214642867158".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp214642867158".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp214642867158".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m21:46:44.110957 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:44.112672 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:44.113841 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp214642867158"
    )
[0m21:46:44.206114 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:44.324385 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m21:46:44.327613 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m21:46:44.328573 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m21:46:44.913548 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m21:46:44.922947 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 21:46:42.816820 => 21:46:44.921405
[0m21:46:44.925206 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m21:46:44.930184 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b098faa0-c45e-495c-8e8f-51fb730c1ea7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa221f84d00>]}
[0m21:46:44.934208 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.13s]
[0m21:46:44.937093 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m21:46:44.942845 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:44.943772 [debug] [MainThread]: On master: BEGIN
[0m21:46:44.944536 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:46:44.947098 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m21:46:44.948012 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m21:46:45.280095 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:45.281799 [debug] [MainThread]: On master: COMMIT
[0m21:46:45.283682 [debug] [MainThread]: Using redshift connection "master"
[0m21:46:45.285135 [debug] [MainThread]: On master: COMMIT
[0m21:46:45.333672 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m21:46:45.335283 [debug] [MainThread]: On master: Close
[0m21:46:45.338368 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:46:45.339508 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m21:46:45.341036 [info ] [MainThread]: 
[0m21:46:45.342909 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.31 seconds (4.31s).
[0m21:46:45.354193 [debug] [MainThread]: Command end result
[0m21:46:45.379572 [info ] [MainThread]: 
[0m21:46:45.380415 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:46:45.380921 [info ] [MainThread]: 
[0m21:46:45.381863 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m21:46:45.387014 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.111273, "process_user_time": 4.642681, "process_kernel_time": 0.450459, "process_mem_max_rss": "115310592", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:46:45.388353 [debug] [MainThread]: Command `dbt run` succeeded at 21:46:45.388106 after 5.11 seconds
[0m21:46:45.389021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa22092dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa231c2f070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa221d62ac0>]}
[0m21:46:45.389584 [debug] [MainThread]: Flushing usage events
[0m21:46:54.030088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe309085d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2e871cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2e8708ac0>]}


============================== 21:46:54.036570 | e3842896-befa-47fc-9a97-e0d78ed65b09 ==============================
[0m21:46:54.036570 [info ] [MainThread]: Running with dbt=1.7.0
[0m21:46:54.037428 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_specifier', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:46:54.579311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e3842896-befa-47fc-9a97-e0d78ed65b09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2f9862400>]}
[0m21:46:54.697288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e3842896-befa-47fc-9a97-e0d78ed65b09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2f9a8af10>]}
[0m21:46:54.699304 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m21:46:54.714905 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m21:46:54.785063 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:46:54.785632 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:46:54.795120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e3842896-befa-47fc-9a97-e0d78ed65b09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2f9bbfe50>]}
[0m21:46:54.810686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e3842896-befa-47fc-9a97-e0d78ed65b09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe309d0f790>]}
[0m21:46:54.811358 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m21:46:54.811846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e3842896-befa-47fc-9a97-e0d78ed65b09', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe309d0f6d0>]}
[0m21:46:54.812748 [warn ] [MainThread]: The selection criterion 'dim_specifier' does not match any nodes
[0m21:46:54.814093 [info ] [MainThread]: 
[0m21:46:54.814551 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m21:46:54.815251 [debug] [MainThread]: Command end result
[0m21:46:54.828929 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.9065632, "process_user_time": 3.602789, "process_kernel_time": 0.315143, "process_mem_max_rss": "114593792", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m21:46:54.830221 [debug] [MainThread]: Command `dbt run` succeeded at 21:46:54.829666 after 0.91 seconds
[0m21:46:54.830805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe309085d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe309dbdcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2f9862400>]}
[0m21:46:54.831334 [debug] [MainThread]: Flushing usage events
[0m22:15:40.074937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53932d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb539eabd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb539e95e20>]}


============================== 22:15:40.082033 | 4549fefd-49ec-472a-b00e-3f91aa2bdd2e ==============================
[0m22:15:40.082033 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:15:40.082875 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_market', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:15:40.638742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4549fefd-49ec-472a-b00e-3f91aa2bdd2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb539e837f0>]}
[0m22:15:40.759504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4549fefd-49ec-472a-b00e-3f91aa2bdd2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb539f8a5e0>]}
[0m22:15:40.761724 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:15:40.777992 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:15:40.849556 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:15:40.850107 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:15:40.860019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4549fefd-49ec-472a-b00e-3f91aa2bdd2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb539fdfe20>]}
[0m22:15:40.880820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4549fefd-49ec-472a-b00e-3f91aa2bdd2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb509a2f7c0>]}
[0m22:15:40.881568 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:15:40.882080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4549fefd-49ec-472a-b00e-3f91aa2bdd2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb509a2f6d0>]}
[0m22:15:40.884094 [info ] [MainThread]: 
[0m22:15:40.885265 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:15:40.886800 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:15:40.911529 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:15:40.912056 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:15:40.912514 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:15:40.917028 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:40.917790 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:41.475477 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:15:41.479532 [debug] [ThreadPool]: On list_dev: Close
[0m22:15:41.483468 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:15:41.497970 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:15:41.498557 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:15:41.499031 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:15:41.499784 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:41.500295 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:41.825841 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:41.828652 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:15:41.830773 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:15:41.901791 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:41.909002 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:15:41.963827 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:15:42.005237 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:42.006165 [debug] [MainThread]: On master: BEGIN
[0m22:15:42.006843 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:15:42.007890 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:42.008581 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:42.345761 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:42.347366 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:42.348960 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:15:42.448229 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:42.455499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4549fefd-49ec-472a-b00e-3f91aa2bdd2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb509886880>]}
[0m22:15:42.457916 [debug] [MainThread]: On master: ROLLBACK
[0m22:15:42.530302 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:42.531695 [debug] [MainThread]: On master: BEGIN
[0m22:15:42.559093 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:42.560883 [debug] [MainThread]: On master: COMMIT
[0m22:15:42.563733 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:42.565643 [debug] [MainThread]: On master: COMMIT
[0m22:15:42.614590 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:42.615759 [debug] [MainThread]: On master: Close
[0m22:15:42.617954 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:15:42.618871 [info ] [MainThread]: 
[0m22:15:42.623624 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m22:15:42.624969 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m22:15:42.626524 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m22:15:42.627332 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m22:15:42.635985 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m22:15:42.638557 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 22:15:42.627825 => 22:15:42.638042
[0m22:15:42.639292 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m22:15:42.740714 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:42.741431 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp221542687076"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m22:15:42.741994 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:15:42.742725 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:42.743277 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:43.301741 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:15:43.331422 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:43.332225 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m22:15:43.380505 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:43.381205 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:43.382060 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp221542687076'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp221542687076'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp221542687076'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:15:43.537238 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:43.574292 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:43.575596 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:15:43.734690 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:43.795030 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:43.796203 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:15:43.914786 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:43.968994 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m22:15:43.975995 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:43.976673 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp221542687076"
            where (
                
                    "dim_market__dbt_tmp221542687076".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp221542687076".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m22:15:44.096627 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:44.099778 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:44.102207 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp221542687076"
    )
[0m22:15:44.189979 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:44.245344 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:15:44.246207 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:15:44.246782 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:15:44.940816 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:15:44.948626 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 22:15:42.639717 => 22:15:44.947109
[0m22:15:44.950973 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m22:15:44.956265 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4549fefd-49ec-472a-b00e-3f91aa2bdd2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb539fece20>]}
[0m22:15:44.960753 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.33s]
[0m22:15:44.963353 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m22:15:44.969576 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:44.971081 [debug] [MainThread]: On master: BEGIN
[0m22:15:44.972135 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:15:44.974371 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:44.975247 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:45.303213 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:45.305632 [debug] [MainThread]: On master: COMMIT
[0m22:15:45.307926 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:45.309624 [debug] [MainThread]: On master: COMMIT
[0m22:15:45.361344 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:45.363666 [debug] [MainThread]: On master: Close
[0m22:15:45.369128 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:15:45.371105 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m22:15:45.373133 [info ] [MainThread]: 
[0m22:15:45.374791 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.49 seconds (4.49s).
[0m22:15:45.378181 [debug] [MainThread]: Command end result
[0m22:15:45.410316 [info ] [MainThread]: 
[0m22:15:45.411292 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:15:45.411914 [info ] [MainThread]: 
[0m22:15:45.412573 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:15:45.417505 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.4717402, "process_user_time": 4.533067, "process_kernel_time": 0.455629, "process_mem_max_rss": "105005056", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:15:45.418833 [debug] [MainThread]: Command `dbt run` succeeded at 22:15:45.418559 after 5.47 seconds
[0m22:15:45.419667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb53932d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb509825dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb509ae5b80>]}
[0m22:15:45.420406 [debug] [MainThread]: Flushing usage events
[0m22:15:52.158597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc740e15d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7317cfc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7317c5eb0>]}


============================== 22:15:52.164678 | 21d355ed-f317-4fc2-ae9d-a8f9ed7241cc ==============================
[0m22:15:52.164678 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:15:52.165511 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_event', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:15:52.579751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '21d355ed-f317-4fc2-ae9d-a8f9ed7241cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7317bab20>]}
[0m22:15:52.700814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '21d355ed-f317-4fc2-ae9d-a8f9ed7241cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7317eaf10>]}
[0m22:15:52.702576 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:15:52.722768 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:15:52.791823 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:15:52.792401 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:15:52.801920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '21d355ed-f317-4fc2-ae9d-a8f9ed7241cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc741ca7e80>]}
[0m22:15:52.818034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '21d355ed-f317-4fc2-ae9d-a8f9ed7241cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc731bf07c0>]}
[0m22:15:52.818823 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:15:52.819342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21d355ed-f317-4fc2-ae9d-a8f9ed7241cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc731bf0700>]}
[0m22:15:52.821639 [info ] [MainThread]: 
[0m22:15:52.822776 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:15:52.824394 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:15:52.848758 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:15:52.849352 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:15:52.849814 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:15:52.854310 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:52.854811 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:53.389226 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:15:53.399712 [debug] [ThreadPool]: On list_dev: Close
[0m22:15:53.409194 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:15:53.428635 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:15:53.430147 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:15:53.431023 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:15:53.432101 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:53.432823 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:53.781066 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:53.783663 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:15:53.785721 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:15:53.852224 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:53.859060 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:15:53.914423 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:15:53.945547 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:53.946335 [debug] [MainThread]: On master: BEGIN
[0m22:15:53.946910 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:15:53.947797 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:53.948405 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:54.275931 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:54.277302 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:54.278482 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:15:54.377415 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:54.385954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '21d355ed-f317-4fc2-ae9d-a8f9ed7241cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc741c85520>]}
[0m22:15:54.389011 [debug] [MainThread]: On master: ROLLBACK
[0m22:15:54.454047 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:54.457283 [debug] [MainThread]: On master: BEGIN
[0m22:15:54.480927 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:54.482302 [debug] [MainThread]: On master: COMMIT
[0m22:15:54.483462 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:54.484257 [debug] [MainThread]: On master: COMMIT
[0m22:15:54.531120 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:54.532655 [debug] [MainThread]: On master: Close
[0m22:15:54.535536 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:15:54.536859 [info ] [MainThread]: 
[0m22:15:54.546043 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m22:15:54.548608 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m22:15:54.551137 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m22:15:54.552286 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m22:15:54.562782 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m22:15:54.564143 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 22:15:54.552957 => 22:15:54.563740
[0m22:15:54.564825 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m22:15:54.670171 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:54.670903 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp221554617953"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m22:15:54.671481 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:15:54.672239 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:54.672772 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:55.059245 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:55.111537 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:55.112447 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m22:15:55.160306 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:55.161263 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:55.162682 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp221554617953'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp221554617953'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp221554617953'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:15:55.318136 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:55.365272 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:55.366661 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:15:55.520134 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:55.561161 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:55.562175 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:15:55.678720 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:55.705525 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m22:15:55.710053 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:55.710642 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp221554617953"
            where (
                
                    "dim_event__dbt_tmp221554617953".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m22:15:55.821483 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:55.822499 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:55.823347 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp221554617953"
    )
[0m22:15:55.906526 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:55.956963 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:15:55.957940 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:15:55.958520 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:15:56.614259 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:15:56.620186 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 22:15:54.565422 => 22:15:56.619199
[0m22:15:56.621978 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m22:15:56.625822 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '21d355ed-f317-4fc2-ae9d-a8f9ed7241cc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc741d46f70>]}
[0m22:15:56.629354 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.08s]
[0m22:15:56.632327 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m22:15:56.638827 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:56.640070 [debug] [MainThread]: On master: BEGIN
[0m22:15:56.640867 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:15:56.642220 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:15:56.643083 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:15:56.977801 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:56.978934 [debug] [MainThread]: On master: COMMIT
[0m22:15:56.979944 [debug] [MainThread]: Using redshift connection "master"
[0m22:15:56.980747 [debug] [MainThread]: On master: COMMIT
[0m22:15:57.029550 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:15:57.031112 [debug] [MainThread]: On master: Close
[0m22:15:57.034380 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:15:57.035760 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m22:15:57.037124 [info ] [MainThread]: 
[0m22:15:57.038255 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.21 seconds (4.21s).
[0m22:15:57.040058 [debug] [MainThread]: Command end result
[0m22:15:57.061665 [info ] [MainThread]: 
[0m22:15:57.062419 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:15:57.062930 [info ] [MainThread]: 
[0m22:15:57.063522 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:15:57.067006 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0149717, "process_user_time": 4.503383, "process_kernel_time": 0.402407, "process_mem_max_rss": "110657536", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:15:57.067996 [debug] [MainThread]: Command `dbt run` succeeded at 22:15:57.067780 after 5.02 seconds
[0m22:15:57.068618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc740e15d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc731bf07f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc731bf03a0>]}
[0m22:15:57.069242 [debug] [MainThread]: Flushing usage events
[0m22:16:03.853622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb210a1bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11b85ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11b6f5b0>]}


============================== 22:16:03.863787 | 47022999-7031-4a5b-a180-5899ef48c6fb ==============================
[0m22:16:03.863787 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:16:03.864782 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_participant', 'send_anonymous_usage_stats': 'True'}
[0m22:16:04.364227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47022999-7031-4a5b-a180-5899ef48c6fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11b5c700>]}
[0m22:16:04.484456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47022999-7031-4a5b-a180-5899ef48c6fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11b64ac0>]}
[0m22:16:04.486166 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:16:04.501751 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:16:04.572871 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:16:04.573499 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:16:04.583244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47022999-7031-4a5b-a180-5899ef48c6fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb00447df0>]}
[0m22:16:04.599808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47022999-7031-4a5b-a180-5899ef48c6fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb21f45790>]}
[0m22:16:04.600815 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:16:04.601350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47022999-7031-4a5b-a180-5899ef48c6fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb21f456a0>]}
[0m22:16:04.603537 [info ] [MainThread]: 
[0m22:16:04.604782 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:16:04.606307 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:16:04.632276 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:16:04.632911 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:16:04.633395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:04.638162 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:04.638674 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:05.128782 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:05.135409 [debug] [ThreadPool]: On list_dev: Close
[0m22:16:05.145934 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:16:05.169640 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:05.170620 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:16:05.171303 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:05.172343 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:05.173037 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:05.505296 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:05.508015 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:05.509937 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:16:05.577931 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:05.586047 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:16:05.640265 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:16:05.679967 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:05.680866 [debug] [MainThread]: On master: BEGIN
[0m22:16:05.681523 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:16:05.682539 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:05.683237 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:06.019169 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:06.022029 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:06.024149 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:16:06.130607 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:06.135639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47022999-7031-4a5b-a180-5899ef48c6fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb00338f40>]}
[0m22:16:06.137114 [debug] [MainThread]: On master: ROLLBACK
[0m22:16:06.212849 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:06.215743 [debug] [MainThread]: On master: BEGIN
[0m22:16:06.239582 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:06.240670 [debug] [MainThread]: On master: COMMIT
[0m22:16:06.241690 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:06.242502 [debug] [MainThread]: On master: COMMIT
[0m22:16:06.288081 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:06.289635 [debug] [MainThread]: On master: Close
[0m22:16:06.293168 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:16:06.294708 [info ] [MainThread]: 
[0m22:16:06.300565 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m22:16:06.302041 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m22:16:06.303928 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m22:16:06.304926 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m22:16:06.314630 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m22:16:06.316514 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 22:16:06.305526 => 22:16:06.315892
[0m22:16:06.317370 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m22:16:06.417115 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:06.417814 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp221606365622"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m22:16:06.418355 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:16:06.419106 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:06.419664 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:06.829509 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:06.873972 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:06.874818 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m22:16:06.920186 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:06.921197 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:06.922383 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp221606365622'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp221606365622'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp221606365622'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:16:07.072027 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:07.120068 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:07.121317 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:07.268488 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:07.314717 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:07.315780 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:07.430976 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:07.478087 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m22:16:07.483526 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:07.484280 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp221606365622"
            where (
                
                    "dim_participant__dbt_tmp221606365622".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp221606365622".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m22:16:07.603826 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:07.605790 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:07.607347 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp221606365622"
    )
[0m22:16:07.685176 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:07.735419 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:16:07.736531 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:16:07.737205 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:16:08.263169 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:16:08.274835 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 22:16:06.317869 => 22:16:08.272181
[0m22:16:08.281594 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m22:16:08.286280 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47022999-7031-4a5b-a180-5899ef48c6fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11e7cc40>]}
[0m22:16:08.289441 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 1.98s]
[0m22:16:08.291038 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m22:16:08.298385 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:08.299432 [debug] [MainThread]: On master: BEGIN
[0m22:16:08.300187 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:16:08.302754 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:08.303620 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:08.675522 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:08.677584 [debug] [MainThread]: On master: COMMIT
[0m22:16:08.679803 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:08.681143 [debug] [MainThread]: On master: COMMIT
[0m22:16:08.733113 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:08.735554 [debug] [MainThread]: On master: Close
[0m22:16:08.740953 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:16:08.742696 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m22:16:08.744645 [info ] [MainThread]: 
[0m22:16:08.746033 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.14 seconds (4.14s).
[0m22:16:08.748721 [debug] [MainThread]: Command end result
[0m22:16:08.776357 [info ] [MainThread]: 
[0m22:16:08.777158 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:16:08.777642 [info ] [MainThread]: 
[0m22:16:08.778302 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:16:08.782032 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.0383396, "process_user_time": 4.598808, "process_kernel_time": 0.435924, "process_mem_max_rss": "113250304", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:16:08.783167 [debug] [MainThread]: Command `dbt run` succeeded at 22:16:08.782949 after 5.04 seconds
[0m22:16:08.783875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb210a1bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11d00d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb22060610>]}
[0m22:16:08.784505 [debug] [MainThread]: Flushing usage events
[0m22:16:17.773192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a18b25670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a195252e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a19536370>]}


============================== 22:16:17.779736 | e93d4047-33b2-49c9-82b7-8425ec7390cb ==============================
[0m22:16:17.779736 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:16:17.780715 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_event_dtls', 'send_anonymous_usage_stats': 'True'}
[0m22:16:18.329198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e93d4047-33b2-49c9-82b7-8425ec7390cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a19696fa0>]}
[0m22:16:18.456308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e93d4047-33b2-49c9-82b7-8425ec7390cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a08b6b0a0>]}
[0m22:16:18.458496 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:16:18.474481 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:16:18.545976 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:16:18.546546 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:16:18.556107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e93d4047-33b2-49c9-82b7-8425ec7390cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a29b77e20>]}
[0m22:16:18.572257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e93d4047-33b2-49c9-82b7-8425ec7390cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a29a8f760>]}
[0m22:16:18.572960 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:16:18.573470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e93d4047-33b2-49c9-82b7-8425ec7390cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a29a8f6a0>]}
[0m22:16:18.575346 [info ] [MainThread]: 
[0m22:16:18.576373 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:16:18.577813 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:16:18.602119 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:16:18.602696 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:16:18.603151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:18.607660 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:18.608158 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:19.102932 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:19.107199 [debug] [ThreadPool]: On list_dev: Close
[0m22:16:19.112115 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:16:19.130663 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:19.131551 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:16:19.132138 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:19.133023 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:19.133565 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:19.462303 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:19.463682 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:19.464775 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:16:19.535347 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:19.542166 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:16:19.607595 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:16:19.639166 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:19.640071 [debug] [MainThread]: On master: BEGIN
[0m22:16:19.640645 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:16:19.641573 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:19.642174 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:19.995517 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:19.996974 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:19.998011 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:16:20.096760 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:20.102293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e93d4047-33b2-49c9-82b7-8425ec7390cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a2986f850>]}
[0m22:16:20.104403 [debug] [MainThread]: On master: ROLLBACK
[0m22:16:20.178544 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:20.180597 [debug] [MainThread]: On master: BEGIN
[0m22:16:20.216609 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:20.217527 [debug] [MainThread]: On master: COMMIT
[0m22:16:20.218168 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:20.218823 [debug] [MainThread]: On master: COMMIT
[0m22:16:20.270594 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:20.272751 [debug] [MainThread]: On master: Close
[0m22:16:20.276905 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:16:20.279504 [info ] [MainThread]: 
[0m22:16:20.285345 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m22:16:20.287501 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m22:16:20.291199 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m22:16:20.292732 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m22:16:20.307917 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m22:16:20.310695 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 22:16:20.293592 => 22:16:20.310017
[0m22:16:20.311624 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m22:16:20.420029 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:20.420790 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp221620364849"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m22:16:20.421357 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:16:20.422143 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:20.422694 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:20.819804 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:20.868571 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:20.869495 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m22:16:20.918054 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:20.919182 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:20.920668 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp221620364849'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp221620364849'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp221620364849'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:16:21.068197 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:21.115409 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:21.116737 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:21.266431 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:21.321883 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:21.323159 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:21.441462 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:21.491450 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m22:16:21.497092 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:21.497885 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp221620364849"
            where (
                
                    "dim_event_dtls__dbt_tmp221620364849".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m22:16:21.609704 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:21.612046 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:21.613802 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp221620364849"
    )
[0m22:16:21.694611 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:21.738571 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:16:21.739731 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:16:21.740438 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:16:22.521903 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:16:22.526964 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 22:16:20.312114 => 22:16:22.526176
[0m22:16:22.528219 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m22:16:22.530980 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e93d4047-33b2-49c9-82b7-8425ec7390cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a29c2ef40>]}
[0m22:16:22.533504 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.24s]
[0m22:16:22.535296 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m22:16:22.540060 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:22.541114 [debug] [MainThread]: On master: BEGIN
[0m22:16:22.541874 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:16:22.543512 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:22.544776 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:22.860783 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:22.862193 [debug] [MainThread]: On master: COMMIT
[0m22:16:22.863737 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:22.864620 [debug] [MainThread]: On master: COMMIT
[0m22:16:22.912843 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:22.914139 [debug] [MainThread]: On master: Close
[0m22:16:22.916570 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:16:22.917457 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m22:16:22.918710 [info ] [MainThread]: 
[0m22:16:22.919881 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.34 seconds (4.34s).
[0m22:16:22.922197 [debug] [MainThread]: Command end result
[0m22:16:22.950543 [info ] [MainThread]: 
[0m22:16:22.951519 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:16:22.952198 [info ] [MainThread]: 
[0m22:16:22.952941 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:16:22.957470 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.2985644, "process_user_time": 4.606892, "process_kernel_time": 0.409076, "process_mem_max_rss": "126492672", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:16:22.958699 [debug] [MainThread]: Command `dbt run` succeeded at 22:16:22.958420 after 5.30 seconds
[0m22:16:22.959516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a18b25670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a29a8f130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a29b9f5e0>]}
[0m22:16:22.960348 [debug] [MainThread]: Flushing usage events
[0m22:16:29.539257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e48b51820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e382e0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e382bc640>]}


============================== 22:16:29.546963 | 8767ef9d-3eb0-4254-9dc3-51ddc95f83bf ==============================
[0m22:16:29.546963 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:16:29.547872 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_group', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:16:29.967936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8767ef9d-3eb0-4254-9dc3-51ddc95f83bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e5982b7c0>]}
[0m22:16:30.088832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8767ef9d-3eb0-4254-9dc3-51ddc95f83bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e499d0070>]}
[0m22:16:30.090808 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:16:30.107283 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:16:30.175540 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:16:30.176102 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:16:30.185456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8767ef9d-3eb0-4254-9dc3-51ddc95f83bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e59ba7ee0>]}
[0m22:16:30.200652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8767ef9d-3eb0-4254-9dc3-51ddc95f83bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e59ac0880>]}
[0m22:16:30.201376 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:16:30.201875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8767ef9d-3eb0-4254-9dc3-51ddc95f83bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e59ac0790>]}
[0m22:16:30.203798 [info ] [MainThread]: 
[0m22:16:30.204899 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:16:30.206343 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:16:30.230408 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:16:30.230937 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:16:30.231391 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:30.235786 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:30.236294 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:30.742567 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:16:30.749184 [debug] [ThreadPool]: On list_dev: Close
[0m22:16:30.756142 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:16:30.778131 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:30.779171 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:16:30.779870 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:30.780924 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:30.781656 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:31.102508 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:31.103939 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:31.104969 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:16:31.170128 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:31.178314 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:16:31.236682 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:16:31.277735 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:31.278640 [debug] [MainThread]: On master: BEGIN
[0m22:16:31.279295 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:16:31.280390 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:31.281151 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:31.640204 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:31.642317 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:31.643616 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:16:31.742953 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:31.747616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8767ef9d-3eb0-4254-9dc3-51ddc95f83bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e383a07f0>]}
[0m22:16:31.749162 [debug] [MainThread]: On master: ROLLBACK
[0m22:16:31.826263 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:31.828327 [debug] [MainThread]: On master: BEGIN
[0m22:16:31.854118 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:31.855198 [debug] [MainThread]: On master: COMMIT
[0m22:16:31.856208 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:31.857013 [debug] [MainThread]: On master: COMMIT
[0m22:16:31.907119 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:31.908446 [debug] [MainThread]: On master: Close
[0m22:16:31.922132 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:16:31.923443 [info ] [MainThread]: 
[0m22:16:31.932002 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m22:16:31.934032 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m22:16:31.936160 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m22:16:31.937227 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m22:16:31.947726 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m22:16:31.949795 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 22:16:31.937848 => 22:16:31.949228
[0m22:16:31.950629 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m22:16:32.054367 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:32.055106 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp221632000556"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m22:16:32.055671 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:16:32.056409 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:32.056937 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:32.446519 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:32.500510 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:32.501290 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m22:16:32.553059 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:32.554458 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:32.555962 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp221632000556'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp221632000556'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp221632000556'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:16:32.708048 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:32.744818 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:32.745918 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:32.891781 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:32.920066 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:32.921047 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:33.036766 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:33.073155 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m22:16:33.077984 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:33.078573 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp221632000556"
            where (
                
                    "dim_group__dbt_tmp221632000556".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp221632000556".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m22:16:33.192100 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:33.194201 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:33.196474 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp221632000556"
    )
[0m22:16:33.285770 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:33.340266 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:16:33.341345 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:16:33.342001 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:16:33.888674 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:16:33.894514 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 22:16:31.951115 => 22:16:33.893187
[0m22:16:33.896861 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m22:16:33.899979 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8767ef9d-3eb0-4254-9dc3-51ddc95f83bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e38736ca0>]}
[0m22:16:33.902934 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 1.96s]
[0m22:16:33.905247 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m22:16:33.910243 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:33.911516 [debug] [MainThread]: On master: BEGIN
[0m22:16:33.912313 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:16:33.913501 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:33.914355 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:34.245174 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:34.247054 [debug] [MainThread]: On master: COMMIT
[0m22:16:34.248444 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:34.249301 [debug] [MainThread]: On master: COMMIT
[0m22:16:34.297275 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:34.298803 [debug] [MainThread]: On master: Close
[0m22:16:34.301580 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:16:34.302626 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m22:16:34.304017 [info ] [MainThread]: 
[0m22:16:34.305251 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.10 seconds (4.10s).
[0m22:16:34.307486 [debug] [MainThread]: Command end result
[0m22:16:34.337510 [info ] [MainThread]: 
[0m22:16:34.338546 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:16:34.339233 [info ] [MainThread]: 
[0m22:16:34.339990 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:16:34.344658 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9284973, "process_user_time": 4.521218, "process_kernel_time": 0.383287, "process_mem_max_rss": "122146816", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:16:34.345727 [debug] [MainThread]: Command `dbt run` succeeded at 22:16:34.345492 after 4.93 seconds
[0m22:16:34.346427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e48b51820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e59ac0730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e38730eb0>]}
[0m22:16:34.347128 [debug] [MainThread]: Flushing usage events
[0m22:16:40.714115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd790b0d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791cc4ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791cc96d0>]}


============================== 22:16:40.720960 | 5418bfb9-8c8d-4126-9673-77d2994a92c8 ==============================
[0m22:16:40.720960 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:16:40.721798 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:16:41.154941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5418bfb9-8c8d-4126-9673-77d2994a92c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791ca4a30>]}
[0m22:16:41.276114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5418bfb9-8c8d-4126-9673-77d2994a92c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd770147100>]}
[0m22:16:41.278261 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:16:41.294912 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:16:41.366731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:16:41.367367 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:16:41.376949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5418bfb9-8c8d-4126-9673-77d2994a92c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7a1f4fdc0>]}
[0m22:16:41.392437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5418bfb9-8c8d-4126-9673-77d2994a92c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd792025760>]}
[0m22:16:41.393146 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:16:41.393642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5418bfb9-8c8d-4126-9673-77d2994a92c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd792025670>]}
[0m22:16:41.395893 [info ] [MainThread]: 
[0m22:16:41.397143 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:16:41.398654 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:16:41.423301 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:16:41.423939 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:16:41.424411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:16:41.429561 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:41.430200 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:41.905780 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:41.912410 [debug] [ThreadPool]: On list_dev: Close
[0m22:16:41.919318 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:16:41.943836 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:41.944943 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:16:41.945695 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:16:41.947003 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:41.947831 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:42.277696 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:42.278558 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:16:42.279173 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:16:42.355925 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:42.360422 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:16:42.416376 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:16:42.464563 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:42.465289 [debug] [MainThread]: On master: BEGIN
[0m22:16:42.465823 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:16:42.466665 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:42.467194 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:42.802191 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:42.804054 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:42.806239 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:16:42.906369 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:42.910943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5418bfb9-8c8d-4126-9673-77d2994a92c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77019e2e0>]}
[0m22:16:42.913220 [debug] [MainThread]: On master: ROLLBACK
[0m22:16:42.980434 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:42.982047 [debug] [MainThread]: On master: BEGIN
[0m22:16:43.004981 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:43.006886 [debug] [MainThread]: On master: COMMIT
[0m22:16:43.008662 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:43.009975 [debug] [MainThread]: On master: COMMIT
[0m22:16:43.063127 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:43.064402 [debug] [MainThread]: On master: Close
[0m22:16:43.067284 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:16:43.068436 [info ] [MainThread]: 
[0m22:16:43.075829 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:16:43.079657 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:16:43.082444 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:16:43.083947 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:16:43.098632 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:16:43.100936 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:16:43.084773 => 22:16:43.100261
[0m22:16:43.101778 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:16:43.215994 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:43.217608 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp221643155709"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:16:43.218341 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:16:43.219143 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:43.219695 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:43.631844 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:43.681949 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:43.682864 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:16:43.733844 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:43.735053 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:43.736560 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp221643155709'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp221643155709'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp221643155709'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:16:43.888940 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:43.938038 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:43.939269 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:44.097361 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:44.139790 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:44.140802 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:16:44.264774 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:44.314989 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:16:44.322243 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:44.322957 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp221643155709"
            where (
                
                    "dim_outcome__dbt_tmp221643155709".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp221643155709".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp221643155709".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:16:44.445246 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:44.447178 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:44.448818 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp221643155709"
    )
[0m22:16:44.549339 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:44.600165 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:16:44.601287 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:16:44.601973 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:16:45.255953 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:16:45.259129 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:16:43.102275 => 22:16:45.258521
[0m22:16:45.260255 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:16:45.262645 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5418bfb9-8c8d-4126-9673-77d2994a92c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7a1f5b970>]}
[0m22:16:45.264696 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.18s]
[0m22:16:45.265864 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:16:45.268215 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:45.268875 [debug] [MainThread]: On master: BEGIN
[0m22:16:45.269465 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:16:45.270727 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:16:45.271603 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:16:45.616426 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:45.617674 [debug] [MainThread]: On master: COMMIT
[0m22:16:45.618963 [debug] [MainThread]: Using redshift connection "master"
[0m22:16:45.619818 [debug] [MainThread]: On master: COMMIT
[0m22:16:45.675902 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:16:45.677384 [debug] [MainThread]: On master: Close
[0m22:16:45.680870 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:16:45.682734 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:16:45.683989 [info ] [MainThread]: 
[0m22:16:45.684995 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m22:16:45.686831 [debug] [MainThread]: Command end result
[0m22:16:45.718078 [info ] [MainThread]: 
[0m22:16:45.719084 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:16:45.719768 [info ] [MainThread]: 
[0m22:16:45.720527 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:16:45.725014 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.1188655, "process_user_time": 4.500498, "process_kernel_time": 0.377977, "process_mem_max_rss": "120418304", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:16:45.726153 [debug] [MainThread]: Command `dbt run` succeeded at 22:16:45.725895 after 5.12 seconds
[0m22:16:45.726877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd790b0d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd77017bdc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd792025220>]}
[0m22:16:45.727606 [debug] [MainThread]: Flushing usage events
[0m22:16:54.106518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff360c39bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff361c4cca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff361c365b0>]}


============================== 22:16:54.113019 | 51a2a9b6-1b49-4dd3-9ed7-f3fa8ac57bd4 ==============================
[0m22:16:54.113019 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:16:54.113887 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_specifier', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:16:54.657729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '51a2a9b6-1b49-4dd3-9ed7-f3fa8ac57bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff361c24700>]}
[0m22:16:54.777099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '51a2a9b6-1b49-4dd3-9ed7-f3fa8ac57bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff361c2cac0>]}
[0m22:16:54.779164 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:16:54.794778 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:16:54.862750 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:16:54.863297 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:16:54.872725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '51a2a9b6-1b49-4dd3-9ed7-f3fa8ac57bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff381dafdf0>]}
[0m22:16:54.888460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '51a2a9b6-1b49-4dd3-9ed7-f3fa8ac57bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff381cc7790>]}
[0m22:16:54.889165 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:16:54.889660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '51a2a9b6-1b49-4dd3-9ed7-f3fa8ac57bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff381cc76a0>]}
[0m22:16:54.890582 [warn ] [MainThread]: The selection criterion 'dim_specifier' does not match any nodes
[0m22:16:54.891927 [info ] [MainThread]: 
[0m22:16:54.892405 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m22:16:54.893107 [debug] [MainThread]: Command end result
[0m22:16:54.907337 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.91764474, "process_user_time": 3.62865, "process_kernel_time": 0.32609, "process_mem_max_rss": "115331072", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:16:54.908583 [debug] [MainThread]: Command `dbt run` succeeded at 22:16:54.908042 after 0.92 seconds
[0m22:16:54.909167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff360c39bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff381d75c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff361c24700>]}
[0m22:16:54.909699 [debug] [MainThread]: Flushing usage events
[0m22:18:33.890875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b8cffd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a071160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a050a00>]}


============================== 22:18:33.897828 | 24555513-daf4-423a-999a-188d07447c5a ==============================
[0m22:18:33.897828 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:18:33.898663 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m22:18:34.453925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '24555513-daf4-423a-999a-188d07447c5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a071160>]}
[0m22:18:34.573753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '24555513-daf4-423a-999a-188d07447c5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8a81f9f70>]}
[0m22:18:34.575916 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:18:34.592837 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:18:34.664682 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:18:34.665793 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:18:34.857538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24555513-daf4-423a-999a-188d07447c5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b9d13d60>]}
[0m22:18:34.874557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '24555513-daf4-423a-999a-188d07447c5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a3eb8b0>]}
[0m22:18:34.875288 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:18:34.875809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24555513-daf4-423a-999a-188d07447c5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a3eb7c0>]}
[0m22:18:34.877683 [info ] [MainThread]: 
[0m22:18:34.878719 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:18:34.880144 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:18:34.905209 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:18:34.905858 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:18:34.906334 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:18:34.910796 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:18:34.911629 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:18:35.427688 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:18:35.436328 [debug] [ThreadPool]: On list_dev: Close
[0m22:18:35.441569 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:18:35.459424 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:18:35.460163 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:18:35.460725 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:18:35.461611 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:18:35.462214 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:18:35.786944 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:35.789758 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:18:35.791778 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:18:35.855753 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:35.862743 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:18:35.914614 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:18:35.948421 [debug] [MainThread]: Using redshift connection "master"
[0m22:18:35.949209 [debug] [MainThread]: On master: BEGIN
[0m22:18:35.949787 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:18:35.950757 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:18:35.951392 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:18:36.279211 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:36.281397 [debug] [MainThread]: Using redshift connection "master"
[0m22:18:36.282994 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:18:36.415113 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:36.422808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '24555513-daf4-423a-999a-188d07447c5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a3eb610>]}
[0m22:18:36.424692 [debug] [MainThread]: On master: ROLLBACK
[0m22:18:36.500800 [debug] [MainThread]: Using redshift connection "master"
[0m22:18:36.503670 [debug] [MainThread]: On master: BEGIN
[0m22:18:36.528712 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:36.531467 [debug] [MainThread]: On master: COMMIT
[0m22:18:36.533096 [debug] [MainThread]: Using redshift connection "master"
[0m22:18:36.533974 [debug] [MainThread]: On master: COMMIT
[0m22:18:36.582044 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:36.583590 [debug] [MainThread]: On master: Close
[0m22:18:36.586909 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:18:36.588244 [info ] [MainThread]: 
[0m22:18:36.593459 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:18:36.594598 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:18:36.596043 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:18:36.596810 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:18:36.606464 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:18:36.608572 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:18:36.597259 => 22:18:36.607888
[0m22:18:36.609531 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:18:36.710200 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:36.710896 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp221836657885"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,traded_ind::int
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:18:36.711439 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:18:36.712170 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:18:36.712710 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:18:40.043388 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m22:18:40.069293 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:40.069899 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:18:40.115795 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:40.116329 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:40.117045 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp221836657885'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp221836657885'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp221836657885'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:18:40.278018 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:40.315655 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:40.316658 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:18:40.473771 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:40.517430 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:40.518490 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:18:40.639317 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:40.681645 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:18:40.688765 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:40.689412 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp221836657885"
            where (
                
                    "dim_outcome__dbt_tmp221836657885".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp221836657885".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp221836657885".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:18:40.808724 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:40.810571 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:40.811866 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp221836657885"
    )
[0m22:18:40.902881 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:40.947799 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:18:40.948644 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:18:40.949244 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:18:41.687938 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:18:41.693380 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:18:36.610020 => 22:18:41.692593
[0m22:18:41.694737 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:18:41.697515 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '24555513-daf4-423a-999a-188d07447c5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b9da4ca0>]}
[0m22:18:41.699496 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 5.10s]
[0m22:18:41.700670 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:18:41.703029 [debug] [MainThread]: Using redshift connection "master"
[0m22:18:41.703640 [debug] [MainThread]: On master: BEGIN
[0m22:18:41.704182 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:18:41.705292 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:18:41.706137 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:18:42.047676 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:42.050815 [debug] [MainThread]: On master: COMMIT
[0m22:18:42.052240 [debug] [MainThread]: Using redshift connection "master"
[0m22:18:42.053226 [debug] [MainThread]: On master: COMMIT
[0m22:18:42.107581 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:18:42.110567 [debug] [MainThread]: On master: Close
[0m22:18:42.115068 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:18:42.116287 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:18:42.117646 [info ] [MainThread]: 
[0m22:18:42.119417 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.24 seconds (7.24s).
[0m22:18:42.121589 [debug] [MainThread]: Command end result
[0m22:18:42.202828 [info ] [MainThread]: 
[0m22:18:42.203471 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:18:42.203931 [info ] [MainThread]: 
[0m22:18:42.204414 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:18:42.207264 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.424939, "process_user_time": 4.650002, "process_kernel_time": 0.426261, "process_mem_max_rss": "127025152", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:18:42.208077 [debug] [MainThread]: Command `dbt run` succeeded at 22:18:42.207880 after 8.43 seconds
[0m22:18:42.208614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8b8cffd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a270eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe89a59ef10>]}
[0m22:18:42.209154 [debug] [MainThread]: Flushing usage events
[0m22:25:18.222706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc08f96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1579c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc154a2b0>]}


============================== 22:25:18.229114 | f5bcda25-f0bf-4220-8524-9e03604636e6 ==============================
[0m22:25:18.229114 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:25:18.229973 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_market', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:25:18.787571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f5bcda25-f0bf-4220-8524-9e03604636e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1554070>]}
[0m22:25:18.906622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f5bcda25-f0bf-4220-8524-9e03604636e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfe064b220>]}
[0m22:25:18.908714 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:25:18.925406 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:25:18.996383 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:25:18.997274 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:25:19.191301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f5bcda25-f0bf-4220-8524-9e03604636e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfd23530d0>]}
[0m22:25:19.209403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f5bcda25-f0bf-4220-8524-9e03604636e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc18b87f0>]}
[0m22:25:19.210188 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:25:19.210877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f5bcda25-f0bf-4220-8524-9e03604636e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc18b8730>]}
[0m22:25:19.213055 [info ] [MainThread]: 
[0m22:25:19.214197 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:25:19.215621 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:25:19.240634 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:25:19.241255 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:25:19.241718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:25:19.246713 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:19.247337 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:19.753560 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:25:19.758708 [debug] [ThreadPool]: On list_dev: Close
[0m22:25:19.763568 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:25:19.780818 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:19.781479 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:25:19.782030 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:25:19.782878 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:19.783463 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:20.115881 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:20.117176 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:20.118116 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:25:20.189533 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:20.198659 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:25:20.249422 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:25:20.289392 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:20.290326 [debug] [MainThread]: On master: BEGIN
[0m22:25:20.290975 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:25:20.291994 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:20.292717 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:20.665379 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:20.668228 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:20.670682 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:25:20.773722 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:20.777356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f5bcda25-f0bf-4220-8524-9e03604636e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfe06a58b0>]}
[0m22:25:20.778766 [debug] [MainThread]: On master: ROLLBACK
[0m22:25:20.852706 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:20.854795 [debug] [MainThread]: On master: BEGIN
[0m22:25:20.883911 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:20.885776 [debug] [MainThread]: On master: COMMIT
[0m22:25:20.887356 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:20.888363 [debug] [MainThread]: On master: COMMIT
[0m22:25:20.936025 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:20.938400 [debug] [MainThread]: On master: Close
[0m22:25:20.942543 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:25:20.943837 [info ] [MainThread]: 
[0m22:25:20.951831 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m22:25:20.954557 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m22:25:20.958464 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m22:25:20.960385 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m22:25:20.971328 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m22:25:20.973043 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 22:25:20.961212 => 22:25:20.972454
[0m22:25:20.973861 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m22:25:21.072506 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:21.073165 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp222521021152"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m22:25:21.073697 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:25:21.074398 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:21.074908 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:21.472085 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:21.526194 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:21.527102 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m22:25:21.589652 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:21.591508 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:21.593151 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp222521021152'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp222521021152'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp222521021152'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:25:21.746991 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:21.779973 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:21.780882 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:21.931099 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:21.982762 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:21.983992 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:22.103151 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:22.154040 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m22:25:22.160909 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:22.161677 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp222521021152"
            where (
                
                    "dim_market__dbt_tmp222521021152".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp222521021152".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m22:25:22.289536 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:22.292289 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:22.294232 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp222521021152"
    )
[0m22:25:22.407705 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:22.458308 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:25:22.459438 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:25:22.460103 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:25:23.126687 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:25:23.130752 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 22:25:20.974347 => 22:25:23.129986
[0m22:25:23.132550 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m22:25:23.136240 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f5bcda25-f0bf-4220-8524-9e03604636e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfd245dcd0>]}
[0m22:25:23.139921 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.18s]
[0m22:25:23.144448 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m22:25:23.150267 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:23.152028 [debug] [MainThread]: On master: BEGIN
[0m22:25:23.153454 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:25:23.155146 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:23.156107 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:23.609994 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:23.611232 [debug] [MainThread]: On master: COMMIT
[0m22:25:23.612257 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:23.613043 [debug] [MainThread]: On master: COMMIT
[0m22:25:23.679218 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:23.680470 [debug] [MainThread]: On master: Close
[0m22:25:23.682643 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:25:23.683436 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m22:25:23.684537 [info ] [MainThread]: 
[0m22:25:23.685682 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.47 seconds (4.47s).
[0m22:25:23.688452 [debug] [MainThread]: Command end result
[0m22:25:23.774499 [info ] [MainThread]: 
[0m22:25:23.775121 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:25:23.775564 [info ] [MainThread]: 
[0m22:25:23.776038 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:25:23.778982 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.66883, "process_user_time": 4.741606, "process_kernel_time": 0.398212, "process_mem_max_rss": "131420160", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:25:23.779719 [debug] [MainThread]: Command `dbt run` succeeded at 22:25:23.779542 after 5.67 seconds
[0m22:25:23.780221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc08f96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfd1c58c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1a75c70>]}
[0m22:25:23.780748 [debug] [MainThread]: Flushing usage events
[0m22:25:30.040759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd031435670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0417742e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd04178b370>]}


============================== 22:25:30.047256 | 2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0 ==============================
[0m22:25:30.047256 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:25:30.048097 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_event', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:25:30.452898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0418e7070>]}
[0m22:25:30.572557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0417bb0a0>]}
[0m22:25:30.574162 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:25:30.589760 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:25:30.655544 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:25:30.656169 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:25:30.665747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd01016fe20>]}
[0m22:25:30.681681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd03263f760>]}
[0m22:25:30.682420 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:25:30.682927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd03263f6a0>]}
[0m22:25:30.684834 [info ] [MainThread]: 
[0m22:25:30.685898 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:25:30.687382 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:25:30.711651 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:25:30.712177 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:25:30.712615 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:25:30.717122 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:30.717645 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:31.204449 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:31.212093 [debug] [ThreadPool]: On list_dev: Close
[0m22:25:31.219524 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:25:31.239101 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:31.239793 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:25:31.240333 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:25:31.241166 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:31.241747 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:31.562098 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:31.563247 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:31.564117 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:25:31.633619 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:31.636451 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:25:31.690844 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:25:31.726193 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:31.726774 [debug] [MainThread]: On master: BEGIN
[0m22:25:31.727193 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:25:31.728136 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:31.728683 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:32.060414 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:32.063572 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:32.064627 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:25:32.163155 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:32.168383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd04197f850>]}
[0m22:25:32.170619 [debug] [MainThread]: On master: ROLLBACK
[0m22:25:32.235938 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:32.237827 [debug] [MainThread]: On master: BEGIN
[0m22:25:32.260101 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:32.261577 [debug] [MainThread]: On master: COMMIT
[0m22:25:32.262832 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:32.263771 [debug] [MainThread]: On master: COMMIT
[0m22:25:32.310064 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:32.312627 [debug] [MainThread]: On master: Close
[0m22:25:32.315787 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:25:32.317379 [info ] [MainThread]: 
[0m22:25:32.325205 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m22:25:32.327187 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m22:25:32.329836 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m22:25:32.331167 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m22:25:32.342929 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m22:25:32.344811 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 22:25:32.332220 => 22:25:32.344282
[0m22:25:32.345611 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m22:25:32.448081 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:32.448763 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp222532396147"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m22:25:32.449303 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:25:32.450019 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:32.450540 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:32.845341 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:32.896654 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:32.897500 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m22:25:32.942557 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:32.943491 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:32.944790 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp222532396147'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp222532396147'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp222532396147'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:25:33.096528 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:33.144339 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:33.145458 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:33.292460 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:33.346229 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:33.347323 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:33.468076 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:33.517881 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m22:25:33.523872 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:33.524513 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp222532396147"
            where (
                
                    "dim_event__dbt_tmp222532396147".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m22:25:33.658073 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:33.661225 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:33.663543 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp222532396147"
    )
[0m22:25:33.757665 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:33.803590 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:25:33.804599 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:25:33.805260 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:25:34.367098 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:25:34.373018 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 22:25:32.346088 => 22:25:34.372117
[0m22:25:34.374242 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m22:25:34.376654 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a3d58a8-705c-4ae9-9f4a-a5a58df79cd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd041a666d0>]}
[0m22:25:34.379044 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.05s]
[0m22:25:34.380832 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m22:25:34.384434 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:34.385427 [debug] [MainThread]: On master: BEGIN
[0m22:25:34.386204 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:25:34.387565 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:34.388436 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:34.719786 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:34.722041 [debug] [MainThread]: On master: COMMIT
[0m22:25:34.724293 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:34.726495 [debug] [MainThread]: On master: COMMIT
[0m22:25:34.774010 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:34.775766 [debug] [MainThread]: On master: Close
[0m22:25:34.780185 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:25:34.781505 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m22:25:34.783181 [info ] [MainThread]: 
[0m22:25:34.784876 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.10 seconds (4.10s).
[0m22:25:34.787737 [debug] [MainThread]: Command end result
[0m22:25:34.817160 [info ] [MainThread]: 
[0m22:25:34.818165 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:25:34.818850 [info ] [MainThread]: 
[0m22:25:34.819594 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:25:34.823975 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.887523, "process_user_time": 4.451419, "process_kernel_time": 0.357557, "process_mem_max_rss": "127827968", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:25:34.825113 [debug] [MainThread]: Command `dbt run` succeeded at 22:25:34.824857 after 4.89 seconds
[0m22:25:34.825835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd031435670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd041abe9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0326f58b0>]}
[0m22:25:34.826546 [debug] [MainThread]: Flushing usage events
[0m22:25:41.067392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d8c75d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d9b8ec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d9b84eb0>]}


============================== 22:25:41.073751 | 7a39c66b-3937-486a-a131-22fb9e074b93 ==============================
[0m22:25:41.073751 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:25:41.074572 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_participant', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:25:41.491120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a39c66b-3937-486a-a131-22fb9e074b93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d9b7ab20>]}
[0m22:25:41.609347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a39c66b-3937-486a-a131-22fb9e074b93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d9ba9f10>]}
[0m22:25:41.611320 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:25:41.626797 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:25:41.694253 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:25:41.694859 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:25:41.704226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a39c66b-3937-486a-a131-22fb9e074b93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d9e17e80>]}
[0m22:25:41.719265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a39c66b-3937-486a-a131-22fb9e074b93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ca0a07c0>]}
[0m22:25:41.719959 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:25:41.720465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a39c66b-3937-486a-a131-22fb9e074b93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ca0a0700>]}
[0m22:25:41.722350 [info ] [MainThread]: 
[0m22:25:41.723423 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:25:41.724961 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:25:41.748991 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:25:41.749559 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:25:41.750018 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:25:41.754521 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:41.755036 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:42.215232 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:42.220460 [debug] [ThreadPool]: On list_dev: Close
[0m22:25:42.225171 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:25:42.241111 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:42.241788 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:25:42.242326 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:25:42.243153 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:42.243749 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:42.561157 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:42.563552 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:42.567973 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:25:42.638530 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:42.643812 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:25:42.695890 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:25:42.736190 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:42.737023 [debug] [MainThread]: On master: BEGIN
[0m22:25:42.737671 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:25:42.738663 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:42.739357 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:43.092873 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:43.094703 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:43.095952 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:25:43.197749 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:43.205790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a39c66b-3937-486a-a131-22fb9e074b93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d9db6520>]}
[0m22:25:43.208136 [debug] [MainThread]: On master: ROLLBACK
[0m22:25:43.277586 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:43.278692 [debug] [MainThread]: On master: BEGIN
[0m22:25:43.304612 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:43.305933 [debug] [MainThread]: On master: COMMIT
[0m22:25:43.307674 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:43.308787 [debug] [MainThread]: On master: COMMIT
[0m22:25:43.356132 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:43.359264 [debug] [MainThread]: On master: Close
[0m22:25:43.364561 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:25:43.366377 [info ] [MainThread]: 
[0m22:25:43.374054 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m22:25:43.375879 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m22:25:43.378274 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m22:25:43.380158 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m22:25:43.390999 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m22:25:43.393061 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 22:25:43.381042 => 22:25:43.392472
[0m22:25:43.393908 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m22:25:43.494724 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:43.495433 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp222543443555"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m22:25:43.496015 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:25:43.496751 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:43.497282 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:43.872593 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:43.921762 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:43.922730 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m22:25:43.966313 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:43.967313 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:43.968817 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp222543443555'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp222543443555'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp222543443555'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:25:44.121643 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:44.169660 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:44.170963 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:44.318559 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:44.356896 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:44.357885 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:44.475214 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:44.513475 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m22:25:44.519274 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:44.520108 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp222543443555"
            where (
                
                    "dim_participant__dbt_tmp222543443555".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp222543443555".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m22:25:44.654527 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:44.656935 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:44.659373 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp222543443555"
    )
[0m22:25:44.749643 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:44.797424 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:25:44.798449 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:25:44.799143 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:25:45.425241 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:25:45.428846 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 22:25:43.394405 => 22:25:45.428058
[0m22:25:45.429924 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m22:25:45.432129 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a39c66b-3937-486a-a131-22fb9e074b93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d9f62b50>]}
[0m22:25:45.434755 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 2.05s]
[0m22:25:45.436342 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m22:25:45.439012 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:45.439753 [debug] [MainThread]: On master: BEGIN
[0m22:25:45.440370 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:25:45.441328 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:45.442016 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:45.761432 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:45.763248 [debug] [MainThread]: On master: COMMIT
[0m22:25:45.765068 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:45.766761 [debug] [MainThread]: On master: COMMIT
[0m22:25:45.816978 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:45.818669 [debug] [MainThread]: On master: Close
[0m22:25:45.823142 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:25:45.824671 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m22:25:45.826478 [info ] [MainThread]: 
[0m22:25:45.828228 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.10 seconds (4.10s).
[0m22:25:45.831069 [debug] [MainThread]: Command end result
[0m22:25:45.859279 [info ] [MainThread]: 
[0m22:25:45.860205 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:25:45.860884 [info ] [MainThread]: 
[0m22:25:45.861629 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:25:45.865555 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9029636, "process_user_time": 4.423228, "process_kernel_time": 0.363657, "process_mem_max_rss": "126959616", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:25:45.866616 [debug] [MainThread]: Command `dbt run` succeeded at 22:25:45.866374 after 4.90 seconds
[0m22:25:45.867357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2d8c75d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ca0a0730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ca0a03a0>]}
[0m22:25:45.868070 [debug] [MainThread]: Flushing usage events
[0m22:25:54.198308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa040bbdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa04175df70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa041748ac0>]}


============================== 22:25:54.204538 | 8f791184-071b-4541-9a84-1b1cc05463a1 ==============================
[0m22:25:54.204538 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:25:54.205328 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_event_dtls', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:25:54.709105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8f791184-071b-4541-9a84-1b1cc05463a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa041732400>]}
[0m22:25:54.829767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8f791184-071b-4541-9a84-1b1cc05463a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa052122f10>]}
[0m22:25:54.832031 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:25:54.847439 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:25:54.914676 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:25:54.915249 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:25:54.924781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8f791184-071b-4541-9a84-1b1cc05463a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa02035fe50>]}
[0m22:25:54.939206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f791184-071b-4541-9a84-1b1cc05463a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa041b47790>]}
[0m22:25:54.939887 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:25:54.940384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f791184-071b-4541-9a84-1b1cc05463a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa041b476d0>]}
[0m22:25:54.942223 [info ] [MainThread]: 
[0m22:25:54.943262 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:25:54.944708 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:25:54.968903 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:25:54.969434 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:25:54.969897 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:25:54.974281 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:54.974784 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:55.433610 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:55.439441 [debug] [ThreadPool]: On list_dev: Close
[0m22:25:55.447391 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:25:55.470820 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:55.471691 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:25:55.472340 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:25:55.473347 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:55.474034 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:55.834949 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:55.836303 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:25:55.838139 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:25:55.903159 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:55.908032 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:25:55.963160 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:25:55.994236 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:55.994871 [debug] [MainThread]: On master: BEGIN
[0m22:25:55.995305 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:25:55.995983 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:55.996457 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:56.331911 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:56.333759 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:56.335126 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:25:56.434763 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:56.440676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f791184-071b-4541-9a84-1b1cc05463a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0521440a0>]}
[0m22:25:56.442809 [debug] [MainThread]: On master: ROLLBACK
[0m22:25:56.512634 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:56.514402 [debug] [MainThread]: On master: BEGIN
[0m22:25:56.545416 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:56.546951 [debug] [MainThread]: On master: COMMIT
[0m22:25:56.548264 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:56.549393 [debug] [MainThread]: On master: COMMIT
[0m22:25:56.603993 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:56.604775 [debug] [MainThread]: On master: Close
[0m22:25:56.606240 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:25:56.606867 [info ] [MainThread]: 
[0m22:25:56.610052 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m22:25:56.610932 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m22:25:56.612022 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m22:25:56.612608 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m22:25:56.618952 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m22:25:56.620322 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 22:25:56.612966 => 22:25:56.619925
[0m22:25:56.620894 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m22:25:56.716887 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:56.717593 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp222556665027"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m22:25:56.718149 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:25:56.718876 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:56.719401 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:57.115617 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:57.170596 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:57.171505 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m22:25:57.223033 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:57.224222 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:57.225914 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp222556665027'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp222556665027'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp222556665027'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:25:57.379833 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:57.426063 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:57.427075 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:57.577268 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:57.629069 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:57.630130 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:25:57.750835 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:57.802879 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m22:25:57.808144 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:57.808784 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp222556665027"
            where (
                
                    "dim_event_dtls__dbt_tmp222556665027".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m22:25:57.934609 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:57.937496 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:57.939067 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp222556665027"
    )
[0m22:25:58.032681 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:58.081184 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:25:58.082120 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:25:58.082774 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:25:58.840184 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:25:58.843206 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 22:25:56.621222 => 22:25:58.842590
[0m22:25:58.844238 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m22:25:58.846588 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f791184-071b-4541-9a84-1b1cc05463a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0521f6190>]}
[0m22:25:58.849000 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.23s]
[0m22:25:58.850805 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m22:25:58.855272 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:58.856373 [debug] [MainThread]: On master: BEGIN
[0m22:25:58.857551 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:25:58.859236 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:25:58.860261 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:25:59.195244 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:59.197421 [debug] [MainThread]: On master: COMMIT
[0m22:25:59.199691 [debug] [MainThread]: Using redshift connection "master"
[0m22:25:59.201810 [debug] [MainThread]: On master: COMMIT
[0m22:25:59.253789 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:25:59.256509 [debug] [MainThread]: On master: Close
[0m22:25:59.261286 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:25:59.263254 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m22:25:59.265403 [info ] [MainThread]: 
[0m22:25:59.267017 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.32 seconds (4.32s).
[0m22:25:59.270145 [debug] [MainThread]: Command end result
[0m22:25:59.298477 [info ] [MainThread]: 
[0m22:25:59.299418 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:25:59.300112 [info ] [MainThread]: 
[0m22:25:59.300775 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:25:59.304720 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.211483, "process_user_time": 4.476303, "process_kernel_time": 0.373702, "process_mem_max_rss": "124633088", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:25:59.305772 [debug] [MainThread]: Command `dbt run` succeeded at 22:25:59.305532 after 5.21 seconds
[0m22:25:59.306474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa040bbdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa041bfdcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa041bfd850>]}
[0m22:25:59.307153 [debug] [MainThread]: Flushing usage events
[0m22:26:06.937092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa540ac5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5512b5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa55129fe20>]}


============================== 22:26:06.943107 | 95783e21-6005-4496-972e-1b1216424e66 ==============================
[0m22:26:06.943107 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:26:06.943922 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_group', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:26:07.741969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '95783e21-6005-4496-972e-1b1216424e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5419ac7f0>]}
[0m22:26:07.864980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '95783e21-6005-4496-972e-1b1216424e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa541a725e0>]}
[0m22:26:07.866547 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:26:07.883038 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:26:07.954525 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:26:07.955138 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:26:07.966401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '95783e21-6005-4496-972e-1b1216424e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa541b87e20>]}
[0m22:26:07.991661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '95783e21-6005-4496-972e-1b1216424e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa55167f7c0>]}
[0m22:26:07.993161 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:26:07.993735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95783e21-6005-4496-972e-1b1216424e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa55167f6d0>]}
[0m22:26:07.996447 [info ] [MainThread]: 
[0m22:26:07.999082 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:26:08.008057 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:26:08.034308 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:26:08.034952 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:26:08.035416 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:26:08.040019 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:08.040567 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:08.521391 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:08.526912 [debug] [ThreadPool]: On list_dev: Close
[0m22:26:08.533075 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:26:08.551640 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:26:08.552566 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:26:08.553144 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:26:08.554023 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:08.554613 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:08.878617 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:08.880176 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:26:08.881342 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:26:08.950707 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:08.956030 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:26:09.008597 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:26:09.047953 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:09.048831 [debug] [MainThread]: On master: BEGIN
[0m22:26:09.049489 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:26:09.050505 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:09.051198 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:09.391919 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:09.394462 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:09.396748 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:26:09.499647 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:09.509184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '95783e21-6005-4496-972e-1b1216424e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa551557e50>]}
[0m22:26:09.512062 [debug] [MainThread]: On master: ROLLBACK
[0m22:26:09.580328 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:09.582466 [debug] [MainThread]: On master: BEGIN
[0m22:26:09.609909 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:09.612312 [debug] [MainThread]: On master: COMMIT
[0m22:26:09.615023 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:09.617193 [debug] [MainThread]: On master: COMMIT
[0m22:26:09.667623 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:09.670885 [debug] [MainThread]: On master: Close
[0m22:26:09.675174 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:26:09.676463 [info ] [MainThread]: 
[0m22:26:09.682520 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m22:26:09.684685 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m22:26:09.686925 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m22:26:09.688186 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m22:26:09.699947 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m22:26:09.701899 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 22:26:09.688861 => 22:26:09.701319
[0m22:26:09.702684 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m22:26:09.810254 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:09.810959 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp222609756528"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m22:26:09.811503 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:26:09.812231 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:09.812854 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:10.192617 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:10.243181 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:10.244062 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m22:26:10.291870 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:10.292923 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:10.294345 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp222609756528'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp222609756528'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp222609756528'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:26:10.469724 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:10.511310 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:10.512570 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:26:10.657648 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:10.710666 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:10.712024 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:26:10.830046 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:10.887567 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m22:26:10.893220 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:10.893906 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp222609756528"
            where (
                
                    "dim_group__dbt_tmp222609756528".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp222609756528".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m22:26:11.030919 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:11.032969 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:11.034310 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp222609756528"
    )
[0m22:26:11.131515 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:11.184149 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:26:11.185178 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:26:11.185852 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:26:11.846938 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:26:11.853730 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 22:26:09.703120 => 22:26:11.852646
[0m22:26:11.855748 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m22:26:11.859399 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95783e21-6005-4496-972e-1b1216424e66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa560bfe850>]}
[0m22:26:11.862814 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.17s]
[0m22:26:11.864887 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m22:26:11.867524 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:11.868055 [debug] [MainThread]: On master: BEGIN
[0m22:26:11.868499 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:26:11.869456 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:11.869929 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:12.189909 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:12.192048 [debug] [MainThread]: On master: COMMIT
[0m22:26:12.193612 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:12.194545 [debug] [MainThread]: On master: COMMIT
[0m22:26:12.240719 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:12.241931 [debug] [MainThread]: On master: Close
[0m22:26:12.245128 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:26:12.246576 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m22:26:12.248446 [info ] [MainThread]: 
[0m22:26:12.249524 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.25 seconds (4.25s).
[0m22:26:12.252520 [debug] [MainThread]: Command end result
[0m22:26:12.277915 [info ] [MainThread]: 
[0m22:26:12.278659 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:26:12.279349 [info ] [MainThread]: 
[0m22:26:12.280078 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:26:12.284057 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.4539757, "process_user_time": 4.688161, "process_kernel_time": 0.416869, "process_mem_max_rss": "104456192", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:26:12.285256 [debug] [MainThread]: Command `dbt run` succeeded at 22:26:12.285036 after 5.46 seconds
[0m22:26:12.288587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa540ac5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa55167f670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa55184a8e0>]}
[0m22:26:12.289387 [debug] [MainThread]: Flushing usage events
[0m22:26:19.139420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfb1109820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfa1915250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfa18ec640>]}


============================== 22:26:19.147472 | f15be5f6-cd15-4a92-9510-ff7f6246605c ==============================
[0m22:26:19.147472 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:26:19.148335 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m22:26:19.686298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f15be5f6-cd15-4a92-9510-ff7f6246605c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfa18e37c0>]}
[0m22:26:19.809966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f15be5f6-cd15-4a92-9510-ff7f6246605c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf90900070>]}
[0m22:26:19.812229 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:26:19.828818 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:26:19.897533 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:26:19.898132 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:26:19.907617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f15be5f6-cd15-4a92-9510-ff7f6246605c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfb1ab7ee0>]}
[0m22:26:19.923298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f15be5f6-cd15-4a92-9510-ff7f6246605c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfa1c18880>]}
[0m22:26:19.923996 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:26:19.924499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f15be5f6-cd15-4a92-9510-ff7f6246605c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfa1c18790>]}
[0m22:26:19.926422 [info ] [MainThread]: 
[0m22:26:19.927487 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:26:19.929024 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:26:19.953656 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:26:19.954197 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:26:19.954670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:26:19.959164 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:19.959669 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:20.451604 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:20.455223 [debug] [ThreadPool]: On list_dev: Close
[0m22:26:20.459668 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:26:20.477259 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:26:20.478090 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:26:20.478624 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:26:20.479421 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:20.479948 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:20.797266 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:20.800053 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:26:20.801591 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:26:20.866942 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:20.875001 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:26:20.933383 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:26:20.975403 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:20.976263 [debug] [MainThread]: On master: BEGIN
[0m22:26:20.976909 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:26:20.977882 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:20.978568 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:21.316160 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:21.319168 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:21.323063 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:26:21.428683 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:21.436482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f15be5f6-cd15-4a92-9510-ff7f6246605c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfb1a49370>]}
[0m22:26:21.439262 [debug] [MainThread]: On master: ROLLBACK
[0m22:26:21.512183 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:21.513869 [debug] [MainThread]: On master: BEGIN
[0m22:26:21.538022 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:21.539350 [debug] [MainThread]: On master: COMMIT
[0m22:26:21.540493 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:21.541344 [debug] [MainThread]: On master: COMMIT
[0m22:26:21.589686 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:21.592018 [debug] [MainThread]: On master: Close
[0m22:26:21.595555 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:26:21.597110 [info ] [MainThread]: 
[0m22:26:21.603733 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:26:21.605694 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:26:21.607840 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:26:21.609321 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:26:21.623053 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:26:21.624402 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:26:21.610190 => 22:26:21.623976
[0m22:26:21.624983 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:26:21.794007 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:21.795005 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp222621710122"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:26:21.795729 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:26:21.796937 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:21.797685 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:22.191442 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:22.227361 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:22.228108 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:26:22.276311 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:22.277196 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:22.278312 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp222621710122'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp222621710122'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp222621710122'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:26:22.429590 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:22.479262 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:22.480753 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:26:22.640581 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:22.686223 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:22.687593 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:26:22.811473 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:22.866238 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:26:22.874125 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:22.874874 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp222621710122"
            where (
                
                    "dim_outcome__dbt_tmp222621710122".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp222621710122".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp222621710122".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:26:22.999055 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:23.000917 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:23.002048 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp222621710122"
    )
[0m22:26:23.129269 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:23.178061 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:26:23.179087 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:26:23.179757 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:26:23.831491 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:26:23.837661 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:26:21.625393 => 22:26:23.836905
[0m22:26:23.839369 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:26:23.843654 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f15be5f6-cd15-4a92-9510-ff7f6246605c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfb1bca8b0>]}
[0m22:26:23.847050 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.24s]
[0m22:26:23.849197 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:26:23.855586 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:23.856927 [debug] [MainThread]: On master: BEGIN
[0m22:26:23.858161 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:26:23.859438 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:26:23.859938 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:26:24.181960 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:24.183795 [debug] [MainThread]: On master: COMMIT
[0m22:26:24.185460 [debug] [MainThread]: Using redshift connection "master"
[0m22:26:24.187202 [debug] [MainThread]: On master: COMMIT
[0m22:26:24.236162 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:26:24.237725 [debug] [MainThread]: On master: Close
[0m22:26:24.240128 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:26:24.241249 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:26:24.242434 [info ] [MainThread]: 
[0m22:26:24.243570 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.32 seconds (4.32s).
[0m22:26:24.246215 [debug] [MainThread]: Command end result
[0m22:26:24.272501 [info ] [MainThread]: 
[0m22:26:24.273387 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:26:24.274203 [info ] [MainThread]: 
[0m22:26:24.275052 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:26:24.279616 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.30114, "process_user_time": 4.703378, "process_kernel_time": 0.425625, "process_mem_max_rss": "115482624", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:26:24.280951 [debug] [MainThread]: Command `dbt run` succeeded at 22:26:24.280698 after 5.30 seconds
[0m22:26:24.281710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfb1109820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfa1c18730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfb1bbf8b0>]}
[0m22:26:24.282430 [debug] [MainThread]: Flushing usage events
[0m22:26:32.912533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c8a9d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9c0c2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9c23370>]}


============================== 22:26:32.918794 | d7b706a5-b673-4ea0-8fab-6debd126758c ==============================
[0m22:26:32.918794 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:26:32.919656 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_specifier', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:26:33.424366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd7b706a5-b673-4ea0-8fab-6debd126758c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9d40fa0>]}
[0m22:26:33.546610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd7b706a5-b673-4ea0-8fab-6debd126758c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c97220a0>]}
[0m22:26:33.548741 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:26:33.564416 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:26:33.634292 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:26:33.634864 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:26:33.644517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd7b706a5-b673-4ea0-8fab-6debd126758c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3a866fe20>]}
[0m22:26:33.661119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd7b706a5-b673-4ea0-8fab-6debd126758c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9ff7760>]}
[0m22:26:33.661846 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:26:33.662350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd7b706a5-b673-4ea0-8fab-6debd126758c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3b9ff76a0>]}
[0m22:26:33.663294 [warn ] [MainThread]: The selection criterion 'dim_specifier' does not match any nodes
[0m22:26:33.664670 [info ] [MainThread]: 
[0m22:26:33.665140 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m22:26:33.666169 [debug] [MainThread]: Command end result
[0m22:26:33.680026 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8740373, "process_user_time": 3.606126, "process_kernel_time": 0.31631, "process_mem_max_rss": "116793344", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:26:33.681363 [debug] [MainThread]: Command `dbt run` succeeded at 22:26:33.680816 after 0.88 seconds
[0m22:26:33.681966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c8a9d670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c97220a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3c99a7850>]}
[0m22:26:33.682536 [debug] [MainThread]: Flushing usage events
[0m22:28:59.700089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6112bfd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd611ea0e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd611ecca90>]}


============================== 22:28:59.706821 | 0377b029-781f-4730-8383-5b8bf074ba11 ==============================
[0m22:28:59.706821 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:28:59.707669 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m22:29:00.272556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0377b029-781f-4730-8383-5b8bf074ba11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd611ecc4c0>]}
[0m22:29:00.392983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0377b029-781f-4730-8383-5b8bf074ba11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd612109190>]}
[0m22:29:00.395012 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:29:00.412167 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:29:00.491229 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:29:00.491849 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:29:00.501306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0377b029-781f-4730-8383-5b8bf074ba11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd601da7f70>]}
[0m22:29:00.517820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0377b029-781f-4730-8383-5b8bf074ba11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61224b910>]}
[0m22:29:00.518557 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:29:00.519084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0377b029-781f-4730-8383-5b8bf074ba11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd61224b820>]}
[0m22:29:00.521036 [info ] [MainThread]: 
[0m22:29:00.522124 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:29:00.523633 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:29:00.549032 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:29:00.549688 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:29:00.550165 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:29:00.554830 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:29:00.555705 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:29:01.085146 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:29:01.092746 [debug] [ThreadPool]: On list_dev: Close
[0m22:29:01.097857 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:29:01.117548 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:29:01.118413 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:29:01.119029 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:29:01.120009 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:29:01.120781 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:29:01.449565 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:01.452505 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:29:01.454615 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:29:01.523101 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:01.530196 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:29:01.583417 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:29:01.615323 [debug] [MainThread]: Using redshift connection "master"
[0m22:29:01.616115 [debug] [MainThread]: On master: BEGIN
[0m22:29:01.616697 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:29:01.617589 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:29:01.618197 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:29:01.944947 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:01.945759 [debug] [MainThread]: Using redshift connection "master"
[0m22:29:01.946501 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:29:02.042176 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:02.046433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0377b029-781f-4730-8383-5b8bf074ba11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd601c39a60>]}
[0m22:29:02.047417 [debug] [MainThread]: On master: ROLLBACK
[0m22:29:02.112887 [debug] [MainThread]: Using redshift connection "master"
[0m22:29:02.114753 [debug] [MainThread]: On master: BEGIN
[0m22:29:02.138328 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:02.140493 [debug] [MainThread]: On master: COMMIT
[0m22:29:02.142675 [debug] [MainThread]: Using redshift connection "master"
[0m22:29:02.144421 [debug] [MainThread]: On master: COMMIT
[0m22:29:02.193863 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:02.195364 [debug] [MainThread]: On master: Close
[0m22:29:02.198562 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:29:02.199539 [info ] [MainThread]: 
[0m22:29:02.205403 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:29:02.207008 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:29:02.208976 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:29:02.210003 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:29:02.225134 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:29:02.229675 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:29:02.210538 => 22:29:02.228430
[0m22:29:02.231997 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:29:02.370628 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:02.371421 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp222902310145"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:29:02.372054 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:29:02.372885 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:29:02.373479 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:29:02.779770 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:02.822350 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:02.823100 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:29:02.870593 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:02.871660 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:02.872806 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp222902310145'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp222902310145'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp222902310145'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:29:03.019309 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:03.058849 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:03.060001 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:29:03.213677 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:03.256374 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:03.257428 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:29:03.373323 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:03.413263 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:29:03.421211 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:03.421814 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp222902310145"
            where (
                
                    "dim_outcome__dbt_tmp222902310145".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp222902310145".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp222902310145".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:29:03.543148 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:03.545491 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:03.547279 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp222902310145"
    )
[0m22:29:03.641998 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:03.681806 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:29:03.682782 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:29:03.683379 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:29:04.595277 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:29:04.598059 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:29:02.233204 => 22:29:04.597459
[0m22:29:04.599132 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:29:04.601459 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0377b029-781f-4730-8383-5b8bf074ba11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5f029cc10>]}
[0m22:29:04.603960 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.39s]
[0m22:29:04.605328 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:29:04.608043 [debug] [MainThread]: Using redshift connection "master"
[0m22:29:04.608782 [debug] [MainThread]: On master: BEGIN
[0m22:29:04.609444 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:29:04.610460 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:29:04.611175 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:29:04.931686 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:04.933833 [debug] [MainThread]: On master: COMMIT
[0m22:29:04.935466 [debug] [MainThread]: Using redshift connection "master"
[0m22:29:04.936516 [debug] [MainThread]: On master: COMMIT
[0m22:29:04.985984 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:29:04.988371 [debug] [MainThread]: On master: Close
[0m22:29:04.991975 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:29:04.993387 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:29:04.994860 [info ] [MainThread]: 
[0m22:29:04.995854 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.47 seconds (4.47s).
[0m22:29:04.997551 [debug] [MainThread]: Command end result
[0m22:29:05.021086 [info ] [MainThread]: 
[0m22:29:05.021944 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:29:05.022561 [info ] [MainThread]: 
[0m22:29:05.023231 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:29:05.026849 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.4333887, "process_user_time": 4.494495, "process_kernel_time": 0.385567, "process_mem_max_rss": "119713792", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:29:05.028205 [debug] [MainThread]: Command `dbt run` succeeded at 22:29:05.027885 after 5.44 seconds
[0m22:29:05.029497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6112bfd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd601ca20d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd601ea8c40>]}
[0m22:29:05.030222 [debug] [MainThread]: Flushing usage events
[0m22:32:00.428032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac8bbffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac9848c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac983edf0>]}


============================== 22:32:00.434866 | 79fb8eca-72ab-4bce-b80c-b4baed1038c8 ==============================
[0m22:32:00.434866 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:32:00.435765 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:32:00.994005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '79fb8eca-72ab-4bce-b80c-b4baed1038c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbafa3d4640>]}
[0m22:32:01.112514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '79fb8eca-72ab-4bce-b80c-b4baed1038c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbad81dba30>]}
[0m22:32:01.114067 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:32:01.130851 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:32:01.207402 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:32:01.208323 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:32:01.402215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79fb8eca-72ab-4bce-b80c-b4baed1038c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac9d1be20>]}
[0m22:32:01.417898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79fb8eca-72ab-4bce-b80c-b4baed1038c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac9c43910>]}
[0m22:32:01.418617 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:32:01.419139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79fb8eca-72ab-4bce-b80c-b4baed1038c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac9c43850>]}
[0m22:32:01.421034 [info ] [MainThread]: 
[0m22:32:01.422087 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:32:01.423487 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:32:01.448418 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:32:01.449048 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:32:01.449537 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:32:01.454087 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:32:01.454913 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:32:01.988300 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:32:01.995941 [debug] [ThreadPool]: On list_dev: Close
[0m22:32:02.001263 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:32:02.019190 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:32:02.019895 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:32:02.020483 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:32:02.021398 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:32:02.022015 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:32:02.360664 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:02.364111 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:32:02.366878 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:32:02.436552 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:02.443482 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:32:02.504098 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:32:02.529898 [debug] [MainThread]: Using redshift connection "master"
[0m22:32:02.530590 [debug] [MainThread]: On master: BEGIN
[0m22:32:02.531095 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:32:02.531860 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:32:02.532412 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:32:02.851741 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:02.852466 [debug] [MainThread]: Using redshift connection "master"
[0m22:32:02.853125 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:32:02.957409 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:02.960510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79fb8eca-72ab-4bce-b80c-b4baed1038c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac9ac8ca0>]}
[0m22:32:02.961667 [debug] [MainThread]: On master: ROLLBACK
[0m22:32:03.028324 [debug] [MainThread]: Using redshift connection "master"
[0m22:32:03.030619 [debug] [MainThread]: On master: BEGIN
[0m22:32:03.053529 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:03.055463 [debug] [MainThread]: On master: COMMIT
[0m22:32:03.057087 [debug] [MainThread]: Using redshift connection "master"
[0m22:32:03.058537 [debug] [MainThread]: On master: COMMIT
[0m22:32:03.169328 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:03.172003 [debug] [MainThread]: On master: Close
[0m22:32:03.175797 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:32:03.177226 [info ] [MainThread]: 
[0m22:32:03.183307 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:32:03.184763 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:32:03.186675 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:32:03.187754 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:32:03.197697 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:32:03.199700 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:32:03.188379 => 22:32:03.199148
[0m22:32:03.200564 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:32:03.298993 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:03.299735 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp223203246653"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,traded_ind::INT
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:32:03.300308 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:32:03.301043 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:32:03.301588 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:32:03.989434 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:32:04.029493 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:04.030198 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:32:04.073579 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:04.074283 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:04.075372 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp223203246653'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp223203246653'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp223203246653'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:32:04.286028 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:04.325608 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:04.326812 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:32:04.485943 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:04.528431 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:04.529563 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:32:04.651644 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:04.690508 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:32:04.697317 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:04.698004 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp223203246653"
            where (
                
                    "dim_outcome__dbt_tmp223203246653".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp223203246653".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp223203246653".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:32:04.830264 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:04.831577 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:04.832619 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp223203246653"
    )
[0m22:32:04.919764 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:04.962096 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:32:04.963054 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:32:04.963677 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:32:05.539872 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:32:05.544221 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:32:03.201062 => 22:32:05.543505
[0m22:32:05.546016 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:32:05.549144 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79fb8eca-72ab-4bce-b80c-b4baed1038c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbafa5996d0>]}
[0m22:32:05.551597 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.36s]
[0m22:32:05.553269 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:32:05.556643 [debug] [MainThread]: Using redshift connection "master"
[0m22:32:05.557481 [debug] [MainThread]: On master: BEGIN
[0m22:32:05.558268 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:32:05.559378 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:32:05.560142 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:32:05.895010 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:05.897479 [debug] [MainThread]: On master: COMMIT
[0m22:32:05.899065 [debug] [MainThread]: Using redshift connection "master"
[0m22:32:05.899967 [debug] [MainThread]: On master: COMMIT
[0m22:32:05.947604 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:32:05.950229 [debug] [MainThread]: On master: Close
[0m22:32:05.955249 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:32:05.956201 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:32:05.957775 [info ] [MainThread]: 
[0m22:32:05.959331 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.54 seconds (4.54s).
[0m22:32:05.961152 [debug] [MainThread]: Command end result
[0m22:32:06.041903 [info ] [MainThread]: 
[0m22:32:06.042543 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:32:06.043008 [info ] [MainThread]: 
[0m22:32:06.043502 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:32:06.046532 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.724488, "process_user_time": 4.636292, "process_kernel_time": 0.429688, "process_mem_max_rss": "127864832", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:32:06.047384 [debug] [MainThread]: Command `dbt run` succeeded at 22:32:06.047176 after 5.73 seconds
[0m22:32:06.047956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac8bbffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbafa5bda30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbac9cb1310>]}
[0m22:32:06.048525 [debug] [MainThread]: Flushing usage events
[0m22:34:02.595374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff601179820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff601c20250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff601bf4640>]}


============================== 22:34:02.602800 | 0faa83a0-89d4-4aae-9de7-dfc99ed2fded ==============================
[0m22:34:02.602800 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:34:02.603725 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_market', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:34:03.162523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0faa83a0-89d4-4aae-9de7-dfc99ed2fded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff601bea7c0>]}
[0m22:34:03.287846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0faa83a0-89d4-4aae-9de7-dfc99ed2fded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff611968070>]}
[0m22:34:03.290222 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:34:03.310108 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:34:03.389408 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:34:03.390434 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:34:03.607586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0faa83a0-89d4-4aae-9de7-dfc99ed2fded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5e05230a0>]}
[0m22:34:03.628829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0faa83a0-89d4-4aae-9de7-dfc99ed2fded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff601f7e820>]}
[0m22:34:03.629710 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:34:03.630236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0faa83a0-89d4-4aae-9de7-dfc99ed2fded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff601f7e760>]}
[0m22:34:03.632365 [info ] [MainThread]: 
[0m22:34:03.633504 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:34:03.635025 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:34:03.662496 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:34:03.663358 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:34:03.663992 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:03.669361 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:03.670619 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:04.222601 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:04.227961 [debug] [ThreadPool]: On list_dev: Close
[0m22:34:04.236017 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:34:04.259055 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:04.259948 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:34:04.260593 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:34:04.261575 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:04.262281 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:04.761349 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:04.763916 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:04.766259 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:34:04.837289 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:04.842362 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:34:04.894069 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:34:04.934747 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:04.935709 [debug] [MainThread]: On master: BEGIN
[0m22:34:04.936378 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:04.937450 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:04.938177 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:05.273990 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:05.276967 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:05.279827 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:34:05.383651 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:05.389459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0faa83a0-89d4-4aae-9de7-dfc99ed2fded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6119eee80>]}
[0m22:34:05.391268 [debug] [MainThread]: On master: ROLLBACK
[0m22:34:05.460577 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:05.461871 [debug] [MainThread]: On master: BEGIN
[0m22:34:05.484306 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:05.485711 [debug] [MainThread]: On master: COMMIT
[0m22:34:05.487080 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:05.488017 [debug] [MainThread]: On master: COMMIT
[0m22:34:05.538298 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:05.540618 [debug] [MainThread]: On master: Close
[0m22:34:05.544574 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:05.546211 [info ] [MainThread]: 
[0m22:34:05.553517 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m22:34:05.555727 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m22:34:05.558052 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m22:34:05.559345 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m22:34:05.573683 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m22:34:05.575900 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 22:34:05.560689 => 22:34:05.575250
[0m22:34:05.576856 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m22:34:05.677491 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:05.678266 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp223405625038"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line = true then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable = true then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m22:34:05.678836 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:05.679762 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:05.680342 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:06.058630 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:06.090569 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:06.091314 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m22:34:06.148006 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:06.148696 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:06.149457 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp223405625038'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp223405625038'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp223405625038'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:34:06.306477 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:06.354772 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:06.355909 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:06.504212 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:06.539639 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:06.540587 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:06.660865 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:06.688996 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m22:34:06.693927 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:06.694548 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp223405625038"
            where (
                
                    "dim_market__dbt_tmp223405625038".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp223405625038".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m22:34:06.810891 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:06.813093 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:06.814353 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp223405625038"
    )
[0m22:34:06.898535 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:06.955004 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:34:06.956026 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:34:06.956685 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:34:07.809356 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:07.816637 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 22:34:05.577329 => 22:34:07.815311
[0m22:34:07.818845 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m22:34:07.823505 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0faa83a0-89d4-4aae-9de7-dfc99ed2fded', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff60219ec70>]}
[0m22:34:07.827153 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.27s]
[0m22:34:07.829865 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m22:34:07.835551 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:07.836991 [debug] [MainThread]: On master: BEGIN
[0m22:34:07.837931 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:34:07.839295 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:07.840167 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:08.188869 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:08.190745 [debug] [MainThread]: On master: COMMIT
[0m22:34:08.192651 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:08.194444 [debug] [MainThread]: On master: COMMIT
[0m22:34:08.248220 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:08.250146 [debug] [MainThread]: On master: Close
[0m22:34:08.253320 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:08.254524 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m22:34:08.255938 [info ] [MainThread]: 
[0m22:34:08.257204 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.62 seconds (4.62s).
[0m22:34:08.261092 [debug] [MainThread]: Command end result
[0m22:34:08.359395 [info ] [MainThread]: 
[0m22:34:08.360432 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:34:08.360978 [info ] [MainThread]: 
[0m22:34:08.361496 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:34:08.364610 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.876664, "process_user_time": 4.829144, "process_kernel_time": 0.441828, "process_mem_max_rss": "124583936", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:34:08.365610 [debug] [MainThread]: Command `dbt run` succeeded at 22:34:08.365401 after 5.88 seconds
[0m22:34:08.366178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff601179820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5e03dfc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6119eeca0>]}
[0m22:34:08.366760 [debug] [MainThread]: Flushing usage events
[0m22:34:15.078781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0980a9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c9decca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c9dd55b0>]}


============================== 22:34:15.085243 | 90e5368f-d6a5-4b8d-9a07-f9101825c638 ==============================
[0m22:34:15.085243 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:34:15.086113 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_event', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:34:15.504915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '90e5368f-d6a5-4b8d-9a07-f9101825c638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c9dc3700>]}
[0m22:34:15.625081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '90e5368f-d6a5-4b8d-9a07-f9101825c638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c9dccac0>]}
[0m22:34:15.626736 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:34:15.642423 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:34:15.710721 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:34:15.711290 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:34:15.720618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '90e5368f-d6a5-4b8d-9a07-f9101825c638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca1dfdf0>]}
[0m22:34:15.735144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '90e5368f-d6a5-4b8d-9a07-f9101825c638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca0f7790>]}
[0m22:34:15.735855 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:34:15.736351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90e5368f-d6a5-4b8d-9a07-f9101825c638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca0f76a0>]}
[0m22:34:15.738201 [info ] [MainThread]: 
[0m22:34:15.739247 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:34:15.740682 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:34:15.765305 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:34:15.765849 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:34:15.766308 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:15.770814 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:15.771607 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:16.277578 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:16.284026 [debug] [ThreadPool]: On list_dev: Close
[0m22:34:16.292358 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:34:16.310438 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:16.311051 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:34:16.311481 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:34:16.312157 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:16.312617 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:16.633309 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:16.635231 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:16.636624 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:34:16.705226 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:16.714483 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:34:16.769542 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:34:16.794406 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:16.794984 [debug] [MainThread]: On master: BEGIN
[0m22:34:16.795406 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:16.796180 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:16.796634 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:17.130366 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:17.132521 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:17.133857 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:34:17.232306 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:17.239571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '90e5368f-d6a5-4b8d-9a07-f9101825c638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0b8430f40>]}
[0m22:34:17.242050 [debug] [MainThread]: On master: ROLLBACK
[0m22:34:17.313759 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:17.315479 [debug] [MainThread]: On master: BEGIN
[0m22:34:17.340704 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:17.342522 [debug] [MainThread]: On master: COMMIT
[0m22:34:17.344627 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:17.346126 [debug] [MainThread]: On master: COMMIT
[0m22:34:17.397514 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:17.399204 [debug] [MainThread]: On master: Close
[0m22:34:17.402627 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:17.404625 [info ] [MainThread]: 
[0m22:34:17.411350 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m22:34:17.413665 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m22:34:17.416597 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m22:34:17.418162 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m22:34:17.428929 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m22:34:17.430099 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 22:34:17.418872 => 22:34:17.429729
[0m22:34:17.430652 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m22:34:17.526955 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:17.527638 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp223417475256"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m22:34:17.528177 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:17.528889 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:17.529403 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:18.122064 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:18.165395 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:18.166056 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m22:34:18.214139 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:18.215505 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:18.217101 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp223417475256'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp223417475256'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp223417475256'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:34:18.373789 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:18.413041 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:18.413986 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:18.682944 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:18.727413 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:18.728368 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:18.847128 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:18.882413 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m22:34:18.886811 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:18.887400 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp223417475256"
            where (
                
                    "dim_event__dbt_tmp223417475256".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m22:34:19.005017 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:19.007507 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:19.009522 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp223417475256"
    )
[0m22:34:19.095697 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:19.133495 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:34:19.134266 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:34:19.134785 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:34:19.564766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff299507d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff289179e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2891a5a90>]}


============================== 22:34:19.570408 | ed8843df-9723-44d9-83d8-fa772b39dbf9 ==============================
[0m22:34:19.570408 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:34:19.571214 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m22:34:19.684963 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:19.691375 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 22:34:17.430973 => 22:34:19.690010
[0m22:34:19.693797 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m22:34:19.698157 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '90e5368f-d6a5-4b8d-9a07-f9101825c638', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0d968e6a0>]}
[0m22:34:19.702417 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.28s]
[0m22:34:19.705385 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m22:34:19.710647 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:19.712602 [debug] [MainThread]: On master: BEGIN
[0m22:34:19.714296 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:34:19.716130 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:19.716761 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:19.977848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed8843df-9723-44d9-83d8-fa772b39dbf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2891a54c0>]}
[0m22:34:20.066166 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:20.068365 [debug] [MainThread]: On master: COMMIT
[0m22:34:20.070545 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:20.072263 [debug] [MainThread]: On master: COMMIT
[0m22:34:20.096767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed8843df-9723-44d9-83d8-fa772b39dbf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff299f89190>]}
[0m22:34:20.098090 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:34:20.114759 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:34:20.121834 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:20.123947 [debug] [MainThread]: On master: Close
[0m22:34:20.127984 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:20.129484 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m22:34:20.131137 [info ] [MainThread]: 
[0m22:34:20.132754 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.39 seconds (4.39s).
[0m22:34:20.135519 [debug] [MainThread]: Command end result
[0m22:34:20.161165 [info ] [MainThread]: 
[0m22:34:20.161885 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:34:20.162360 [info ] [MainThread]: 
[0m22:34:20.162880 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:34:20.168306 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.192486, "process_user_time": 4.43699, "process_kernel_time": 0.380073, "process_mem_max_rss": "115707904", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:34:20.170409 [debug] [MainThread]: Command `dbt run` succeeded at 22:34:20.170051 after 5.20 seconds
[0m22:34:20.171068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0980a9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0d9742550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca0f7640>]}
[0m22:34:20.171664 [debug] [MainThread]: Flushing usage events
[0m22:34:20.176579 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:34:20.177237 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:34:20.186953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed8843df-9723-44d9-83d8-fa772b39dbf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff280d07f70>]}
[0m22:34:20.202228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed8843df-9723-44d9-83d8-fa772b39dbf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff28946b910>]}
[0m22:34:20.202986 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:34:20.203526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed8843df-9723-44d9-83d8-fa772b39dbf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff28946b820>]}
[0m22:34:20.205476 [info ] [MainThread]: 
[0m22:34:20.206559 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:34:20.208031 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:34:20.233952 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:34:20.234562 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:34:20.235035 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:20.239514 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:20.240029 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:20.724200 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:20.730283 [debug] [ThreadPool]: On list_dev: Close
[0m22:34:20.733220 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:34:20.744778 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:20.745430 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:34:20.745886 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:34:20.746581 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:20.747063 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:21.069156 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:21.071452 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:21.074633 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:34:21.145055 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:21.151107 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:34:21.208214 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:34:21.229629 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:21.230193 [debug] [MainThread]: On master: BEGIN
[0m22:34:21.230623 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:21.231281 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:21.231739 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:21.552507 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:21.553678 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:21.554863 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:34:21.655705 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:21.660713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed8843df-9723-44d9-83d8-fa772b39dbf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff280d13df0>]}
[0m22:34:21.662089 [debug] [MainThread]: On master: ROLLBACK
[0m22:34:21.728418 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:21.729066 [debug] [MainThread]: On master: BEGIN
[0m22:34:21.755543 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:21.756163 [debug] [MainThread]: On master: COMMIT
[0m22:34:21.756740 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:21.757189 [debug] [MainThread]: On master: COMMIT
[0m22:34:21.802014 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:21.802620 [debug] [MainThread]: On master: Close
[0m22:34:21.803812 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:21.804317 [info ] [MainThread]: 
[0m22:34:21.806572 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:34:21.807336 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:34:21.808368 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:34:21.808916 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:34:21.815565 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:34:21.817134 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:34:21.809279 => 22:34:21.816711
[0m22:34:21.817781 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:34:21.921652 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:21.922473 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp223421868985"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind::bool = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:34:21.923033 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:21.923950 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:21.924485 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:22.324435 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:22.354033 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:22.354712 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:34:22.409373 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:22.410026 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:22.410796 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp223421868985'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp223421868985'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp223421868985'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:34:22.566190 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:22.593186 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:22.594172 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:22.743386 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:22.774596 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:22.775505 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:22.893594 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:22.923073 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:34:22.929292 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:22.930049 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp223421868985"
            where (
                
                    "dim_outcome__dbt_tmp223421868985".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp223421868985".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp223421868985".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:34:23.050023 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:23.050779 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:23.051352 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp223421868985"
    )
[0m22:34:23.151061 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:23.177832 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:34:23.178603 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:34:23.179129 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:34:23.781140 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:23.786239 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:34:21.818133 => 22:34:23.785349
[0m22:34:23.787522 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:34:23.790037 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed8843df-9723-44d9-83d8-fa772b39dbf9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2781988b0>]}
[0m22:34:23.791591 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 1.98s]
[0m22:34:23.792519 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:34:23.794580 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:23.795040 [debug] [MainThread]: On master: BEGIN
[0m22:34:23.795491 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:34:23.796220 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:23.796687 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:24.132339 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:24.133524 [debug] [MainThread]: On master: COMMIT
[0m22:34:24.134695 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:24.135534 [debug] [MainThread]: On master: COMMIT
[0m22:34:24.194388 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:24.195621 [debug] [MainThread]: On master: Close
[0m22:34:24.197909 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:24.198898 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:34:24.200247 [info ] [MainThread]: 
[0m22:34:24.201105 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.99 seconds (3.99s).
[0m22:34:24.202113 [debug] [MainThread]: Command end result
[0m22:34:24.218713 [info ] [MainThread]: 
[0m22:34:24.219488 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:34:24.219977 [info ] [MainThread]: 
[0m22:34:24.220510 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:34:24.223735 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7593365, "process_user_time": 4.276011, "process_kernel_time": 0.343446, "process_mem_max_rss": "114823168", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:34:24.224715 [debug] [MainThread]: Command `dbt run` succeeded at 22:34:24.224507 after 4.76 seconds
[0m22:34:24.225490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff299507d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff27818a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff289525af0>]}
[0m22:34:24.226120 [debug] [MainThread]: Flushing usage events
[0m22:34:26.699548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde78ffd670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde79a642e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde79a7b370>]}


============================== 22:34:26.705588 | 4047af0d-b55a-4bae-bcf2-7ff82052acfd ==============================
[0m22:34:26.705588 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:34:26.706445 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_participant', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:34:27.138867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4047af0d-b55a-4bae-bcf2-7ff82052acfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde88227fa0>]}
[0m22:34:27.257577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4047af0d-b55a-4bae-bcf2-7ff82052acfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde79aab0a0>]}
[0m22:34:27.259013 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:34:27.274689 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:34:27.333682 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:34:27.334343 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:34:27.343982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4047af0d-b55a-4bae-bcf2-7ff82052acfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde80b87e20>]}
[0m22:34:27.363422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4047af0d-b55a-4bae-bcf2-7ff82052acfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde8845f760>]}
[0m22:34:27.364200 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:34:27.364704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4047af0d-b55a-4bae-bcf2-7ff82052acfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde8845f6a0>]}
[0m22:34:27.366690 [info ] [MainThread]: 
[0m22:34:27.367755 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:34:27.369233 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:34:27.394608 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:34:27.395223 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:34:27.395692 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:27.400288 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:27.400827 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:27.861437 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:27.863808 [debug] [ThreadPool]: On list_dev: Close
[0m22:34:27.867169 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:34:27.880975 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:27.881669 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:34:27.882157 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:34:27.882841 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:27.883301 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:28.239632 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:28.241252 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:28.241999 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:34:28.308391 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:28.341741 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:34:28.397484 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:34:28.427136 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:28.428198 [debug] [MainThread]: On master: BEGIN
[0m22:34:28.428755 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:28.430084 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:28.430578 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:28.755452 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:28.757116 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:28.758274 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:34:28.853185 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:28.858136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4047af0d-b55a-4bae-bcf2-7ff82052acfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde882bf850>]}
[0m22:34:28.860928 [debug] [MainThread]: On master: ROLLBACK
[0m22:34:28.928698 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:28.930123 [debug] [MainThread]: On master: BEGIN
[0m22:34:28.951877 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:28.953196 [debug] [MainThread]: On master: COMMIT
[0m22:34:28.954424 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:28.955512 [debug] [MainThread]: On master: COMMIT
[0m22:34:29.001821 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:29.002946 [debug] [MainThread]: On master: Close
[0m22:34:29.005226 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:29.006206 [info ] [MainThread]: 
[0m22:34:29.011727 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m22:34:29.012955 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m22:34:29.014727 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m22:34:29.015640 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m22:34:29.023794 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m22:34:29.025534 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 22:34:29.016174 => 22:34:29.025019
[0m22:34:29.026172 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m22:34:29.132713 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:29.133455 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp223429076537"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m22:34:29.134014 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:29.134783 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:29.135313 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:29.511596 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:29.555596 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:29.556609 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m22:34:29.608190 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:29.609719 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:29.611460 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp223429076537'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp223429076537'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp223429076537'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:34:29.767411 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:29.813672 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:29.815074 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:29.959705 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:30.012820 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:30.014073 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:30.135513 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:30.185052 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m22:34:30.191484 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:30.192373 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp223429076537"
            where (
                
                    "dim_participant__dbt_tmp223429076537".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp223429076537".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m22:34:30.307533 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:30.309706 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:30.311206 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp223429076537"
    )
[0m22:34:30.392348 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:30.440463 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:34:30.441514 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:34:30.442175 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:34:30.947965 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:30.950416 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 22:34:29.026589 => 22:34:30.950055
[0m22:34:30.951008 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m22:34:30.952423 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4047af0d-b55a-4bae-bcf2-7ff82052acfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde79c8ed30>]}
[0m22:34:30.953844 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 1.94s]
[0m22:34:30.954745 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m22:34:30.957956 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:30.958517 [debug] [MainThread]: On master: BEGIN
[0m22:34:30.959002 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:34:30.959824 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:30.960298 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:31.264427 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:31.265660 [debug] [MainThread]: On master: COMMIT
[0m22:34:31.266837 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:31.267648 [debug] [MainThread]: On master: COMMIT
[0m22:34:31.312068 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:31.313316 [debug] [MainThread]: On master: Close
[0m22:34:31.315738 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:31.317211 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m22:34:31.319576 [info ] [MainThread]: 
[0m22:34:31.320711 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.95 seconds (3.95s).
[0m22:34:31.322802 [debug] [MainThread]: Command end result
[0m22:34:31.350311 [info ] [MainThread]: 
[0m22:34:31.351196 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:34:31.351810 [info ] [MainThread]: 
[0m22:34:31.352451 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:34:31.356372 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.762944, "process_user_time": 4.457324, "process_kernel_time": 0.389433, "process_mem_max_rss": "118636544", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:34:31.357594 [debug] [MainThread]: Command `dbt run` succeeded at 22:34:31.357361 after 4.76 seconds
[0m22:34:31.358265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde78ffd670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde8845f790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fde885159a0>]}
[0m22:34:31.358907 [debug] [MainThread]: Flushing usage events
[0m22:34:39.969785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f8dd1bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f95adca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f95965b0>]}


============================== 22:34:39.976325 | 6dcdd7d8-bce4-4ef7-9b94-eed831924e02 ==============================
[0m22:34:39.976325 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:34:39.977175 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_event_dtls', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:34:40.601811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6dcdd7d8-bce4-4ef7-9b94-eed831924e02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f9584700>]}
[0m22:34:40.719994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6dcdd7d8-bce4-4ef7-9b94-eed831924e02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f958cac0>]}
[0m22:34:40.722177 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:34:40.738228 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:34:40.808444 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:34:40.809005 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:34:40.818323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6dcdd7d8-bce4-4ef7-9b94-eed831924e02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93ea367df0>]}
[0m22:34:40.834805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6dcdd7d8-bce4-4ef7-9b94-eed831924e02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f99af790>]}
[0m22:34:40.835505 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:34:40.836011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6dcdd7d8-bce4-4ef7-9b94-eed831924e02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f99af6a0>]}
[0m22:34:40.837886 [info ] [MainThread]: 
[0m22:34:40.838917 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:34:40.840325 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:34:40.864177 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:34:40.864707 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:34:40.865157 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:40.869541 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:40.870053 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:41.373842 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:41.377298 [debug] [ThreadPool]: On list_dev: Close
[0m22:34:41.380874 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:34:41.393756 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:41.394339 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:34:41.394821 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:34:41.395549 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:41.396059 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:41.724784 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:41.726570 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:41.728500 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:34:41.796536 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:41.802864 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:34:41.858108 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:34:41.898430 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:41.899454 [debug] [MainThread]: On master: BEGIN
[0m22:34:41.900112 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:41.901094 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:41.901792 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:42.219434 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:42.221156 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:42.222199 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:34:42.318822 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:42.323077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6dcdd7d8-bce4-4ef7-9b94-eed831924e02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f9808f40>]}
[0m22:34:42.324276 [debug] [MainThread]: On master: ROLLBACK
[0m22:34:42.395642 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:42.397873 [debug] [MainThread]: On master: BEGIN
[0m22:34:42.421986 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:42.423554 [debug] [MainThread]: On master: COMMIT
[0m22:34:42.424908 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:42.425988 [debug] [MainThread]: On master: COMMIT
[0m22:34:42.474090 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:42.476606 [debug] [MainThread]: On master: Close
[0m22:34:42.480006 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:42.481488 [info ] [MainThread]: 
[0m22:34:42.489243 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m22:34:42.491610 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m22:34:42.495322 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m22:34:42.497294 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m22:34:42.509714 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m22:34:42.511697 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 22:34:42.498412 => 22:34:42.511099
[0m22:34:42.512512 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m22:34:42.615168 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:42.615896 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp223442562726"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m22:34:42.616454 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:42.617194 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:42.617733 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:42.993213 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:43.045174 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:43.046054 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m22:34:43.092227 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:43.093285 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:43.094684 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp223442562726'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp223442562726'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp223442562726'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:34:43.244723 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:43.282145 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:43.283104 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:43.435128 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:43.489857 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:43.491168 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:43.607606 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:43.661330 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m22:34:43.678664 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:43.680503 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp223442562726"
            where (
                
                    "dim_event_dtls__dbt_tmp223442562726".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m22:34:43.798243 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:43.799374 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:43.800240 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp223442562726"
    )
[0m22:34:43.879732 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:43.936275 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:34:43.937568 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:34:43.938585 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:34:44.539020 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:44.545609 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 22:34:42.513001 => 22:34:44.544449
[0m22:34:44.547480 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m22:34:44.553216 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6dcdd7d8-bce4-4ef7-9b94-eed831924e02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f9b13850>]}
[0m22:34:44.561263 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.06s]
[0m22:34:44.563241 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m22:34:44.569744 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:44.570642 [debug] [MainThread]: On master: BEGIN
[0m22:34:44.571372 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:34:44.574952 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:44.576618 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:44.922761 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:44.927260 [debug] [MainThread]: On master: COMMIT
[0m22:34:44.929019 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:44.929997 [debug] [MainThread]: On master: COMMIT
[0m22:34:44.975279 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:44.978240 [debug] [MainThread]: On master: Close
[0m22:34:44.981790 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:44.982886 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m22:34:44.985308 [info ] [MainThread]: 
[0m22:34:44.986979 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.15 seconds (4.15s).
[0m22:34:44.995475 [debug] [MainThread]: Command end result
[0m22:34:45.021885 [info ] [MainThread]: 
[0m22:34:45.022593 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:34:45.023048 [info ] [MainThread]: 
[0m22:34:45.023569 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:34:45.027908 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.161948, "process_user_time": 4.51772, "process_kernel_time": 0.422288, "process_mem_max_rss": "118337536", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:34:45.029144 [debug] [MainThread]: Command `dbt run` succeeded at 22:34:45.028934 after 5.16 seconds
[0m22:34:45.029799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f8dd1bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93f9a65c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f93ea4c6700>]}
[0m22:34:45.030424 [debug] [MainThread]: Flushing usage events
[0m22:34:52.562948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92913596d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92a11e4f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92a11d0be0>]}


============================== 22:34:52.570338 | a7175a03-0803-48cb-9975-b274c88a8106 ==============================
[0m22:34:52.570338 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:34:52.571321 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_group', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:34:53.044253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a7175a03-0803-48cb-9975-b274c88a8106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92a11bb370>]}
[0m22:34:53.168996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a7175a03-0803-48cb-9975-b274c88a8106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92805b0100>]}
[0m22:34:53.170672 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:34:53.186493 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:34:53.255813 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:34:53.256373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:34:53.265809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7175a03-0803-48cb-9975-b274c88a8106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92a1297e50>]}
[0m22:34:53.280384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7175a03-0803-48cb-9975-b274c88a8106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929225f7f0>]}
[0m22:34:53.281094 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:34:53.281594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7175a03-0803-48cb-9975-b274c88a8106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929225f700>]}
[0m22:34:53.283606 [info ] [MainThread]: 
[0m22:34:53.284738 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:34:53.286305 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:34:53.313119 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:34:53.313733 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:34:53.314206 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:34:53.318735 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:53.319234 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:53.811930 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:53.820019 [debug] [ThreadPool]: On list_dev: Close
[0m22:34:53.826394 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:34:53.850002 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:53.851021 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:34:53.851666 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:34:53.852700 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:53.853620 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:54.178287 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:54.180431 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:34:54.182352 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:34:54.250208 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:54.256117 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:34:54.311633 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:34:54.350480 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:54.351596 [debug] [MainThread]: On master: BEGIN
[0m22:34:54.352389 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:34:54.353401 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:54.354098 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:54.685056 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:54.686542 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:54.687715 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:34:54.787563 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:54.794216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7175a03-0803-48cb-9975-b274c88a8106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92b078efa0>]}
[0m22:34:54.796488 [debug] [MainThread]: On master: ROLLBACK
[0m22:34:54.866088 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:54.867804 [debug] [MainThread]: On master: BEGIN
[0m22:34:54.893807 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:54.895111 [debug] [MainThread]: On master: COMMIT
[0m22:34:54.896922 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:54.897856 [debug] [MainThread]: On master: COMMIT
[0m22:34:54.942824 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:54.944027 [debug] [MainThread]: On master: Close
[0m22:34:54.946420 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:34:54.947439 [info ] [MainThread]: 
[0m22:34:54.954039 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m22:34:54.956141 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m22:34:54.959188 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m22:34:54.960488 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m22:34:54.973311 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m22:34:54.975502 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 22:34:54.961245 => 22:34:54.974704
[0m22:34:54.976761 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m22:34:55.083647 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:55.084351 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp223455030589"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m22:34:55.084905 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:34:55.085632 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:55.086151 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:55.470933 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:55.517302 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:55.518176 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m22:34:55.566382 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:55.567747 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:55.569088 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp223455030589'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp223455030589'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp223455030589'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:34:55.726138 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:55.758269 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:55.759206 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:55.903875 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:55.961607 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:55.962831 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:34:56.082277 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:56.132471 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m22:34:56.138240 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:56.138879 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp223455030589"
            where (
                
                    "dim_group__dbt_tmp223455030589".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp223455030589".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m22:34:56.255058 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:56.256288 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:56.257266 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp223455030589"
    )
[0m22:34:56.335757 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:56.386689 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:34:56.387755 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:34:56.388422 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:34:56.961026 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:34:56.966345 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 22:34:54.977410 => 22:34:56.965114
[0m22:34:56.968523 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m22:34:56.972987 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7175a03-0803-48cb-9975-b274c88a8106', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92a139e9a0>]}
[0m22:34:56.976574 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.01s]
[0m22:34:56.978975 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m22:34:56.983419 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:56.984507 [debug] [MainThread]: On master: BEGIN
[0m22:34:56.985458 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:34:56.986973 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:34:56.988043 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:34:57.298857 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:57.301178 [debug] [MainThread]: On master: COMMIT
[0m22:34:57.302984 [debug] [MainThread]: Using redshift connection "master"
[0m22:34:57.304475 [debug] [MainThread]: On master: COMMIT
[0m22:34:57.351148 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:34:57.354023 [debug] [MainThread]: On master: Close
[0m22:34:57.358294 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:34:57.359715 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m22:34:57.361693 [info ] [MainThread]: 
[0m22:34:57.363993 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.08 seconds (4.08s).
[0m22:34:57.367892 [debug] [MainThread]: Command end result
[0m22:34:57.400288 [info ] [MainThread]: 
[0m22:34:57.401262 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:34:57.401941 [info ] [MainThread]: 
[0m22:34:57.402680 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:34:57.407457 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9713383, "process_user_time": 4.584711, "process_kernel_time": 0.413058, "process_mem_max_rss": "125308928", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:34:57.408617 [debug] [MainThread]: Command `dbt run` succeeded at 22:34:57.408359 after 4.97 seconds
[0m22:34:57.409357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92913596d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92b078e2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92a1360ac0>]}
[0m22:34:57.410119 [debug] [MainThread]: Flushing usage events
[0m22:35:03.904892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf902b5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfb1c4df70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfb1c38be0>]}


============================== 22:35:03.911368 | dc09ccff-cbea-4bed-a000-4852e103d54c ==============================
[0m22:35:03.911368 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:35:03.912193 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m22:35:04.341418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dc09ccff-cbea-4bed-a000-4852e103d54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfb1c21370>]}
[0m22:35:04.502049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dc09ccff-cbea-4bed-a000-4852e103d54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa033af10>]}
[0m22:35:04.508123 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:35:04.529423 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:35:04.601411 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:35:04.602012 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:35:04.611856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dc09ccff-cbea-4bed-a000-4852e103d54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa03afe50>]}
[0m22:35:04.627965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc09ccff-cbea-4bed-a000-4852e103d54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1a57790>]}
[0m22:35:04.628708 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:35:04.629312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc09ccff-cbea-4bed-a000-4852e103d54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1a576d0>]}
[0m22:35:04.631371 [info ] [MainThread]: 
[0m22:35:04.632482 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:35:04.633920 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:35:04.658858 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:35:04.659622 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:35:04.660122 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:35:04.664827 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:35:04.665382 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:35:05.178489 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:35:05.184164 [debug] [ThreadPool]: On list_dev: Close
[0m22:35:05.191439 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:35:05.214488 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:35:05.215449 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:35:05.216106 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:35:05.217104 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:35:05.217870 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:35:05.555311 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:05.556700 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:35:05.557653 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:35:05.622074 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:05.627854 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:35:05.685651 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:35:05.720010 [debug] [MainThread]: Using redshift connection "master"
[0m22:35:05.720690 [debug] [MainThread]: On master: BEGIN
[0m22:35:05.721131 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:35:05.721794 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:35:05.722258 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:35:06.039307 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:06.041722 [debug] [MainThread]: Using redshift connection "master"
[0m22:35:06.043972 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:35:06.143494 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:06.150713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc09ccff-cbea-4bed-a000-4852e103d54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfa035ca00>]}
[0m22:35:06.152981 [debug] [MainThread]: On master: ROLLBACK
[0m22:35:06.222589 [debug] [MainThread]: Using redshift connection "master"
[0m22:35:06.224178 [debug] [MainThread]: On master: BEGIN
[0m22:35:06.248785 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:06.250399 [debug] [MainThread]: On master: COMMIT
[0m22:35:06.251966 [debug] [MainThread]: Using redshift connection "master"
[0m22:35:06.253593 [debug] [MainThread]: On master: COMMIT
[0m22:35:06.302657 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:06.304469 [debug] [MainThread]: On master: Close
[0m22:35:06.307943 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:35:06.309203 [info ] [MainThread]: 
[0m22:35:06.314701 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:35:06.316905 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:35:06.319703 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:35:06.320957 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:35:06.332701 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:35:06.334789 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:35:06.321703 => 22:35:06.334110
[0m22:35:06.335820 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:35:06.442528 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:06.443282 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp223506387898"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind::bool = true then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:35:06.443837 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:35:06.444585 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:35:06.445127 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:35:06.830604 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:06.873937 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:06.874650 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:35:06.927760 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:06.929395 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:06.930812 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp223506387898'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp223506387898'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp223506387898'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:35:07.083919 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:07.119783 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:07.120715 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:35:07.266176 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:07.312561 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:07.313555 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:35:07.431360 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:07.464416 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:35:07.470950 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:07.471774 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp223506387898"
            where (
                
                    "dim_outcome__dbt_tmp223506387898".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp223506387898".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp223506387898".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:35:07.590594 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:07.591969 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:07.593400 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp223506387898"
    )
[0m22:35:07.685844 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:07.723604 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:35:07.724396 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:35:07.724957 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:35:08.380543 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:35:08.383549 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:35:06.336248 => 22:35:08.382943
[0m22:35:08.384603 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:35:08.387591 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dc09ccff-cbea-4bed-a000-4852e103d54c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1b9e940>]}
[0m22:35:08.390380 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.07s]
[0m22:35:08.393709 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:35:08.398150 [debug] [MainThread]: Using redshift connection "master"
[0m22:35:08.399174 [debug] [MainThread]: On master: BEGIN
[0m22:35:08.399973 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:35:08.401318 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:35:08.402284 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:35:08.737146 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:08.738873 [debug] [MainThread]: On master: COMMIT
[0m22:35:08.740921 [debug] [MainThread]: Using redshift connection "master"
[0m22:35:08.742550 [debug] [MainThread]: On master: COMMIT
[0m22:35:08.792180 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:35:08.793497 [debug] [MainThread]: On master: Close
[0m22:35:08.796541 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:35:08.797956 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:35:08.799527 [info ] [MainThread]: 
[0m22:35:08.801012 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.17 seconds (4.17s).
[0m22:35:08.803663 [debug] [MainThread]: Command end result
[0m22:35:08.831167 [info ] [MainThread]: 
[0m22:35:08.832101 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:35:08.832801 [info ] [MainThread]: 
[0m22:35:08.833491 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:35:08.837345 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.038339, "process_user_time": 4.480048, "process_kernel_time": 0.40131, "process_mem_max_rss": "122146816", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:35:08.838739 [debug] [MainThread]: Command `dbt run` succeeded at 22:35:08.838378 after 5.04 seconds
[0m22:35:08.839560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcf902b5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1b0dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcfc1b0d850>]}
[0m22:35:08.840303 [debug] [MainThread]: Flushing usage events
[0m22:35:17.261908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd790bc9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791b3dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791b275b0>]}


============================== 22:35:17.268436 | e48ce298-9429-4c57-9ee1-03aab0e26ee7 ==============================
[0m22:35:17.268436 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:35:17.269333 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_specifier', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:35:17.802892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e48ce298-9429-4c57-9ee1-03aab0e26ee7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791b13700>]}
[0m22:35:17.922620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e48ce298-9429-4c57-9ee1-03aab0e26ee7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791b1cac0>]}
[0m22:35:17.924237 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:35:17.940544 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:35:18.011644 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:35:18.012213 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:35:18.021803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e48ce298-9429-4c57-9ee1-03aab0e26ee7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791f2fdf0>]}
[0m22:35:18.039035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e48ce298-9429-4c57-9ee1-03aab0e26ee7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791e47790>]}
[0m22:35:18.039767 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:35:18.040632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e48ce298-9429-4c57-9ee1-03aab0e26ee7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791e476a0>]}
[0m22:35:18.041717 [warn ] [MainThread]: The selection criterion 'dim_specifier' does not match any nodes
[0m22:35:18.043178 [info ] [MainThread]: 
[0m22:35:18.043658 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m22:35:18.044399 [debug] [MainThread]: Command end result
[0m22:35:18.058171 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.90168405, "process_user_time": 3.575489, "process_kernel_time": 0.314109, "process_mem_max_rss": "115605504", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:35:18.059472 [debug] [MainThread]: Command `dbt run` succeeded at 22:35:18.058932 after 0.90 seconds
[0m22:35:18.060091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd790bc9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791ef5c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd791b13700>]}
[0m22:35:18.060647 [debug] [MainThread]: Flushing usage events
[0m22:35:59.989250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cc0b88520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb231c250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb22f5640>]}


============================== 22:35:59.995848 | 0434781b-33b6-49ce-bebd-f7ad553b0739 ==============================
[0m22:35:59.995848 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:35:59.996674 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:36:00.543718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0434781b-33b6-49ce-bebd-f7ad553b0739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb22e97c0>]}
[0m22:36:00.662994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0434781b-33b6-49ce-bebd-f7ad553b0739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb23ff070>]}
[0m22:36:00.664657 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:36:00.682525 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:36:00.754041 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m22:36:00.754970 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:36:00.755572 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_market.sql
[0m22:36:00.952122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0434781b-33b6-49ce-bebd-f7ad553b0739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c90280d30>]}
[0m22:36:00.967900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0434781b-33b6-49ce-bebd-f7ad553b0739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb265c880>]}
[0m22:36:00.968590 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:36:00.969115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0434781b-33b6-49ce-bebd-f7ad553b0739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb265c790>]}
[0m22:36:00.970964 [info ] [MainThread]: 
[0m22:36:00.972005 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:36:00.973414 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:36:00.998216 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:36:00.998856 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:36:00.999345 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:36:01.003977 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:36:01.004736 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:36:01.547243 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:36:01.553826 [debug] [ThreadPool]: On list_dev: Close
[0m22:36:01.559287 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:36:01.577188 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:36:01.577935 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:36:01.578529 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:36:01.579437 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:36:01.580055 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:36:01.929097 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:01.930885 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:36:01.932096 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:36:01.997587 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:02.005215 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:36:02.056362 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:36:02.089106 [debug] [MainThread]: Using redshift connection "master"
[0m22:36:02.089927 [debug] [MainThread]: On master: BEGIN
[0m22:36:02.090516 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:36:02.091442 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:36:02.092111 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:36:02.430680 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:02.432120 [debug] [MainThread]: Using redshift connection "master"
[0m22:36:02.433448 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:36:02.533889 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:02.539588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0434781b-33b6-49ce-bebd-f7ad553b0739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb24587f0>]}
[0m22:36:02.540670 [debug] [MainThread]: On master: ROLLBACK
[0m22:36:02.608832 [debug] [MainThread]: Using redshift connection "master"
[0m22:36:02.611306 [debug] [MainThread]: On master: BEGIN
[0m22:36:02.636586 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:02.638291 [debug] [MainThread]: On master: COMMIT
[0m22:36:02.639887 [debug] [MainThread]: Using redshift connection "master"
[0m22:36:02.640915 [debug] [MainThread]: On master: COMMIT
[0m22:36:02.684616 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:02.686545 [debug] [MainThread]: On master: Close
[0m22:36:02.689742 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:36:02.690953 [info ] [MainThread]: 
[0m22:36:02.696657 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:36:02.698109 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:36:02.700106 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:36:02.701172 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:36:02.711211 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:36:02.713458 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:36:02.701779 => 22:36:02.712818
[0m22:36:02.714335 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:36:02.814401 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:02.815137 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp223602761117"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:36:02.815724 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:36:02.816461 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:36:02.816999 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:36:06.072754 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m22:36:06.116274 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:06.117186 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:36:06.164675 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:06.165541 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:06.166650 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp223602761117'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp223602761117'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp223602761117'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:36:06.317478 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:06.357307 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:06.358475 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:36:06.506986 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:06.550386 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:06.551418 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:36:06.670852 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:06.712583 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:36:06.719855 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:06.720568 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp223602761117"
            where (
                
                    "dim_outcome__dbt_tmp223602761117".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp223602761117".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp223602761117".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:36:06.841757 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:06.844270 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:06.846260 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp223602761117"
    )
[0m22:36:06.949609 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:06.980500 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:36:06.981373 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:36:06.981913 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:36:07.901720 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:36:07.906561 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:36:02.714788 => 22:36:07.905878
[0m22:36:07.908367 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:36:07.910967 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0434781b-33b6-49ce-bebd-f7ad553b0739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ca02abc70>]}
[0m22:36:07.913528 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 5.21s]
[0m22:36:07.915153 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:36:07.918376 [debug] [MainThread]: Using redshift connection "master"
[0m22:36:07.919141 [debug] [MainThread]: On master: BEGIN
[0m22:36:07.919799 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:36:07.920841 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:36:07.921804 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:36:08.240241 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:08.242921 [debug] [MainThread]: On master: COMMIT
[0m22:36:08.244535 [debug] [MainThread]: Using redshift connection "master"
[0m22:36:08.245594 [debug] [MainThread]: On master: COMMIT
[0m22:36:08.295371 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:36:08.298410 [debug] [MainThread]: On master: Close
[0m22:36:08.302586 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:36:08.304019 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:36:08.305347 [info ] [MainThread]: 
[0m22:36:08.306469 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.33 seconds (7.33s).
[0m22:36:08.308163 [debug] [MainThread]: Command end result
[0m22:36:08.390119 [info ] [MainThread]: 
[0m22:36:08.390797 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:36:08.391277 [info ] [MainThread]: 
[0m22:36:08.391787 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:36:08.395409 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.512765, "process_user_time": 4.658562, "process_kernel_time": 0.422011, "process_mem_max_rss": "126226432", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:36:08.396320 [debug] [MainThread]: Command `dbt run` succeeded at 22:36:08.396026 after 8.51 seconds
[0m22:36:08.396987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cc0b88520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb28401c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7cb281a250>]}
[0m22:36:08.397578 [debug] [MainThread]: Flushing usage events
[0m22:38:07.945218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78e0effcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d05f0160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d05d0a00>]}


============================== 22:38:07.951901 | 01bf2884-9e2e-4d20-bde5-d108ae9552fb ==============================
[0m22:38:07.951901 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:38:07.952798 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:38:08.509659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '01bf2884-9e2e-4d20-bde5-d108ae9552fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d05f0160>]}
[0m22:38:08.631056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '01bf2884-9e2e-4d20-bde5-d108ae9552fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d06a8f70>]}
[0m22:38:08.633319 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:38:08.650669 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:38:08.722170 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:38:08.722752 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:38:08.732201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '01bf2884-9e2e-4d20-bde5-d108ae9552fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78e1de7f10>]}
[0m22:38:08.749520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '01bf2884-9e2e-4d20-bde5-d108ae9552fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d07ab8b0>]}
[0m22:38:08.750222 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:38:08.750738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01bf2884-9e2e-4d20-bde5-d108ae9552fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d07ab7c0>]}
[0m22:38:08.752605 [info ] [MainThread]: 
[0m22:38:08.753651 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:38:08.755106 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:38:08.780256 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:38:08.780888 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:38:08.781364 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:38:08.786007 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:38:08.786840 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:38:09.305324 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:38:09.312601 [debug] [ThreadPool]: On list_dev: Close
[0m22:38:09.318147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:38:09.336255 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:38:09.336952 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:38:09.337531 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:38:09.338440 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:38:09.339045 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:38:09.682144 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:09.685044 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:38:09.686552 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:38:09.755127 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:09.763520 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:38:09.818700 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:38:09.850178 [debug] [MainThread]: Using redshift connection "master"
[0m22:38:09.850921 [debug] [MainThread]: On master: BEGIN
[0m22:38:09.851512 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:38:09.852445 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:38:09.853078 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:38:10.211295 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:10.212976 [debug] [MainThread]: Using redshift connection "master"
[0m22:38:10.214170 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:38:10.311292 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:10.317802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '01bf2884-9e2e-4d20-bde5-d108ae9552fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78e1c5d190>]}
[0m22:38:10.319924 [debug] [MainThread]: On master: ROLLBACK
[0m22:38:10.387291 [debug] [MainThread]: Using redshift connection "master"
[0m22:38:10.389107 [debug] [MainThread]: On master: BEGIN
[0m22:38:10.422009 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:10.424698 [debug] [MainThread]: On master: COMMIT
[0m22:38:10.426858 [debug] [MainThread]: Using redshift connection "master"
[0m22:38:10.427993 [debug] [MainThread]: On master: COMMIT
[0m22:38:10.480954 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:10.483445 [debug] [MainThread]: On master: Close
[0m22:38:10.488307 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:38:10.489430 [info ] [MainThread]: 
[0m22:38:10.495658 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:38:10.497174 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:38:10.499271 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:38:10.500339 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:38:10.510372 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:38:10.512573 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:38:10.500959 => 22:38:10.511970
[0m22:38:10.513462 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:38:10.617172 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:10.617898 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp223810563811"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:38:10.618463 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:38:10.619223 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:38:10.619767 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:38:11.117685 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:11.160040 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:11.160885 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:38:11.206663 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:11.207465 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:11.208575 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp223810563811'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp223810563811'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp223810563811'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:38:11.359297 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:11.398172 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:11.399362 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:38:11.547529 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:11.592938 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:11.593953 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:38:11.714574 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:11.755158 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:38:11.762494 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:11.763219 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp223810563811"
            where (
                
                    "dim_outcome__dbt_tmp223810563811".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp223810563811".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp223810563811".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:38:15.002866 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m22:38:15.003630 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:15.004214 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp223810563811"
    )
[0m22:38:15.088799 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:15.121038 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:38:15.121905 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:38:15.122518 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:38:15.926730 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:38:15.932139 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:38:10.513891 => 22:38:15.931411
[0m22:38:15.933610 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:38:15.936998 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '01bf2884-9e2e-4d20-bde5-d108ae9552fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c0075250>]}
[0m22:38:15.939474 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 5.44s]
[0m22:38:15.941147 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:38:15.944537 [debug] [MainThread]: Using redshift connection "master"
[0m22:38:15.945397 [debug] [MainThread]: On master: BEGIN
[0m22:38:15.946094 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:38:15.947170 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:38:15.947904 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:38:16.274025 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:16.276033 [debug] [MainThread]: On master: COMMIT
[0m22:38:16.277407 [debug] [MainThread]: Using redshift connection "master"
[0m22:38:16.278356 [debug] [MainThread]: On master: COMMIT
[0m22:38:16.334434 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:38:16.337829 [debug] [MainThread]: On master: Close
[0m22:38:16.341281 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:38:16.342157 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:38:16.343849 [info ] [MainThread]: 
[0m22:38:16.344997 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.59 seconds (7.59s).
[0m22:38:16.346831 [debug] [MainThread]: Command end result
[0m22:38:16.370778 [info ] [MainThread]: 
[0m22:38:16.371661 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:38:16.372326 [info ] [MainThread]: 
[0m22:38:16.372949 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:38:16.375997 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.540029, "process_user_time": 4.459774, "process_kernel_time": 0.406771, "process_mem_max_rss": "121683968", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:38:16.376981 [debug] [MainThread]: Command `dbt run` succeeded at 22:38:16.376754 after 8.54 seconds
[0m22:38:16.377639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78e0effcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d07ab760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78d0864b80>]}
[0m22:38:16.378296 [debug] [MainThread]: Flushing usage events
[0m22:39:44.903391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb06146fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb061e79e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb061ea5a90>]}


============================== 22:39:44.910177 | 331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2 ==============================
[0m22:39:44.910177 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:39:44.910968 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_outcome', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:39:45.457661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb061ea54c0>]}
[0m22:39:45.578389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb050489190>]}
[0m22:39:45.580723 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:39:45.597985 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:39:45.669514 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:39:45.670161 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:39:45.680221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb071a97f70>]}
[0m22:39:45.697518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb06236b910>]}
[0m22:39:45.698222 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:39:45.698736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb06236b820>]}
[0m22:39:45.700655 [info ] [MainThread]: 
[0m22:39:45.701726 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:39:45.703262 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:39:45.729241 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:39:45.729869 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:39:45.730345 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:39:45.735142 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:39:45.735938 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:39:46.291977 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:39:46.299533 [debug] [ThreadPool]: On list_dev: Close
[0m22:39:46.304807 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:39:46.322682 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:39:46.323356 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:39:46.323920 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:39:46.324847 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:39:46.325450 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:39:46.658312 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:46.661461 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:39:46.663204 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:39:46.729770 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:46.737378 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:39:46.787201 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:39:46.818622 [debug] [MainThread]: Using redshift connection "master"
[0m22:39:46.819355 [debug] [MainThread]: On master: BEGIN
[0m22:39:46.819930 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:39:46.820808 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:39:46.821449 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:39:47.138269 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:47.139426 [debug] [MainThread]: Using redshift connection "master"
[0m22:39:47.140444 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:39:47.236986 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:47.242622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0621b48e0>]}
[0m22:39:47.244453 [debug] [MainThread]: On master: ROLLBACK
[0m22:39:47.312001 [debug] [MainThread]: Using redshift connection "master"
[0m22:39:47.314318 [debug] [MainThread]: On master: BEGIN
[0m22:39:47.340827 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:47.343358 [debug] [MainThread]: On master: COMMIT
[0m22:39:47.345529 [debug] [MainThread]: Using redshift connection "master"
[0m22:39:47.346749 [debug] [MainThread]: On master: COMMIT
[0m22:39:47.398556 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:47.401135 [debug] [MainThread]: On master: Close
[0m22:39:47.405054 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:39:47.406270 [info ] [MainThread]: 
[0m22:39:47.409934 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:39:47.411086 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:39:47.413015 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:39:47.414046 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:39:47.424622 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:39:47.427109 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:39:47.414682 => 22:39:47.426379
[0m22:39:47.428077 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:39:47.534618 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:47.535327 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp223947480972"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:39:47.535884 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:39:47.536625 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:39:47.537163 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:39:47.968514 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:48.010320 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:48.012277 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:39:48.061878 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:48.062674 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:48.063861 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp223947480972'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp223947480972'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp223947480972'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:39:48.217436 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:48.254542 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:48.255598 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:39:48.404713 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:48.447703 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:48.448727 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:39:48.566159 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:48.606266 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:39:48.613116 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:48.613743 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp223947480972"
            where (
                
                    "dim_outcome__dbt_tmp223947480972".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp223947480972".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp223947480972".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:39:48.829700 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:48.832252 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:48.833795 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp223947480972"
    )
[0m22:39:48.918797 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:48.959373 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:39:48.960287 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:39:48.960889 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:39:50.033136 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:39:50.039465 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:39:47.428638 => 22:39:50.038651
[0m22:39:50.041349 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:39:50.044367 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '331da1ee-6502-4e5b-b3d1-a4ca7a8a49e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb062475d00>]}
[0m22:39:50.046893 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.63s]
[0m22:39:50.048514 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:39:50.051785 [debug] [MainThread]: Using redshift connection "master"
[0m22:39:50.052740 [debug] [MainThread]: On master: BEGIN
[0m22:39:50.053577 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:39:50.054679 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:39:50.055417 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:39:50.377970 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:50.381558 [debug] [MainThread]: On master: COMMIT
[0m22:39:50.383261 [debug] [MainThread]: Using redshift connection "master"
[0m22:39:50.384346 [debug] [MainThread]: On master: COMMIT
[0m22:39:50.431472 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:39:50.433566 [debug] [MainThread]: On master: Close
[0m22:39:50.437125 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:39:50.438315 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:39:50.439588 [info ] [MainThread]: 
[0m22:39:50.440730 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.74 seconds (4.74s).
[0m22:39:50.442508 [debug] [MainThread]: Command end result
[0m22:39:50.467061 [info ] [MainThread]: 
[0m22:39:50.467892 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:39:50.468508 [info ] [MainThread]: 
[0m22:39:50.469173 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:39:50.472685 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.674968, "process_user_time": 4.451671, "process_kernel_time": 0.412163, "process_mem_max_rss": "122695680", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:39:50.473876 [debug] [MainThread]: Command `dbt run` succeeded at 22:39:50.473449 after 5.68 seconds
[0m22:39:50.474607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb06146fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb071cd0970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb0622114f0>]}
[0m22:39:50.475325 [debug] [MainThread]: Flushing usage events
[0m22:40:28.954008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa68e78be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a121dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a147070>]}


============================== 22:40:28.960885 | c0c486d6-1c6d-4237-8760-4ae42945063f ==============================
[0m22:40:28.960885 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:40:28.961803 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:40:29.517806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c0c486d6-1c6d-4237-8760-4ae42945063f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a11d310>]}
[0m22:40:29.638077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c0c486d6-1c6d-4237-8760-4ae42945063f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a2d33d0>]}
[0m22:40:29.640291 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:40:29.659568 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:40:29.736018 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:40:29.737064 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:40:29.938452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c0c486d6-1c6d-4237-8760-4ae42945063f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a55cdc0>]}
[0m22:40:29.955055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c0c486d6-1c6d-4237-8760-4ae42945063f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa3836b7f0>]}
[0m22:40:29.955817 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:40:29.956362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0c486d6-1c6d-4237-8760-4ae42945063f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa3836b760>]}
[0m22:40:29.958388 [info ] [MainThread]: 
[0m22:40:29.959529 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:40:29.961000 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:40:29.986612 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:40:29.987256 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:40:29.987734 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:40:29.992283 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:40:29.993094 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:40:30.493288 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:40:30.499184 [debug] [ThreadPool]: On list_dev: Close
[0m22:40:30.502171 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:40:30.513915 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:40:30.514470 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:40:30.514905 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:40:30.515581 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:40:30.516056 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:40:30.847444 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:30.850252 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:40:30.851915 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:40:30.924389 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:30.932348 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:40:30.982923 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:40:31.002381 [debug] [MainThread]: Using redshift connection "master"
[0m22:40:31.002964 [debug] [MainThread]: On master: BEGIN
[0m22:40:31.003404 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:40:31.004062 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:40:31.004525 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:40:31.339067 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:31.340285 [debug] [MainThread]: Using redshift connection "master"
[0m22:40:31.341341 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:40:31.444871 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:31.449300 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0c486d6-1c6d-4237-8760-4ae42945063f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a4083a0>]}
[0m22:40:31.450735 [debug] [MainThread]: On master: ROLLBACK
[0m22:40:31.518962 [debug] [MainThread]: Using redshift connection "master"
[0m22:40:31.521284 [debug] [MainThread]: On master: BEGIN
[0m22:40:31.547840 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:31.550062 [debug] [MainThread]: On master: COMMIT
[0m22:40:31.551831 [debug] [MainThread]: Using redshift connection "master"
[0m22:40:31.553039 [debug] [MainThread]: On master: COMMIT
[0m22:40:31.599206 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:31.601831 [debug] [MainThread]: On master: Close
[0m22:40:31.606399 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:40:31.607987 [info ] [MainThread]: 
[0m22:40:31.612695 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:40:31.613846 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:40:31.615555 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:40:31.616430 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:40:31.626096 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:40:31.628314 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:40:31.616949 => 22:40:31.627566
[0m22:40:31.629317 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:40:31.733464 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:40:31.734191 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp224031679669"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:40:31.734745 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:40:31.735713 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:40:31.736277 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:40:32.138501 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:32.180311 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:40:32.181077 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:40:32.227420 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:32.228224 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:40:32.229418 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp224031679669'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp224031679669'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp224031679669'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:40:32.390307 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:32.426798 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:40:32.427956 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:40:32.576789 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:32.615458 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:40:32.616686 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:40:32.737522 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:32.780880 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:40:32.787114 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:40:32.787788 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp224031679669"
            where (
                
                    "dim_outcome__dbt_tmp224031679669".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp224031679669".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp224031679669".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:40:32.931419 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:32.933917 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:40:32.935451 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp224031679669"
    )
[0m22:40:32.979287 [debug] [Thread-1  ]: Redshift adapter: Redshift error: column "traded_ind" does not exist in dim_outcome__dbt_tmp224031679669
[0m22:40:32.981760 [debug] [Thread-1  ]: On model.tipico.dim_outcome: ROLLBACK
[0m22:40:33.032695 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:40:31.629782 => 22:40:33.030669
[0m22:40:33.034910 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:40:33.043765 [debug] [Thread-1  ]: Database Error in model dim_outcome (models/dim_outcome.sql)
  column "traded_ind" does not exist in dim_outcome__dbt_tmp224031679669
  compiled Code at target/run/tipico/models/dim_outcome.sql
[0m22:40:33.045151 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0c486d6-1c6d-4237-8760-4ae42945063f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a3790d0>]}
[0m22:40:33.047697 [error] [Thread-1  ]: 1 of 1 ERROR creating sql incremental model timothy_chan.dim_outcome ........... [[31mERROR[0m in 1.43s]
[0m22:40:33.049417 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:40:33.052412 [debug] [MainThread]: Using redshift connection "master"
[0m22:40:33.053146 [debug] [MainThread]: On master: BEGIN
[0m22:40:33.053832 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:40:33.054892 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:40:33.055841 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:40:33.388715 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:33.391763 [debug] [MainThread]: On master: COMMIT
[0m22:40:33.393800 [debug] [MainThread]: Using redshift connection "master"
[0m22:40:33.395127 [debug] [MainThread]: On master: COMMIT
[0m22:40:33.450029 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:40:33.452608 [debug] [MainThread]: On master: Close
[0m22:40:33.456843 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:40:33.457990 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:40:33.459134 [info ] [MainThread]: 
[0m22:40:33.460155 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.50 seconds (3.50s).
[0m22:40:33.461961 [debug] [MainThread]: Command end result
[0m22:40:33.559949 [info ] [MainThread]: 
[0m22:40:33.560614 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:40:33.561075 [info ] [MainThread]: 
[0m22:40:33.561533 [error] [MainThread]:   Database Error in model dim_outcome (models/dim_outcome.sql)
  column "traded_ind" does not exist in dim_outcome__dbt_tmp224031679669
  compiled Code at target/run/tipico/models/dim_outcome.sql
[0m22:40:33.561989 [info ] [MainThread]: 
[0m22:40:33.562484 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:40:33.565852 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 4.7201896, "process_user_time": 4.730516, "process_kernel_time": 0.450765, "process_mem_max_rss": "124583936", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:40:33.566655 [debug] [MainThread]: Command `dbt run` failed at 22:40:33.566469 after 4.72 seconds
[0m22:40:33.567207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa68e78be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa5a4f1370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa69617d00>]}
[0m22:40:33.567757 [debug] [MainThread]: Flushing usage events
[0m22:44:19.726644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec90a55d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec91bfbf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec91be8be0>]}


============================== 22:44:19.733565 | 34e31a82-ccd3-4992-b236-74f729632ad0 ==============================
[0m22:44:19.733565 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:44:19.734457 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_market', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:44:20.266668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '34e31a82-ccd3-4992-b236-74f729632ad0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec91bd2370>]}
[0m22:44:20.384823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '34e31a82-ccd3-4992-b236-74f729632ad0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca1b30130>]}
[0m22:44:20.387032 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:44:20.403064 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:44:20.474547 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:44:20.475145 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:44:20.484576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '34e31a82-ccd3-4992-b236-74f729632ad0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca1e1fe50>]}
[0m22:44:20.501108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '34e31a82-ccd3-4992-b236-74f729632ad0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca1d376a0>]}
[0m22:44:20.501822 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:44:20.502315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '34e31a82-ccd3-4992-b236-74f729632ad0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca1d37610>]}
[0m22:44:20.504178 [info ] [MainThread]: 
[0m22:44:20.505200 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:44:20.506627 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:44:20.530882 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:44:20.531447 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:44:20.531897 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:44:20.536356 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:20.536857 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:21.087138 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:44:21.096898 [debug] [ThreadPool]: On list_dev: Close
[0m22:44:21.103404 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:44:21.125964 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:44:21.126848 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:44:21.127495 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:44:21.128478 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:21.129176 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:21.451126 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:21.452770 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:44:21.454882 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:44:21.525551 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:21.533949 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:44:21.590290 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:44:21.629727 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:21.630714 [debug] [MainThread]: On master: BEGIN
[0m22:44:21.631422 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:44:21.632471 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:21.633204 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:21.970100 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:21.972302 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:21.974102 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:44:22.078164 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:22.086157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '34e31a82-ccd3-4992-b236-74f729632ad0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca1bf4370>]}
[0m22:44:22.088528 [debug] [MainThread]: On master: ROLLBACK
[0m22:44:22.153801 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:22.156079 [debug] [MainThread]: On master: BEGIN
[0m22:44:22.180034 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:22.181329 [debug] [MainThread]: On master: COMMIT
[0m22:44:22.182431 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:22.183248 [debug] [MainThread]: On master: COMMIT
[0m22:44:22.231156 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:22.232962 [debug] [MainThread]: On master: Close
[0m22:44:22.236357 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:44:22.237765 [info ] [MainThread]: 
[0m22:44:22.245173 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m22:44:22.247360 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m22:44:22.250278 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m22:44:22.251887 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m22:44:22.266551 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m22:44:22.268933 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 22:44:22.252905 => 22:44:22.268209
[0m22:44:22.269972 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m22:44:22.374597 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:22.375289 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp224422322082"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable  then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m22:44:22.375844 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:44:22.376566 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:22.377092 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:25.697518 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m22:44:25.749991 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:25.751016 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m22:44:25.799883 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:25.801203 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:25.802545 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp224422322082'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp224422322082'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp224422322082'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:44:25.952066 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:26.002683 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:26.003790 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:44:26.149039 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:26.202925 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:26.203945 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:44:26.322304 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:26.373945 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m22:44:26.380045 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:26.380734 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp224422322082"
            where (
                
                    "dim_market__dbt_tmp224422322082".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp224422322082".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m22:44:26.500003 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:26.501040 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:26.501854 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp224422322082"
    )
[0m22:44:26.587375 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:26.637963 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:44:26.638960 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m22:44:26.639637 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m22:44:27.436768 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:44:27.441817 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 22:44:22.270502 => 22:44:27.440794
[0m22:44:27.443646 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m22:44:27.448071 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '34e31a82-ccd3-4992-b236-74f729632ad0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feca1e2ce80>]}
[0m22:44:27.452086 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 5.20s]
[0m22:44:27.455481 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m22:44:27.460828 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:27.462517 [debug] [MainThread]: On master: BEGIN
[0m22:44:27.463746 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:44:27.465353 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:27.466228 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:27.786757 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:27.789488 [debug] [MainThread]: On master: COMMIT
[0m22:44:27.790775 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:27.791723 [debug] [MainThread]: On master: COMMIT
[0m22:44:27.839492 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:27.840898 [debug] [MainThread]: On master: Close
[0m22:44:27.844468 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:44:27.845545 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m22:44:27.846664 [info ] [MainThread]: 
[0m22:44:27.847585 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.34 seconds (7.34s).
[0m22:44:27.849400 [debug] [MainThread]: Command end result
[0m22:44:27.870699 [info ] [MainThread]: 
[0m22:44:27.871353 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:44:27.871811 [info ] [MainThread]: 
[0m22:44:27.872326 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:44:27.875793 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.261694, "process_user_time": 4.505339, "process_kernel_time": 0.394782, "process_mem_max_rss": "131399680", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:44:27.876823 [debug] [MainThread]: Command `dbt run` succeeded at 22:44:27.876603 after 8.26 seconds
[0m22:44:27.877410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec90a55d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec91e13be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec91f60f70>]}
[0m22:44:27.877985 [debug] [MainThread]: Flushing usage events
[0m22:44:34.558364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80312cdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f803224cf70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8032238ac0>]}


============================== 22:44:34.564398 | a3a3833e-c5bd-4a7a-a682-17677f2d45dd ==============================
[0m22:44:34.564398 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:44:34.565209 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_event', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:44:34.979021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3a3833e-c5bd-4a7a-a682-17677f2d45dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8032223400>]}
[0m22:44:35.098944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3a3833e-c5bd-4a7a-a682-17677f2d45dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80414d0130>]}
[0m22:44:35.100626 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:44:35.116104 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:44:35.185420 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:44:35.186049 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:44:35.195657 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3a3833e-c5bd-4a7a-a682-17677f2d45dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80326ffe50>]}
[0m22:44:35.210937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3a3833e-c5bd-4a7a-a682-17677f2d45dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80326176a0>]}
[0m22:44:35.211599 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:44:35.212093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3a3833e-c5bd-4a7a-a682-17677f2d45dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8032617610>]}
[0m22:44:35.213943 [info ] [MainThread]: 
[0m22:44:35.214966 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:44:35.216804 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:44:35.241449 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:44:35.241981 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:44:35.242431 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:44:35.246846 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:35.247353 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:35.757902 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:44:35.764510 [debug] [ThreadPool]: On list_dev: Close
[0m22:44:35.773716 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:44:35.796792 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:44:35.797684 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:44:35.798335 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:44:35.799311 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:35.800011 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:36.121751 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:36.124214 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:44:36.125843 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:44:36.193027 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:36.201035 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:44:36.249960 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:44:36.289248 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:36.290208 [debug] [MainThread]: On master: BEGIN
[0m22:44:36.290859 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:44:36.291855 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:36.292545 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:36.644716 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:36.646397 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:36.647931 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:44:36.746781 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:36.753634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3a3833e-c5bd-4a7a-a682-17677f2d45dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80415d5d30>]}
[0m22:44:36.755796 [debug] [MainThread]: On master: ROLLBACK
[0m22:44:36.828230 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:36.829591 [debug] [MainThread]: On master: BEGIN
[0m22:44:36.854497 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:36.856359 [debug] [MainThread]: On master: COMMIT
[0m22:44:36.858067 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:36.859412 [debug] [MainThread]: On master: COMMIT
[0m22:44:36.907120 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:36.908887 [debug] [MainThread]: On master: Close
[0m22:44:36.911853 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:44:36.912962 [info ] [MainThread]: 
[0m22:44:36.919561 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m22:44:36.921565 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m22:44:36.924571 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m22:44:36.926231 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m22:44:36.941707 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m22:44:36.943778 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 22:44:36.927247 => 22:44:36.943115
[0m22:44:36.944786 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m22:44:37.050145 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:37.050851 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp224436998052"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m22:44:37.051413 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:44:37.052175 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:37.052695 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:37.454748 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:37.505982 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:37.506949 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m22:44:37.554358 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:37.555542 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:37.556954 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp224436998052'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp224436998052'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp224436998052'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:44:37.713707 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:37.740123 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:37.740942 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:44:37.887707 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:37.944305 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:37.945637 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:44:38.063463 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:38.113738 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m22:44:38.119406 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:38.120062 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp224436998052"
            where (
                
                    "dim_event__dbt_tmp224436998052".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m22:44:38.234538 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:38.236336 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:38.238105 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp224436998052"
    )
[0m22:44:38.322780 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:38.373107 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:44:38.374180 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m22:44:38.374856 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m22:44:39.011583 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:44:39.015318 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 22:44:36.945385 => 22:44:39.014574
[0m22:44:39.016540 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m22:44:39.019144 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3a3833e-c5bd-4a7a-a682-17677f2d45dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80327286a0>]}
[0m22:44:39.021758 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.10s]
[0m22:44:39.023603 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m22:44:39.027547 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:39.028611 [debug] [MainThread]: On master: BEGIN
[0m22:44:39.029413 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:44:39.030850 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:39.031918 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:39.348230 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:39.350415 [debug] [MainThread]: On master: COMMIT
[0m22:44:39.352344 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:39.354193 [debug] [MainThread]: On master: COMMIT
[0m22:44:39.401024 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:39.402905 [debug] [MainThread]: On master: Close
[0m22:44:39.406532 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:44:39.407776 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m22:44:39.409209 [info ] [MainThread]: 
[0m22:44:39.410468 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.19 seconds (4.19s).
[0m22:44:39.413558 [debug] [MainThread]: Command end result
[0m22:44:39.441141 [info ] [MainThread]: 
[0m22:44:39.442080 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:44:39.442766 [info ] [MainThread]: 
[0m22:44:39.443530 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:44:39.447786 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.9966707, "process_user_time": 4.486316, "process_kernel_time": 0.385416, "process_mem_max_rss": "131981312", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:44:39.448913 [debug] [MainThread]: Command `dbt run` succeeded at 22:44:39.448680 after 5.00 seconds
[0m22:44:39.449603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80312cdd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8010260430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f80326176d0>]}
[0m22:44:39.450334 [debug] [MainThread]: Flushing usage events
[0m22:44:45.941685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e8b2dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e9b27c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e9b1deb0>]}


============================== 22:44:45.947765 | 5b1722c6-9cbf-44d6-bf54-50f80a56f863 ==============================
[0m22:44:45.947765 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:44:45.948551 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_participant', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:44:46.375005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b1722c6-9cbf-44d6-bf54-50f80a56f863', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e9b12b20>]}
[0m22:44:46.493843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b1722c6-9cbf-44d6-bf54-50f80a56f863', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e9b42f10>]}
[0m22:44:46.495952 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:44:46.511317 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:44:46.580891 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:44:46.581450 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:44:46.590971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b1722c6-9cbf-44d6-bf54-50f80a56f863', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e9eafe80>]}
[0m22:44:46.606282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b1722c6-9cbf-44d6-bf54-50f80a56f863', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4d9f707c0>]}
[0m22:44:46.606963 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:44:46.607467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b1722c6-9cbf-44d6-bf54-50f80a56f863', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4d9f70700>]}
[0m22:44:46.609308 [info ] [MainThread]: 
[0m22:44:46.610359 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:44:46.611793 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:44:46.636267 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:44:46.636784 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:44:46.637249 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:44:46.641686 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:46.642195 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:47.141425 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:44:47.148729 [debug] [ThreadPool]: On list_dev: Close
[0m22:44:47.158351 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:44:47.185168 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:44:47.186083 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:44:47.186743 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:44:47.187765 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:47.188492 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:47.544183 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:47.546832 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:44:47.548915 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:44:47.621620 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:47.631773 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:44:47.686157 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:44:47.729557 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:47.730444 [debug] [MainThread]: On master: BEGIN
[0m22:44:47.731109 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:44:47.732135 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:47.732844 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:48.078985 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:48.081288 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:48.083389 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:44:48.187751 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:48.196483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b1722c6-9cbf-44d6-bf54-50f80a56f863', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e9d8e520>]}
[0m22:44:48.198694 [debug] [MainThread]: On master: ROLLBACK
[0m22:44:48.269064 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:48.271677 [debug] [MainThread]: On master: BEGIN
[0m22:44:48.297307 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:48.299181 [debug] [MainThread]: On master: COMMIT
[0m22:44:48.300692 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:48.301691 [debug] [MainThread]: On master: COMMIT
[0m22:44:48.345729 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:48.348644 [debug] [MainThread]: On master: Close
[0m22:44:48.353732 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:44:48.355263 [info ] [MainThread]: 
[0m22:44:48.363290 [debug] [Thread-1  ]: Began running node model.tipico.dim_participant
[0m22:44:48.365194 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_participant ................ [RUN]
[0m22:44:48.367966 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_participant)
[0m22:44:48.369376 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_participant
[0m22:44:48.381208 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_participant"
[0m22:44:48.383404 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (compile): 22:44:48.370530 => 22:44:48.382830
[0m22:44:48.384260 [debug] [Thread-1  ]: Began executing node model.tipico.dim_participant
[0m22:44:48.484277 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:48.484937 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

    
  
    

  create temporary table
    "dim_participant__dbt_tmp224448433132"
    
    
    
  as (
    -- Create dim_participant model, insert/update data incrementally


select distinct 
root_id
,participant_id
,"name"
,"position"
,abbreviation
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_participant"
  );
[0m22:44:48.485480 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:44:48.486194 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:48.486743 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:48.875131 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:48.922580 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:48.923439 [debug] [Thread-1  ]: On model.tipico.dim_participant: BEGIN
[0m22:44:48.967739 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:48.968394 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:48.969207 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant__dbt_tmp224448433132'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant__dbt_tmp224448433132'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_participant__dbt_tmp224448433132'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:44:49.115254 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:49.170448 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:49.171564 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:44:49.320827 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:49.379633 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:49.380594 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_participant'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_participant'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_participant'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:44:49.498539 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:49.551194 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_participant"
[0m22:44:49.557869 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:49.558539 [debug] [Thread-1  ]: On model.tipico.dim_participant: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_participant"} */

      
        
            delete from "dev"."timothy_chan"."dim_participant"
            using "dim_participant__dbt_tmp224448433132"
            where (
                
                    "dim_participant__dbt_tmp224448433132".root_id = "dev"."timothy_chan"."dim_participant".root_id
                    and 
                
                    "dim_participant__dbt_tmp224448433132".participant_id = "dev"."timothy_chan"."dim_participant".participant_id
                    
                
                
            );
[0m22:44:49.681712 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:49.684412 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:49.686548 [debug] [Thread-1  ]: On model.tipico.dim_participant: insert into "dev"."timothy_chan"."dim_participant" ("root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated")
    (
        select "root_id", "participant_id", "name", "position", "abbreviation", "tm_created", "tm_updated"
        from "dim_participant__dbt_tmp224448433132"
    )
[0m22:44:49.766282 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:49.816643 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:44:49.817553 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_participant"
[0m22:44:49.818226 [debug] [Thread-1  ]: On model.tipico.dim_participant: COMMIT
[0m22:44:50.580291 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:44:50.586239 [debug] [Thread-1  ]: Timing info for model.tipico.dim_participant (execute): 22:44:48.384752 => 22:44:50.584928
[0m22:44:50.588647 [debug] [Thread-1  ]: On model.tipico.dim_participant: Close
[0m22:44:50.593158 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b1722c6-9cbf-44d6-bf54-50f80a56f863', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e9ebceb0>]}
[0m22:44:50.597115 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_participant ........... [[32mSUCCESS[0m in 2.23s]
[0m22:44:50.599729 [debug] [Thread-1  ]: Finished running node model.tipico.dim_participant
[0m22:44:50.604276 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:50.605366 [debug] [MainThread]: On master: BEGIN
[0m22:44:50.606160 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:44:50.607723 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:44:50.609601 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:44:50.958003 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:50.960526 [debug] [MainThread]: On master: COMMIT
[0m22:44:50.962963 [debug] [MainThread]: Using redshift connection "master"
[0m22:44:50.964731 [debug] [MainThread]: On master: COMMIT
[0m22:44:51.017595 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:44:51.019519 [debug] [MainThread]: On master: Close
[0m22:44:51.022656 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:44:51.023900 [debug] [MainThread]: Connection 'model.tipico.dim_participant' was properly closed.
[0m22:44:51.025211 [info ] [MainThread]: 
[0m22:44:51.026269 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.42 seconds (4.42s).
[0m22:44:51.027968 [debug] [MainThread]: Command end result
[0m22:44:51.048431 [info ] [MainThread]: 
[0m22:44:51.049235 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:44:51.049819 [info ] [MainThread]: 
[0m22:44:51.050456 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:44:51.054257 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.217799, "process_user_time": 4.60512, "process_kernel_time": 0.393411, "process_mem_max_rss": "125378560", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:44:51.055182 [debug] [MainThread]: Command `dbt run` succeeded at 22:44:51.054973 after 5.22 seconds
[0m22:44:51.055792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4e8b2dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4d9f707f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4ea018880>]}
[0m22:44:51.056390 [debug] [MainThread]: Flushing usage events
[0m22:44:59.714736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa2910dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa19b04f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa19af0ac0>]}


============================== 22:44:59.721183 | e9b035ce-3fc6-4148-bff4-4fddb6967995 ==============================
[0m22:44:59.721183 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:44:59.722072 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_event_dtls', 'send_anonymous_usage_stats': 'True'}
[0m22:45:00.254889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e9b035ce-3fc6-4148-bff4-4fddb6967995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa19adb400>]}
[0m22:45:00.377689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e9b035ce-3fc6-4148-bff4-4fddb6967995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa19e82f10>]}
[0m22:45:00.379216 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:45:00.395684 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:45:00.467904 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:45:00.468506 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:45:00.478187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e9b035ce-3fc6-4148-bff4-4fddb6967995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9f812fe50>]}
[0m22:45:00.493715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e9b035ce-3fc6-4148-bff4-4fddb6967995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa086e5790>]}
[0m22:45:00.494428 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:45:00.494943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9b035ce-3fc6-4148-bff4-4fddb6967995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa086e56d0>]}
[0m22:45:00.496789 [info ] [MainThread]: 
[0m22:45:00.497821 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:45:00.499336 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:45:00.523629 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:45:00.524184 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:45:00.524624 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:45:00.529111 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:00.529608 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:01.038143 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:45:01.045766 [debug] [ThreadPool]: On list_dev: Close
[0m22:45:01.053052 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:45:01.073062 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:45:01.073929 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:45:01.074771 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:45:01.075798 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:01.076510 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:01.398353 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:01.400172 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:45:01.401661 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:45:01.467418 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:01.477650 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:45:01.534029 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:45:01.570090 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:01.570989 [debug] [MainThread]: On master: BEGIN
[0m22:45:01.571635 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:45:01.572614 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:01.573308 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:01.915756 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:01.916902 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:01.917910 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:45:02.010708 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:02.016605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9b035ce-3fc6-4148-bff4-4fddb6967995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa0857cf70>]}
[0m22:45:02.019263 [debug] [MainThread]: On master: ROLLBACK
[0m22:45:02.088530 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:02.090465 [debug] [MainThread]: On master: BEGIN
[0m22:45:02.114098 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:02.116733 [debug] [MainThread]: On master: COMMIT
[0m22:45:02.119146 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:02.120869 [debug] [MainThread]: On master: COMMIT
[0m22:45:02.171176 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:02.173968 [debug] [MainThread]: On master: Close
[0m22:45:02.179208 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:45:02.181398 [info ] [MainThread]: 
[0m22:45:02.188910 [debug] [Thread-1  ]: Began running node model.tipico.dim_event_dtls
[0m22:45:02.190781 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event_dtls ................. [RUN]
[0m22:45:02.193102 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event_dtls)
[0m22:45:02.194162 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event_dtls
[0m22:45:02.207258 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event_dtls"
[0m22:45:02.209627 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (compile): 22:45:02.194765 => 22:45:02.208982
[0m22:45:02.210618 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event_dtls
[0m22:45:02.315293 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:02.316014 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

    
  
    

  create temporary table
    "dim_event_dtls__dbt_tmp224502262550"
    
    
    
  as (
    -- Create dim_event_dtls model, insert/update data incrementally


select distinct 
root_id
,block_cashout::INTEGER
,long_term_event_type
,UPPER(outright_type) as outright_type
,cast(sub_group_name_key as varchar(255)) as sub_group_name_key
,sub_group_id_key
,tie_break
,best_of_sets
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event_dtls"
  );
[0m22:45:02.316566 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:45:02.317285 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:02.317814 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:02.707689 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:02.756716 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:02.757574 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: BEGIN
[0m22:45:02.804974 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:02.806397 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:02.808193 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls__dbt_tmp224502262550'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls__dbt_tmp224502262550'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event_dtls__dbt_tmp224502262550'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:45:02.957021 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:03.003644 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:03.004836 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:45:03.153650 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:03.204736 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:03.205872 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event_dtls'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event_dtls'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event_dtls'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:45:03.323814 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:03.359771 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event_dtls"
[0m22:45:03.364098 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:03.364692 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event_dtls"} */

      
        
            delete from "dev"."timothy_chan"."dim_event_dtls"
            using "dim_event_dtls__dbt_tmp224502262550"
            where (
                
                    "dim_event_dtls__dbt_tmp224502262550".root_id = "dev"."timothy_chan"."dim_event_dtls".root_id
                    
                
                
            );
[0m22:45:03.474238 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:03.475906 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:03.476961 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: insert into "dev"."timothy_chan"."dim_event_dtls" ("root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type")
    (
        select "root_id", "block_cashout", "long_term_event_type", "sub_group_name_key", "sub_group_id_key", "tie_break", "best_of_sets", "tm_created", "tm_updated", "outright_type"
        from "dim_event_dtls__dbt_tmp224502262550"
    )
[0m22:45:03.557971 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:03.607848 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:45:03.608964 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event_dtls"
[0m22:45:03.609626 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: COMMIT
[0m22:45:04.198935 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:45:04.205069 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event_dtls (execute): 22:45:02.211219 => 22:45:04.203808
[0m22:45:04.206519 [debug] [Thread-1  ]: On model.tipico.dim_event_dtls: Close
[0m22:45:04.209352 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e9b035ce-3fc6-4148-bff4-4fddb6967995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa19fd6ee0>]}
[0m22:45:04.212780 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event_dtls ............ [[32mSUCCESS[0m in 2.02s]
[0m22:45:04.215351 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event_dtls
[0m22:45:04.220078 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:04.221211 [debug] [MainThread]: On master: BEGIN
[0m22:45:04.222115 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:45:04.223933 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:04.225088 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:04.544467 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:04.546097 [debug] [MainThread]: On master: COMMIT
[0m22:45:04.547553 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:04.548701 [debug] [MainThread]: On master: COMMIT
[0m22:45:04.595800 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:04.597106 [debug] [MainThread]: On master: Close
[0m22:45:04.599248 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:45:04.600066 [debug] [MainThread]: Connection 'model.tipico.dim_event_dtls' was properly closed.
[0m22:45:04.601129 [info ] [MainThread]: 
[0m22:45:04.602084 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.10 seconds (4.10s).
[0m22:45:04.603961 [debug] [MainThread]: Command end result
[0m22:45:04.634271 [info ] [MainThread]: 
[0m22:45:04.635672 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:45:04.636549 [info ] [MainThread]: 
[0m22:45:04.637539 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:45:04.642013 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.032881, "process_user_time": 4.512284, "process_kernel_time": 0.390607, "process_mem_max_rss": "128512000", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:45:04.643296 [debug] [MainThread]: Command `dbt run` succeeded at 22:45:04.643017 after 5.03 seconds
[0m22:45:04.644132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa2910dd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa0879dcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faa0879d850>]}
[0m22:45:04.644849 [debug] [MainThread]: Flushing usage events
[0m22:45:10.926545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf887826d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf99e4ac70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf99e1b2b0>]}


============================== 22:45:10.932716 | 998cda91-1d4c-46ce-9bfd-0b672b9298f3 ==============================
[0m22:45:10.932716 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:45:10.933513 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_group', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:45:11.345796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '998cda91-1d4c-46ce-9bfd-0b672b9298f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf99e24070>]}
[0m22:45:11.465332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '998cda91-1d4c-46ce-9bfd-0b672b9298f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a0ba220>]}
[0m22:45:11.466662 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:45:11.482581 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:45:11.553511 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:45:11.554043 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:45:11.563360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '998cda91-1d4c-46ce-9bfd-0b672b9298f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a3b7eb0>]}
[0m22:45:11.577972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '998cda91-1d4c-46ce-9bfd-0b672b9298f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a2d07f0>]}
[0m22:45:11.578639 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:45:11.579138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '998cda91-1d4c-46ce-9bfd-0b672b9298f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a2d0730>]}
[0m22:45:11.581013 [info ] [MainThread]: 
[0m22:45:11.582034 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:45:11.583448 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:45:11.607802 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:45:11.608333 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:45:11.608790 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:45:11.613234 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:11.613732 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:12.102792 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:12.109271 [debug] [ThreadPool]: On list_dev: Close
[0m22:45:12.117264 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:45:12.141423 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:45:12.142281 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:45:12.142925 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:45:12.143910 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:12.144598 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:12.478312 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:12.479356 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:45:12.480270 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:45:12.542127 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:12.547745 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:45:12.602330 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:45:12.642751 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:12.643644 [debug] [MainThread]: On master: BEGIN
[0m22:45:12.644298 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:45:12.645330 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:12.646022 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:13.140699 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:13.142581 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:13.144072 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:45:13.243811 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:13.250203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '998cda91-1d4c-46ce-9bfd-0b672b9298f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a1158b0>]}
[0m22:45:13.252817 [debug] [MainThread]: On master: ROLLBACK
[0m22:45:13.318803 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:13.320587 [debug] [MainThread]: On master: BEGIN
[0m22:45:13.344701 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:13.345997 [debug] [MainThread]: On master: COMMIT
[0m22:45:13.347220 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:13.348170 [debug] [MainThread]: On master: COMMIT
[0m22:45:13.397827 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:13.400042 [debug] [MainThread]: On master: Close
[0m22:45:13.404347 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:45:13.406505 [info ] [MainThread]: 
[0m22:45:13.414886 [debug] [Thread-1  ]: Began running node model.tipico.dim_group
[0m22:45:13.416811 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_group ...................... [RUN]
[0m22:45:13.419923 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_group)
[0m22:45:13.421692 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_group
[0m22:45:13.433496 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_group"
[0m22:45:13.436966 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (compile): 22:45:13.422808 => 22:45:13.436414
[0m22:45:13.437820 [debug] [Thread-1  ]: Began executing node model.tipico.dim_group
[0m22:45:13.538353 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:13.539008 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

    
  
    

  create temporary table
    "dim_group__dbt_tmp224513487605"
    
    
    
  as (
    -- Create dim_group model, insert/update data incrementally


SELECT 
root_id
,group_id
,"name"
,parent_group_name
,parent_group_id
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_group"
  );
[0m22:45:13.539540 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:45:13.540253 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:13.540769 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:13.910112 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:13.963981 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:13.964817 [debug] [Thread-1  ]: On model.tipico.dim_group: BEGIN
[0m22:45:14.010296 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:14.011319 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:14.012652 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group__dbt_tmp224513487605'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group__dbt_tmp224513487605'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_group__dbt_tmp224513487605'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:45:14.161133 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:14.210151 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:14.211222 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:45:14.357737 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:14.411132 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:14.412187 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_group'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_group'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_group'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:45:14.528193 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:14.562661 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_group"
[0m22:45:14.568195 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:14.568788 [debug] [Thread-1  ]: On model.tipico.dim_group: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_group"} */

      
        
            delete from "dev"."timothy_chan"."dim_group"
            using "dim_group__dbt_tmp224513487605"
            where (
                
                    "dim_group__dbt_tmp224513487605".root_id = "dev"."timothy_chan"."dim_group".root_id
                    and 
                
                    "dim_group__dbt_tmp224513487605".group_id = "dev"."timothy_chan"."dim_group".group_id
                    
                
                
            );
[0m22:45:14.687189 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:14.689922 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:14.691703 [debug] [Thread-1  ]: On model.tipico.dim_group: insert into "dev"."timothy_chan"."dim_group" ("root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated")
    (
        select "root_id", "group_id", "name", "parent_group_name", "parent_group_id", "tm_created", "tm_updated"
        from "dim_group__dbt_tmp224513487605"
    )
[0m22:45:14.769177 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:14.816763 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:45:14.817713 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_group"
[0m22:45:14.818373 [debug] [Thread-1  ]: On model.tipico.dim_group: COMMIT
[0m22:45:15.567598 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:45:15.572881 [debug] [Thread-1  ]: Timing info for model.tipico.dim_group (execute): 22:45:13.438299 => 22:45:15.571603
[0m22:45:15.574319 [debug] [Thread-1  ]: On model.tipico.dim_group: Close
[0m22:45:15.576984 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '998cda91-1d4c-46ce-9bfd-0b672b9298f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a4fdd60>]}
[0m22:45:15.579322 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_group ................. [[32mSUCCESS[0m in 2.16s]
[0m22:45:15.580849 [debug] [Thread-1  ]: Finished running node model.tipico.dim_group
[0m22:45:15.584003 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:15.584828 [debug] [MainThread]: On master: BEGIN
[0m22:45:15.585572 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:45:15.586729 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:15.587556 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:15.898454 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:15.900648 [debug] [MainThread]: On master: COMMIT
[0m22:45:15.902249 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:15.903372 [debug] [MainThread]: On master: COMMIT
[0m22:45:15.948618 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:15.949843 [debug] [MainThread]: On master: Close
[0m22:45:15.952105 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:45:15.952923 [debug] [MainThread]: Connection 'model.tipico.dim_group' was properly closed.
[0m22:45:15.953933 [info ] [MainThread]: 
[0m22:45:15.955163 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.37 seconds (4.37s).
[0m22:45:15.956958 [debug] [MainThread]: Command end result
[0m22:45:15.985875 [info ] [MainThread]: 
[0m22:45:15.987002 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:45:15.987847 [info ] [MainThread]: 
[0m22:45:15.988799 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:45:15.993465 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.1715283, "process_user_time": 4.499301, "process_kernel_time": 0.380377, "process_mem_max_rss": "126345216", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:45:15.994795 [debug] [MainThread]: Command `dbt run` succeeded at 22:45:15.994501 after 5.17 seconds
[0m22:45:15.995653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf887826d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a2d0760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf9a2d0340>]}
[0m22:45:15.996494 [debug] [MainThread]: Flushing usage events
[0m22:45:22.355438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1b9295d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c96c4c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c96bcf70>]}


============================== 22:45:22.361790 | 72d90605-7055-47d4-9eaf-aea813ef4370 ==============================
[0m22:45:22.361790 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:45:22.362645 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m22:45:22.770551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '72d90605-7055-47d4-9eaf-aea813ef4370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c96b2f10>]}
[0m22:45:22.890810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '72d90605-7055-47d4-9eaf-aea813ef4370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c96e1f10>]}
[0m22:45:22.892564 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:45:22.908478 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:45:22.977712 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:45:22.978275 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:45:22.987676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '72d90605-7055-47d4-9eaf-aea813ef4370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c9a6fe80>]}
[0m22:45:23.002051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '72d90605-7055-47d4-9eaf-aea813ef4370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ba07e7c0>]}
[0m22:45:23.002716 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:45:23.003208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72d90605-7055-47d4-9eaf-aea813ef4370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ba07e700>]}
[0m22:45:23.005076 [info ] [MainThread]: 
[0m22:45:23.006102 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:45:23.007556 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:45:23.031981 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:45:23.032527 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:45:23.032974 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:45:23.037530 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:23.038032 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:23.517586 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:23.524737 [debug] [ThreadPool]: On list_dev: Close
[0m22:45:23.531997 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:45:23.558726 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:45:23.559718 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:45:23.560407 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:45:23.561412 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:23.562044 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:24.073264 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:45:24.074735 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:45:24.075764 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:45:24.144834 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:24.149910 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:45:24.201838 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:45:24.240142 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:24.241052 [debug] [MainThread]: On master: BEGIN
[0m22:45:24.241698 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:45:24.242712 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:24.243398 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:24.581158 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:24.582254 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:24.583262 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:45:24.681870 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:24.687258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '72d90605-7055-47d4-9eaf-aea813ef4370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c998e520>]}
[0m22:45:24.689963 [debug] [MainThread]: On master: ROLLBACK
[0m22:45:24.764942 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:24.765915 [debug] [MainThread]: On master: BEGIN
[0m22:45:24.791645 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:24.792338 [debug] [MainThread]: On master: COMMIT
[0m22:45:24.792911 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:24.793344 [debug] [MainThread]: On master: COMMIT
[0m22:45:24.841024 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:24.841856 [debug] [MainThread]: On master: Close
[0m22:45:24.843547 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:45:24.844268 [info ] [MainThread]: 
[0m22:45:24.848558 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:45:24.849461 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:45:24.850692 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:45:24.851366 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:45:24.858556 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:45:24.859964 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:45:24.851780 => 22:45:24.859573
[0m22:45:24.860568 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:45:24.960010 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:45:24.960725 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp224524907210"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:45:24.961265 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:45:24.962016 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:24.962541 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:25.373414 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:25.398615 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:45:25.399217 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:45:25.444570 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:25.445192 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:45:25.445932 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp224524907210'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp224524907210'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp224524907210'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:45:25.593725 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:25.635535 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:45:25.636854 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:45:25.789157 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:25.826224 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:45:25.827536 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:45:25.942777 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:25.986096 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:45:25.993674 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:45:25.994390 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp224524907210"
            where (
                
                    "dim_outcome__dbt_tmp224524907210".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp224524907210".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp224524907210".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:45:26.103529 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:26.105257 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:45:26.106597 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp224524907210"
    )
[0m22:45:26.146916 [debug] [Thread-1  ]: Redshift adapter: Redshift error: column "traded_ind" does not exist in dim_outcome__dbt_tmp224524907210
[0m22:45:26.149436 [debug] [Thread-1  ]: On model.tipico.dim_outcome: ROLLBACK
[0m22:45:26.198089 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:45:24.860915 => 22:45:26.196340
[0m22:45:26.200684 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:45:26.210890 [debug] [Thread-1  ]: Database Error in model dim_outcome (models/dim_outcome.sql)
  column "traded_ind" does not exist in dim_outcome__dbt_tmp224524907210
  compiled Code at target/run/tipico/models/dim_outcome.sql
[0m22:45:26.212849 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '72d90605-7055-47d4-9eaf-aea813ef4370', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ba1b25e0>]}
[0m22:45:26.215510 [error] [Thread-1  ]: 1 of 1 ERROR creating sql incremental model timothy_chan.dim_outcome ........... [[31mERROR[0m in 1.36s]
[0m22:45:26.217483 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:45:26.221178 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:26.222500 [debug] [MainThread]: On master: BEGIN
[0m22:45:26.223218 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:45:26.224293 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:45:26.224996 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:45:26.562917 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:26.564105 [debug] [MainThread]: On master: COMMIT
[0m22:45:26.565395 [debug] [MainThread]: Using redshift connection "master"
[0m22:45:26.567188 [debug] [MainThread]: On master: COMMIT
[0m22:45:26.615052 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:45:26.616484 [debug] [MainThread]: On master: Close
[0m22:45:26.619095 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:45:26.620429 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:45:26.621660 [info ] [MainThread]: 
[0m22:45:26.622577 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.62 seconds (3.62s).
[0m22:45:26.624653 [debug] [MainThread]: Command end result
[0m22:45:26.652837 [info ] [MainThread]: 
[0m22:45:26.653763 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:45:26.654429 [info ] [MainThread]: 
[0m22:45:26.655113 [error] [MainThread]:   Database Error in model dim_outcome (models/dim_outcome.sql)
  column "traded_ind" does not exist in dim_outcome__dbt_tmp224524907210
  compiled Code at target/run/tipico/models/dim_outcome.sql
[0m22:45:26.655768 [info ] [MainThread]: 
[0m22:45:26.656459 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:45:26.660731 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 4.413725, "process_user_time": 4.386313, "process_kernel_time": 0.38974, "process_mem_max_rss": "122527744", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:45:26.662027 [debug] [MainThread]: Command `dbt run` failed at 22:45:26.661741 after 4.42 seconds
[0m22:45:26.662796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1b9295d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ba07e7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1ba16fc40>]}
[0m22:45:26.663508 [debug] [MainThread]: Flushing usage events
[0m22:49:40.595700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb88f27d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb89db0e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb89ddda90>]}


============================== 22:49:40.602487 | 3f417ac8-c9c6-4243-bb0b-fd02947afb44 ==============================
[0m22:49:40.602487 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:49:40.603356 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_outcome', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:49:41.162165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3f417ac8-c9c6-4243-bb0b-fd02947afb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb89ddd4c0>]}
[0m22:49:41.282957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3f417ac8-c9c6-4243-bb0b-fd02947afb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb68390190>]}
[0m22:49:41.285181 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:49:41.302120 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:49:41.373429 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:49:41.374353 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:49:41.568882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f417ac8-c9c6-4243-bb0b-fd02947afb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb79f64d90>]}
[0m22:49:41.586068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f417ac8-c9c6-4243-bb0b-fd02947afb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb68493910>]}
[0m22:49:41.586791 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:49:41.587308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f417ac8-c9c6-4243-bb0b-fd02947afb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb68493820>]}
[0m22:49:41.589247 [info ] [MainThread]: 
[0m22:49:41.590301 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:49:41.591720 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:49:41.617005 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:49:41.617677 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:49:41.618151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:49:41.622579 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:49:41.623437 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:49:42.245454 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:49:42.254422 [debug] [ThreadPool]: On list_dev: Close
[0m22:49:42.259803 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:49:42.276660 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:49:42.277320 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:49:42.277888 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:49:42.278805 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:49:42.279448 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:49:42.607448 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:42.609728 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:49:42.611135 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:49:42.678104 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:42.681020 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:49:42.730389 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:49:42.752888 [debug] [MainThread]: Using redshift connection "master"
[0m22:49:42.753496 [debug] [MainThread]: On master: BEGIN
[0m22:49:42.753984 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:49:42.754718 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:49:42.755244 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:49:43.074905 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:43.075630 [debug] [MainThread]: Using redshift connection "master"
[0m22:49:43.076253 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:49:43.172752 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:43.175883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f417ac8-c9c6-4243-bb0b-fd02947afb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb79e36c10>]}
[0m22:49:43.177049 [debug] [MainThread]: On master: ROLLBACK
[0m22:49:43.243153 [debug] [MainThread]: Using redshift connection "master"
[0m22:49:43.245272 [debug] [MainThread]: On master: BEGIN
[0m22:49:43.270567 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:43.272031 [debug] [MainThread]: On master: COMMIT
[0m22:49:43.273049 [debug] [MainThread]: Using redshift connection "master"
[0m22:49:43.273580 [debug] [MainThread]: On master: COMMIT
[0m22:49:43.316463 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:43.317349 [debug] [MainThread]: On master: Close
[0m22:49:43.318865 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:49:43.319444 [info ] [MainThread]: 
[0m22:49:43.323529 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:49:43.324417 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:49:43.325599 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:49:43.326331 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:49:43.333171 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:49:43.335113 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:49:43.326724 => 22:49:43.334622
[0m22:49:43.335775 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:49:43.434999 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:43.435700 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp224943381904"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:49:43.436253 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:49:43.436989 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:49:43.437529 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:49:49.544668 [debug] [Thread-1  ]: SQL status: SUCCESS in 6.0 seconds
[0m22:49:49.578116 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:49.578794 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:49:49.626126 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:49.627354 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:49.628741 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp224943381904'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp224943381904'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp224943381904'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:49:49.781446 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:49.819714 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:49.821043 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:49:49.966665 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:50.012306 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:50.013289 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:49:50.130469 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:50.173214 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:49:50.180348 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:50.181041 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp224943381904"
            where (
                
                    "dim_outcome__dbt_tmp224943381904".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp224943381904".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp224943381904".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:49:50.299884 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:50.301919 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:50.303696 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp224943381904"
    )
[0m22:49:53.103619 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m22:49:53.139343 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:49:53.140963 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:49:53.141702 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:49:53.790179 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:49:53.797104 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:49:43.336146 => 22:49:53.796022
[0m22:49:53.798821 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:49:53.803581 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f417ac8-c9c6-4243-bb0b-fd02947afb44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb79d703a0>]}
[0m22:49:53.807462 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 10.48s]
[0m22:49:53.809363 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:49:53.813907 [debug] [MainThread]: Using redshift connection "master"
[0m22:49:53.814704 [debug] [MainThread]: On master: BEGIN
[0m22:49:53.815447 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:49:53.818228 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:49:53.819570 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:49:54.150169 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:54.153133 [debug] [MainThread]: On master: COMMIT
[0m22:49:54.155108 [debug] [MainThread]: Using redshift connection "master"
[0m22:49:54.156363 [debug] [MainThread]: On master: COMMIT
[0m22:49:54.206118 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:49:54.208938 [debug] [MainThread]: On master: Close
[0m22:49:54.212880 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:49:54.214232 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:49:54.215492 [info ] [MainThread]: 
[0m22:49:54.216511 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 12.63 seconds (12.63s).
[0m22:49:54.218636 [debug] [MainThread]: Command end result
[0m22:49:54.328109 [info ] [MainThread]: 
[0m22:49:54.328770 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:49:54.329238 [info ] [MainThread]: 
[0m22:49:54.329751 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:49:54.333613 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.852789, "process_user_time": 4.602403, "process_kernel_time": 0.504042, "process_mem_max_rss": "122306560", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:49:54.334500 [debug] [MainThread]: Command `dbt run` succeeded at 22:49:54.334268 after 13.85 seconds
[0m22:49:54.335077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb88f27d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb79dbb130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb89b7ffa0>]}
[0m22:49:54.335659 [debug] [MainThread]: Flushing usage events
[0m22:50:37.792176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd350d50be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd351771dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd351798070>]}


============================== 22:50:37.798962 | 119f70b4-48c7-4b07-a442-c572717c8b0a ==============================
[0m22:50:37.798962 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:50:37.799820 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:50:38.364469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '119f70b4-48c7-4b07-a442-c572717c8b0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35176c310>]}
[0m22:50:38.483189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '119f70b4-48c7-4b07-a442-c572717c8b0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33036b3d0>]}
[0m22:50:38.485347 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:50:38.502403 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:50:38.573761 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:50:38.574631 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:50:38.766518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '119f70b4-48c7-4b07-a442-c572717c8b0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd330474dc0>]}
[0m22:50:38.782897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '119f70b4-48c7-4b07-a442-c572717c8b0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34254b7f0>]}
[0m22:50:38.783608 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:50:38.784120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '119f70b4-48c7-4b07-a442-c572717c8b0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd34254b760>]}
[0m22:50:38.785982 [info ] [MainThread]: 
[0m22:50:38.787026 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:50:38.788424 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:50:38.813779 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:50:38.814430 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:50:38.814907 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:50:38.819409 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:50:38.819920 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:50:39.343095 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:50:39.348744 [debug] [ThreadPool]: On list_dev: Close
[0m22:50:39.354802 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:50:39.373522 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:50:39.374322 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:50:39.374891 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:50:39.375795 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:50:39.376401 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:50:39.717304 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:39.720069 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:50:39.721703 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:50:39.791094 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:39.798025 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:50:39.849029 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:50:39.869959 [debug] [MainThread]: Using redshift connection "master"
[0m22:50:39.870538 [debug] [MainThread]: On master: BEGIN
[0m22:50:39.870968 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:50:39.871615 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:50:39.872079 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:50:40.194952 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:40.196536 [debug] [MainThread]: Using redshift connection "master"
[0m22:50:40.198006 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:50:40.300602 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:40.306313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '119f70b4-48c7-4b07-a442-c572717c8b0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3423d03a0>]}
[0m22:50:40.307896 [debug] [MainThread]: On master: ROLLBACK
[0m22:50:40.385360 [debug] [MainThread]: Using redshift connection "master"
[0m22:50:40.387598 [debug] [MainThread]: On master: BEGIN
[0m22:50:40.414806 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:40.417338 [debug] [MainThread]: On master: COMMIT
[0m22:50:40.419460 [debug] [MainThread]: Using redshift connection "master"
[0m22:50:40.420699 [debug] [MainThread]: On master: COMMIT
[0m22:50:40.473161 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:40.474879 [debug] [MainThread]: On master: Close
[0m22:50:40.478910 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:50:40.480336 [info ] [MainThread]: 
[0m22:50:40.486827 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:50:40.488288 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:50:40.490307 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:50:40.491602 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:50:40.501616 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:50:40.503818 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:50:40.492406 => 22:50:40.503151
[0m22:50:40.504732 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:50:40.602564 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:40.603268 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp225040550571"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:50:40.603816 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:50:40.604544 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:50:40.605080 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:50:41.021631 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:41.064875 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:41.065768 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:50:41.111131 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:41.111962 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:41.113075 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp225040550571'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp225040550571'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp225040550571'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:50:41.274032 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:41.311972 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:41.313124 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:50:41.471667 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:41.513483 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:41.514490 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:50:41.641088 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:41.682404 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:50:41.688646 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:41.689310 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp225040550571"
            where (
                
                    "dim_outcome__dbt_tmp225040550571".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp225040550571".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp225040550571".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:50:41.820421 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:41.823620 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:41.825149 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp225040550571"
    )
[0m22:50:41.905429 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:41.945993 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:50:41.946831 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:50:41.947414 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:50:42.536496 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:50:42.542038 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:50:40.505276 => 22:50:42.541099
[0m22:50:42.543303 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:50:42.545699 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '119f70b4-48c7-4b07-a442-c572717c8b0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3427bccd0>]}
[0m22:50:42.548120 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.06s]
[0m22:50:42.549683 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:50:42.552995 [debug] [MainThread]: Using redshift connection "master"
[0m22:50:42.553931 [debug] [MainThread]: On master: BEGIN
[0m22:50:42.554689 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:50:42.555763 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:50:42.556512 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:50:42.874347 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:42.877273 [debug] [MainThread]: On master: COMMIT
[0m22:50:42.879359 [debug] [MainThread]: Using redshift connection "master"
[0m22:50:42.880399 [debug] [MainThread]: On master: COMMIT
[0m22:50:42.928501 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:50:42.931231 [debug] [MainThread]: On master: Close
[0m22:50:42.935074 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:50:42.936306 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:50:42.937763 [info ] [MainThread]: 
[0m22:50:42.938755 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.15 seconds (4.15s).
[0m22:50:42.940457 [debug] [MainThread]: Command end result
[0m22:50:43.023642 [info ] [MainThread]: 
[0m22:50:43.024278 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:50:43.024738 [info ] [MainThread]: 
[0m22:50:43.025236 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:50:43.028225 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.3414445, "process_user_time": 4.659853, "process_kernel_time": 0.430532, "process_mem_max_rss": "127430656", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:50:43.029059 [debug] [MainThread]: Command `dbt run` succeeded at 22:50:43.028858 after 5.34 seconds
[0m22:50:43.029600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd350d50be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3423d03a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3303f8790>]}
[0m22:50:43.030167 [debug] [MainThread]: Flushing usage events
[0m22:55:00.036226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe009590820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00a7e5c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00a7dcf70>]}


============================== 22:55:00.043176 | 76616ea6-c889-4517-a279-ab75dd2d2d5e ==============================
[0m22:55:00.043176 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:55:00.044021 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:55:00.607463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '76616ea6-c889-4517-a279-ab75dd2d2d5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00a7d3f10>]}
[0m22:55:00.725173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '76616ea6-c889-4517-a279-ab75dd2d2d5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00a801f10>]}
[0m22:55:00.727168 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:55:00.743948 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:55:00.815069 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:55:00.815665 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:55:00.825067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '76616ea6-c889-4517-a279-ab75dd2d2d5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00ac6fe80>]}
[0m22:55:00.841840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '76616ea6-c889-4517-a279-ab75dd2d2d5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00ab847c0>]}
[0m22:55:00.842563 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:55:00.843084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '76616ea6-c889-4517-a279-ab75dd2d2d5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00ab84700>]}
[0m22:55:00.844980 [info ] [MainThread]: 
[0m22:55:00.846027 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:55:00.847451 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:55:00.873778 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:55:00.874394 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:55:00.874888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:55:00.879439 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:00.880265 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:01.418019 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:55:01.425441 [debug] [ThreadPool]: On list_dev: Close
[0m22:55:01.430697 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:55:01.448998 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:55:01.449687 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:55:01.450257 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:55:01.451159 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:01.451773 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:01.798615 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:01.800893 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:55:01.802261 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:55:01.868303 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:01.873795 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:55:01.927508 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:55:01.949119 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:01.949825 [debug] [MainThread]: On master: BEGIN
[0m22:55:01.950306 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:55:01.951165 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:01.951716 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:02.281275 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:02.281908 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:02.282483 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:55:02.382486 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:02.389033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '76616ea6-c889-4517-a279-ab75dd2d2d5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00a98c520>]}
[0m22:55:02.394588 [debug] [MainThread]: On master: ROLLBACK
[0m22:55:02.464839 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:02.466974 [debug] [MainThread]: On master: BEGIN
[0m22:55:02.491862 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:02.493164 [debug] [MainThread]: On master: COMMIT
[0m22:55:02.494204 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:02.495043 [debug] [MainThread]: On master: COMMIT
[0m22:55:02.538870 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:02.540764 [debug] [MainThread]: On master: Close
[0m22:55:02.543630 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:55:02.544615 [info ] [MainThread]: 
[0m22:55:02.547970 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:55:02.548872 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:55:02.549984 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:55:02.550567 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:55:02.557012 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:55:02.558725 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:55:02.550909 => 22:55:02.558110
[0m22:55:02.559435 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:55:02.664863 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:02.665574 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp225502610884"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:55:02.666139 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:55:02.666884 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:02.667421 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:03.055880 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:03.085630 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:03.086305 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:55:03.136901 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:03.137563 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:03.138346 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp225502610884'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp225502610884'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp225502610884'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:55:03.291175 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:03.318552 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:03.319489 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:55:03.462593 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:03.495238 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:03.496203 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:55:03.617072 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:03.649591 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:55:03.655604 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:03.656238 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp225502610884"
            where (
                
                    "dim_outcome__dbt_tmp225502610884".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp225502610884".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp225502610884".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:55:03.769752 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:03.771960 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:03.773282 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp225502610884"
    )
[0m22:55:03.859798 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:03.890349 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:55:03.891182 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:03.891711 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m22:55:04.482234 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m22:55:04.489233 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:55:02.559811 => 22:55:04.487936
[0m22:55:04.490986 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:55:04.494314 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76616ea6-c889-4517-a279-ab75dd2d2d5e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00ac7aeb0>]}
[0m22:55:04.497634 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 1.94s]
[0m22:55:04.499357 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:55:04.502497 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:04.503386 [debug] [MainThread]: On master: BEGIN
[0m22:55:04.504185 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:55:04.505460 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:04.506358 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:04.854825 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:04.857790 [debug] [MainThread]: On master: COMMIT
[0m22:55:04.859378 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:04.861044 [debug] [MainThread]: On master: COMMIT
[0m22:55:04.914028 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:04.916465 [debug] [MainThread]: On master: Close
[0m22:55:04.920333 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:55:04.921615 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:55:04.923016 [info ] [MainThread]: 
[0m22:55:04.924270 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.08 seconds (4.08s).
[0m22:55:04.926182 [debug] [MainThread]: Command end result
[0m22:55:04.949937 [info ] [MainThread]: 
[0m22:55:04.950800 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:55:04.951404 [info ] [MainThread]: 
[0m22:55:04.952077 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m22:55:04.955922 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.031554, "process_user_time": 4.333283, "process_kernel_time": 0.411639, "process_mem_max_rss": "121229312", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:55:04.957235 [debug] [MainThread]: Command `dbt run` succeeded at 22:55:04.956874 after 5.03 seconds
[0m22:55:04.958026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe009590820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00accef40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe00ab847f0>]}
[0m22:55:04.958752 [debug] [MainThread]: Flushing usage events
[0m22:55:49.936997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc28c10be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc29663dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2968c070>]}


============================== 22:55:49.943735 | 5ab1024f-1167-401a-827d-32b1f4df9274 ==============================
[0m22:55:49.943735 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:55:49.944611 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:55:50.502582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ab1024f-1167-401a-827d-32b1f4df9274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2965d310>]}
[0m22:55:50.622503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ab1024f-1167-401a-827d-32b1f4df9274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc0822b3d0>]}
[0m22:55:50.624101 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m22:55:50.641203 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:55:50.710890 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:55:50.711784 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m22:55:50.913994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ab1024f-1167-401a-827d-32b1f4df9274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc1a8f5dc0>]}
[0m22:55:50.930336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ab1024f-1167-401a-827d-32b1f4df9274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc1a71b7f0>]}
[0m22:55:50.931041 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m22:55:50.931551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ab1024f-1167-401a-827d-32b1f4df9274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc1a71b760>]}
[0m22:55:50.933393 [info ] [MainThread]: 
[0m22:55:50.934452 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m22:55:50.935913 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m22:55:50.960371 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m22:55:50.961280 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m22:55:50.961878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:55:50.966554 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:50.967098 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:51.478309 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m22:55:51.486146 [debug] [ThreadPool]: On list_dev: Close
[0m22:55:51.491601 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m22:55:51.509194 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:55:51.509888 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m22:55:51.510445 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:55:51.511340 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:51.511946 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:51.842016 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:51.845051 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m22:55:51.847041 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m22:55:51.913962 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:51.921411 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m22:55:51.974832 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m22:55:51.996916 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:51.997492 [debug] [MainThread]: On master: BEGIN
[0m22:55:51.997923 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:55:51.998581 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:51.999048 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:52.340156 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:52.342028 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:52.343409 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m22:55:52.453272 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:52.458439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ab1024f-1167-401a-827d-32b1f4df9274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc1a5a03a0>]}
[0m22:55:52.459970 [debug] [MainThread]: On master: ROLLBACK
[0m22:55:52.531470 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:52.533657 [debug] [MainThread]: On master: BEGIN
[0m22:55:52.557857 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:52.559421 [debug] [MainThread]: On master: COMMIT
[0m22:55:52.560735 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:52.562183 [debug] [MainThread]: On master: COMMIT
[0m22:55:52.612604 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:52.614589 [debug] [MainThread]: On master: Close
[0m22:55:52.617527 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:55:52.618483 [info ] [MainThread]: 
[0m22:55:52.623574 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m22:55:52.625052 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m22:55:52.627059 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m22:55:52.627992 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m22:55:52.637547 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m22:55:52.639504 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 22:55:52.628500 => 22:55:52.638957
[0m22:55:52.640286 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m22:55:52.738714 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:52.739436 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp225552684969"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as is_traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m22:55:52.740009 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m22:55:52.740750 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:52.741292 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:53.159364 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:53.203342 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:53.204127 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m22:55:53.250264 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:53.251072 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:53.252144 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp225552684969'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp225552684969'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp225552684969'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m22:55:53.401707 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:53.440590 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:53.441611 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:55:53.585753 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:53.626854 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:53.627879 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m22:55:53.745804 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:53.787049 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m22:55:53.794045 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:53.794702 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp225552684969"
            where (
                
                    "dim_outcome__dbt_tmp225552684969".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp225552684969".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp225552684969".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m22:55:53.911247 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:53.913509 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m22:55:53.914980 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp225552684969"
    )
[0m22:55:53.952468 [debug] [Thread-1  ]: Redshift adapter: Redshift error: column "traded_ind" does not exist in dim_outcome__dbt_tmp225552684969
[0m22:55:53.954553 [debug] [Thread-1  ]: On model.tipico.dim_outcome: ROLLBACK
[0m22:55:54.003166 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 22:55:52.640758 => 22:55:54.001802
[0m22:55:54.004862 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m22:55:54.013175 [debug] [Thread-1  ]: Database Error in model dim_outcome (models/dim_outcome.sql)
  column "traded_ind" does not exist in dim_outcome__dbt_tmp225552684969
  compiled Code at target/run/tipico/models/dim_outcome.sql
[0m22:55:54.014481 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5ab1024f-1167-401a-827d-32b1f4df9274', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc1aa092e0>]}
[0m22:55:54.016832 [error] [Thread-1  ]: 1 of 1 ERROR creating sql incremental model timothy_chan.dim_outcome ........... [[31mERROR[0m in 1.39s]
[0m22:55:54.018421 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m22:55:54.021214 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:54.021934 [debug] [MainThread]: On master: BEGIN
[0m22:55:54.022578 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:55:54.023673 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m22:55:54.024400 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m22:55:54.351763 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:54.354013 [debug] [MainThread]: On master: COMMIT
[0m22:55:54.355715 [debug] [MainThread]: Using redshift connection "master"
[0m22:55:54.356779 [debug] [MainThread]: On master: COMMIT
[0m22:55:54.404871 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m22:55:54.407814 [debug] [MainThread]: On master: Close
[0m22:55:54.411012 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:55:54.412337 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m22:55:54.413939 [info ] [MainThread]: 
[0m22:55:54.414975 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 3.48 seconds (3.48s).
[0m22:55:54.416789 [debug] [MainThread]: Command end result
[0m22:55:54.516719 [info ] [MainThread]: 
[0m22:55:54.517385 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:55:54.517848 [info ] [MainThread]: 
[0m22:55:54.518316 [error] [MainThread]:   Database Error in model dim_outcome (models/dim_outcome.sql)
  column "traded_ind" does not exist in dim_outcome__dbt_tmp225552684969
  compiled Code at target/run/tipico/models/dim_outcome.sql
[0m22:55:54.518776 [info ] [MainThread]: 
[0m22:55:54.519267 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m22:55:54.522188 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 4.6929417, "process_user_time": 4.612614, "process_kernel_time": 0.403285, "process_mem_max_rss": "128241664", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:55:54.523014 [debug] [MainThread]: Command `dbt run` failed at 22:55:54.522816 after 4.69 seconds
[0m22:55:54.523585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc28c10be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc1a878790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbf827e340>]}
[0m22:55:54.524153 [debug] [MainThread]: Flushing usage events
[0m23:00:45.623105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b882fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b97d0e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b97fda90>]}


============================== 23:00:45.629662 | b8a40554-8760-4ca8-b9bf-881d1d78b0a3 ==============================
[0m23:00:45.629662 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:00:45.630548 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:00:46.229303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b8a40554-8760-4ca8-b9bf-881d1d78b0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b97fd4c0>]}
[0m23:00:46.347328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b8a40554-8760-4ca8-b9bf-881d1d78b0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9cd9190>]}
[0m23:00:46.348786 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:00:46.365634 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:00:46.436701 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:00:46.437604 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m23:00:46.629894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b8a40554-8760-4ca8-b9bf-881d1d78b0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9fb4d90>]}
[0m23:00:46.648654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b8a40554-8760-4ca8-b9bf-881d1d78b0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b9b43910>]}
[0m23:00:46.649398 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:00:46.649928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8a40554-8760-4ca8-b9bf-881d1d78b0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b9b43820>]}
[0m23:00:46.651786 [info ] [MainThread]: 
[0m23:00:46.652854 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:00:46.654295 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:00:46.679135 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:00:46.679755 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:00:46.680233 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:00:46.684812 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:00:46.685361 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:00:47.247781 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:00:47.255840 [debug] [ThreadPool]: On list_dev: Close
[0m23:00:47.260352 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:00:47.275340 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:00:47.275975 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:00:47.276492 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:00:47.277311 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:00:47.277839 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:00:47.608968 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:47.611614 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:00:47.613181 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:00:47.687320 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:47.694479 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:00:47.751577 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:00:47.771658 [debug] [MainThread]: Using redshift connection "master"
[0m23:00:47.772264 [debug] [MainThread]: On master: BEGIN
[0m23:00:47.772701 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:00:47.773370 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:00:47.773840 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:00:48.117188 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:48.119812 [debug] [MainThread]: Using redshift connection "master"
[0m23:00:48.121480 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:00:48.223751 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:48.231706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8a40554-8760-4ca8-b9bf-881d1d78b0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b9a2e460>]}
[0m23:00:48.233311 [debug] [MainThread]: On master: ROLLBACK
[0m23:00:48.300604 [debug] [MainThread]: Using redshift connection "master"
[0m23:00:48.302761 [debug] [MainThread]: On master: BEGIN
[0m23:00:48.336775 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:48.337955 [debug] [MainThread]: On master: COMMIT
[0m23:00:48.339062 [debug] [MainThread]: Using redshift connection "master"
[0m23:00:48.339880 [debug] [MainThread]: On master: COMMIT
[0m23:00:48.389747 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:48.391945 [debug] [MainThread]: On master: Close
[0m23:00:48.395519 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:00:48.396699 [info ] [MainThread]: 
[0m23:00:48.401669 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:00:48.403007 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:00:48.404865 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:00:48.405894 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:00:48.415894 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:00:48.417977 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:00:48.406504 => 23:00:48.417411
[0m23:00:48.418753 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:00:48.517692 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:48.518459 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp230048464335"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = 'true' then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_outcome"
  );
[0m23:00:48.519047 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:00:48.519792 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:00:48.520344 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:00:48.925484 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:48.968593 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:48.969429 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:00:49.015405 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:49.016312 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:49.017539 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp230048464335'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp230048464335'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp230048464335'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:00:49.169031 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:49.196927 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:49.197930 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:00:49.344506 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:49.374663 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:49.375663 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:00:49.493737 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:49.533678 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:00:49.540174 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:49.540906 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp230048464335"
            where (
                
                    "dim_outcome__dbt_tmp230048464335".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp230048464335".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp230048464335".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:00:49.663709 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:49.665463 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:49.666585 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp230048464335"
    )
[0m23:00:49.778515 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:49.820492 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:00:49.821488 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:00:49.822190 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:00:50.549183 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:00:50.553610 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:00:48.419175 => 23:00:50.552855
[0m23:00:50.554833 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:00:50.558181 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b8a40554-8760-4ca8-b9bf-881d1d78b0a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a9eab0a0>]}
[0m23:00:50.560992 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.15s]
[0m23:00:50.562644 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:00:50.565841 [debug] [MainThread]: Using redshift connection "master"
[0m23:00:50.566707 [debug] [MainThread]: On master: BEGIN
[0m23:00:50.567983 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:00:50.569432 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:00:50.570226 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:00:50.900920 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:50.903805 [debug] [MainThread]: On master: COMMIT
[0m23:00:50.906091 [debug] [MainThread]: Using redshift connection "master"
[0m23:00:50.907186 [debug] [MainThread]: On master: COMMIT
[0m23:00:50.960084 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:00:50.962185 [debug] [MainThread]: On master: Close
[0m23:00:50.965724 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:00:50.966936 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:00:50.968213 [info ] [MainThread]: 
[0m23:00:50.969390 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.32 seconds (4.32s).
[0m23:00:50.971105 [debug] [MainThread]: Command end result
[0m23:00:51.052119 [info ] [MainThread]: 
[0m23:00:51.052760 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:00:51.053219 [info ] [MainThread]: 
[0m23:00:51.053709 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:00:51.056662 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.538628, "process_user_time": 4.648207, "process_kernel_time": 0.423509, "process_mem_max_rss": "127795200", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:00:51.057501 [debug] [MainThread]: Command `dbt run` succeeded at 23:00:51.057303 after 5.54 seconds
[0m23:00:51.058073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b882fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5a993ffa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb5b9a41a60>]}
[0m23:00:51.058645 [debug] [MainThread]: Flushing usage events
[0m23:03:27.274199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8809497cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8809fc8160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8809fa8a00>]}


============================== 23:03:27.280718 | 53312258-f4af-48de-a98e-29d0fabdcd84 ==============================
[0m23:03:27.280718 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:03:27.281517 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:03:27.840825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '53312258-f4af-48de-a98e-29d0fabdcd84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8809fc8160>]}
[0m23:03:27.960551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '53312258-f4af-48de-a98e-29d0fabdcd84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e9590f70>]}
[0m23:03:27.961997 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:03:27.979068 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:03:28.052096 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:03:28.053020 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m23:03:28.249168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53312258-f4af-48de-a98e-29d0fabdcd84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87f88140d0>]}
[0m23:03:28.266815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53312258-f4af-48de-a98e-29d0fabdcd84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880a5039a0>]}
[0m23:03:28.267523 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:03:28.268040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53312258-f4af-48de-a98e-29d0fabdcd84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880a503910>]}
[0m23:03:28.269935 [info ] [MainThread]: 
[0m23:03:28.271036 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:03:28.272484 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:03:28.297408 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:03:28.298023 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:03:28.298496 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:03:28.303044 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:03:28.303568 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:03:28.891111 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:03:28.893751 [debug] [ThreadPool]: On list_dev: Close
[0m23:03:28.897034 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:03:28.907854 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:03:28.908379 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:03:28.908814 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:03:28.909470 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:03:28.909922 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:03:29.228600 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:29.229669 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:03:29.230200 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:03:29.296322 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:29.302504 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:03:29.354319 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:03:29.379429 [debug] [MainThread]: Using redshift connection "master"
[0m23:03:29.380103 [debug] [MainThread]: On master: BEGIN
[0m23:03:29.380604 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:03:29.381369 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:03:29.381852 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:03:29.698364 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:29.700942 [debug] [MainThread]: Using redshift connection "master"
[0m23:03:29.702561 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:03:29.799794 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:29.806181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53312258-f4af-48de-a98e-29d0fabdcd84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880a503700>]}
[0m23:03:29.808054 [debug] [MainThread]: On master: ROLLBACK
[0m23:03:29.877272 [debug] [MainThread]: Using redshift connection "master"
[0m23:03:29.882025 [debug] [MainThread]: On master: BEGIN
[0m23:03:29.907637 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:29.908957 [debug] [MainThread]: On master: COMMIT
[0m23:03:29.910911 [debug] [MainThread]: Using redshift connection "master"
[0m23:03:29.912107 [debug] [MainThread]: On master: COMMIT
[0m23:03:29.959562 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:29.962185 [debug] [MainThread]: On master: Close
[0m23:03:29.966043 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:03:29.967405 [info ] [MainThread]: 
[0m23:03:29.972758 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:03:29.974200 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:03:29.976102 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:03:29.977119 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:03:29.985955 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:03:29.987893 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:03:29.977725 => 23:03:29.987352
[0m23:03:29.988732 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:03:30.089068 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:30.089803 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp230330035862"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = 'true' then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from stg_outcome
  );
[0m23:03:30.090351 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:03:30.091093 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:03:30.091625 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:03:30.487831 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:30.532150 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:30.533001 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:03:30.580095 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:30.580892 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:30.581960 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp230330035862'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp230330035862'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp230330035862'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:03:30.729315 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:30.769018 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:30.770167 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:03:30.915224 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:30.958110 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:30.959037 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:03:31.076805 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:31.115948 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:03:31.122607 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:31.123269 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp230330035862"
            where (
                
                    "dim_outcome__dbt_tmp230330035862".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp230330035862".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp230330035862".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:03:31.238635 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:31.241184 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:31.242489 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp230330035862"
    )
[0m23:03:31.373599 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:31.407929 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:03:31.408725 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:03:31.409246 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:03:31.984662 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:03:31.990389 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:03:29.989329 => 23:03:31.989703
[0m23:03:31.991570 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:03:31.994644 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '53312258-f4af-48de-a98e-29d0fabdcd84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87e9691c40>]}
[0m23:03:31.997232 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.02s]
[0m23:03:31.998828 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:03:32.001955 [debug] [MainThread]: Using redshift connection "master"
[0m23:03:32.002881 [debug] [MainThread]: On master: BEGIN
[0m23:03:32.003714 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:03:32.004809 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:03:32.005558 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:03:32.333792 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:32.335858 [debug] [MainThread]: On master: COMMIT
[0m23:03:32.337571 [debug] [MainThread]: Using redshift connection "master"
[0m23:03:32.338607 [debug] [MainThread]: On master: COMMIT
[0m23:03:32.385983 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:03:32.387861 [debug] [MainThread]: On master: Close
[0m23:03:32.390655 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:03:32.391599 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:03:32.392727 [info ] [MainThread]: 
[0m23:03:32.393786 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m23:03:32.395822 [debug] [MainThread]: Command end result
[0m23:03:32.473794 [info ] [MainThread]: 
[0m23:03:32.474444 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:03:32.474914 [info ] [MainThread]: 
[0m23:03:32.475418 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:03:32.478960 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.314779, "process_user_time": 4.630598, "process_kernel_time": 0.435052, "process_mem_max_rss": "126468096", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:03:32.479772 [debug] [MainThread]: Command `dbt run` succeeded at 23:03:32.479577 after 5.32 seconds
[0m23:03:32.480319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8809497cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87d8071820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f880a676f10>]}
[0m23:03:32.480862 [debug] [MainThread]: Flushing usage events
[0m23:05:55.121181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a70e5fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a718f2e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a61aeea90>]}


============================== 23:05:55.128592 | 2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92 ==============================
[0m23:05:55.128592 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:05:55.129469 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:05:55.715342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a61aee4c0>]}
[0m23:05:55.836947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a50609190>]}
[0m23:05:55.839144 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:05:55.856784 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:05:55.928786 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:05:55.929354 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:05:55.939258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a71acff70>]}
[0m23:05:55.957073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a61e33a00>]}
[0m23:05:55.957779 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:05:55.958293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a61e33970>]}
[0m23:05:55.960237 [info ] [MainThread]: 
[0m23:05:55.961310 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:05:55.962761 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:05:55.987677 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:05:55.988284 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:05:55.988741 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:05:55.993293 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:05:55.994181 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:05:56.540075 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:05:56.544972 [debug] [ThreadPool]: On list_dev: Close
[0m23:05:56.549144 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:05:56.566891 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:05:56.567654 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:05:56.568218 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:05:56.569104 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:05:56.569719 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:05:56.956568 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:56.959239 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:05:56.961272 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:05:57.035259 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:57.045062 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:05:57.102798 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:05:57.133965 [debug] [MainThread]: Using redshift connection "master"
[0m23:05:57.134724 [debug] [MainThread]: On master: BEGIN
[0m23:05:57.135296 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:05:57.136214 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:05:57.136832 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:05:57.461273 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:57.462672 [debug] [MainThread]: Using redshift connection "master"
[0m23:05:57.463762 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:05:57.560067 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:57.568733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a61ce3130>]}
[0m23:05:57.570570 [debug] [MainThread]: On master: ROLLBACK
[0m23:05:57.638607 [debug] [MainThread]: Using redshift connection "master"
[0m23:05:57.641134 [debug] [MainThread]: On master: BEGIN
[0m23:05:57.664346 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:57.665324 [debug] [MainThread]: On master: COMMIT
[0m23:05:57.666265 [debug] [MainThread]: Using redshift connection "master"
[0m23:05:57.666971 [debug] [MainThread]: On master: COMMIT
[0m23:05:57.710446 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:57.711368 [debug] [MainThread]: On master: Close
[0m23:05:57.713167 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:05:57.713921 [info ] [MainThread]: 
[0m23:05:57.717730 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:05:57.718637 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:05:57.719955 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:05:57.720677 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:05:57.728288 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:05:57.729900 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:05:57.721115 => 23:05:57.729480
[0m23:05:57.730533 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:05:57.831700 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:57.832405 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp230557778466"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind = 'true' then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from stg_outcome
  );
[0m23:05:57.832962 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:05:57.833701 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:05:57.834229 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:05:58.334302 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:05:58.377154 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:58.378021 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:05:58.425180 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:58.425973 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:58.427057 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp230557778466'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp230557778466'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp230557778466'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:05:58.579073 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:58.615817 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:58.616774 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:05:58.766423 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:58.808424 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:58.809549 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:05:58.927494 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:58.965369 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:05:58.971753 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:58.972420 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp230557778466"
            where (
                
                    "dim_outcome__dbt_tmp230557778466".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp230557778466".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp230557778466".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:05:59.135995 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:59.139304 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:59.141602 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp230557778466"
    )
[0m23:05:59.231940 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:05:59.271520 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:05:59.272560 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:05:59.273165 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:05:59.946186 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:05:59.949163 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:05:57.730913 => 23:05:59.948561
[0m23:05:59.950284 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:05:59.952645 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2ad788c7-b5a2-45ce-8bfb-30b26a2ccf92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a71af0f10>]}
[0m23:05:59.955223 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.23s]
[0m23:05:59.956811 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:05:59.960027 [debug] [MainThread]: Using redshift connection "master"
[0m23:05:59.961106 [debug] [MainThread]: On master: BEGIN
[0m23:05:59.961837 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:05:59.962946 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:05:59.963746 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:06:00.324843 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:00.326174 [debug] [MainThread]: On master: COMMIT
[0m23:06:00.327209 [debug] [MainThread]: Using redshift connection "master"
[0m23:06:00.328023 [debug] [MainThread]: On master: COMMIT
[0m23:06:00.373382 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:00.375496 [debug] [MainThread]: On master: Close
[0m23:06:00.378264 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:06:00.379241 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:06:00.380234 [info ] [MainThread]: 
[0m23:06:00.381130 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.42 seconds (4.42s).
[0m23:06:00.382817 [debug] [MainThread]: Command end result
[0m23:06:00.402706 [info ] [MainThread]: 
[0m23:06:00.403501 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:06:00.404091 [info ] [MainThread]: 
[0m23:06:00.404728 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:06:00.409004 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.402915, "process_user_time": 4.473314, "process_kernel_time": 0.399938, "process_mem_max_rss": "127287296", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:06:00.410371 [debug] [MainThread]: Command `dbt run` succeeded at 23:06:00.410083 after 5.40 seconds
[0m23:06:00.411050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a70e5fd30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a71a8a0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8a71b86880>]}
[0m23:06:00.411695 [debug] [MainThread]: Flushing usage events
[0m23:06:41.304840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f1598be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e1888dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e18b0070>]}


============================== 23:06:41.311306 | 8d66d2ac-41eb-4d7f-a41c-b6d417c4b901 ==============================
[0m23:06:41.311306 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:06:41.312127 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_outcome', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:06:41.773900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d66d2ac-41eb-4d7f-a41c-b6d417c4b901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e1885310>]}
[0m23:06:41.893875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d66d2ac-41eb-4d7f-a41c-b6d417c4b901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3d03d43d0>]}
[0m23:06:41.896184 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:06:41.912596 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:06:41.980765 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:06:41.981681 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m23:06:42.172052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d66d2ac-41eb-4d7f-a41c-b6d417c4b901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e1c08d60>]}
[0m23:06:42.186487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d66d2ac-41eb-4d7f-a41c-b6d417c4b901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f244b8e0>]}
[0m23:06:42.187150 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:06:42.187674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d66d2ac-41eb-4d7f-a41c-b6d417c4b901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f244b910>]}
[0m23:06:42.189504 [info ] [MainThread]: 
[0m23:06:42.190527 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:06:42.191933 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:06:42.216836 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:06:42.217518 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:06:42.217993 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:06:42.222592 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:06:42.223107 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:06:42.708269 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:42.715266 [debug] [ThreadPool]: On list_dev: Close
[0m23:06:42.720602 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:06:42.738046 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:06:42.738804 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:06:42.739389 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:06:42.740317 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:06:42.740938 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:06:43.054070 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:43.057173 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:06:43.058808 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:06:43.124335 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:43.131771 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:06:43.181699 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:06:43.214571 [debug] [MainThread]: Using redshift connection "master"
[0m23:06:43.215300 [debug] [MainThread]: On master: BEGIN
[0m23:06:43.215851 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:06:43.216726 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:06:43.217326 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:06:43.537486 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:43.538438 [debug] [MainThread]: Using redshift connection "master"
[0m23:06:43.539264 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:06:43.635079 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:43.639034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d66d2ac-41eb-4d7f-a41c-b6d417c4b901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e1bfae20>]}
[0m23:06:43.640779 [debug] [MainThread]: On master: ROLLBACK
[0m23:06:43.704017 [debug] [MainThread]: Using redshift connection "master"
[0m23:06:43.705919 [debug] [MainThread]: On master: BEGIN
[0m23:06:43.727509 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:43.729758 [debug] [MainThread]: On master: COMMIT
[0m23:06:43.731556 [debug] [MainThread]: Using redshift connection "master"
[0m23:06:43.732658 [debug] [MainThread]: On master: COMMIT
[0m23:06:43.781986 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:43.784768 [debug] [MainThread]: On master: Close
[0m23:06:43.787888 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:06:43.788987 [info ] [MainThread]: 
[0m23:06:43.795495 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:06:43.796803 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:06:43.798373 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:06:43.799245 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:06:43.807960 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:06:43.809964 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:06:43.799767 => 23:06:43.809401
[0m23:06:43.810752 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:06:43.908664 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:43.909386 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp230643855640"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from stg_outcome
  );
[0m23:06:43.909940 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:06:43.910675 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:06:43.911213 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:06:44.307673 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:44.341560 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:44.342464 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:06:44.391667 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:44.392365 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:44.393105 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp230643855640'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp230643855640'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp230643855640'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:06:44.550899 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:44.588840 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:44.589890 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:06:44.736232 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:44.779000 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:44.780008 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:06:44.898934 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:44.939525 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:06:44.945599 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:44.946238 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp230643855640"
            where (
                
                    "dim_outcome__dbt_tmp230643855640".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp230643855640".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp230643855640".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:06:45.066581 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:45.068486 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:45.069762 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp230643855640"
    )
[0m23:06:45.164111 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:45.199208 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:06:45.200190 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:06:45.200819 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:06:46.193112 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:06:46.198336 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:06:43.811194 => 23:06:46.197659
[0m23:06:46.200245 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:06:46.202900 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d66d2ac-41eb-4d7f-a41c-b6d417c4b901', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3d041bcd0>]}
[0m23:06:46.205531 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.41s]
[0m23:06:46.207176 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:06:46.210285 [debug] [MainThread]: Using redshift connection "master"
[0m23:06:46.211026 [debug] [MainThread]: On master: BEGIN
[0m23:06:46.211719 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:06:46.212801 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:06:46.213526 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:06:46.528915 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:46.531918 [debug] [MainThread]: On master: COMMIT
[0m23:06:46.534436 [debug] [MainThread]: Using redshift connection "master"
[0m23:06:46.536020 [debug] [MainThread]: On master: COMMIT
[0m23:06:46.582029 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:06:46.584227 [debug] [MainThread]: On master: Close
[0m23:06:46.587256 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:06:46.588631 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:06:46.589820 [info ] [MainThread]: 
[0m23:06:46.590804 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.40 seconds (4.40s).
[0m23:06:46.592571 [debug] [MainThread]: Command end result
[0m23:06:46.670330 [info ] [MainThread]: 
[0m23:06:46.670975 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:06:46.671430 [info ] [MainThread]: 
[0m23:06:46.671917 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:06:46.674853 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.4764943, "process_user_time": 4.617286, "process_kernel_time": 0.401322, "process_mem_max_rss": "133103616", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:06:46.675681 [debug] [MainThread]: Command `dbt run` succeeded at 23:06:46.675488 after 5.48 seconds
[0m23:06:46.676221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f1598be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e1b5a8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3e1baca90>]}
[0m23:06:46.676777 [debug] [MainThread]: Flushing usage events
[0m23:07:39.070737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8939737d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89596c1e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89596eea90>]}


============================== 23:07:39.077671 | 7e472fcf-d157-4fa1-8823-a2b62f745249 ==============================
[0m23:07:39.077671 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:07:39.078554 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_outcome', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:07:39.624694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7e472fcf-d157-4fa1-8823-a2b62f745249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89596ee4c0>]}
[0m23:07:39.746537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7e472fcf-d157-4fa1-8823-a2b62f745249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8959871190>]}
[0m23:07:39.748765 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:07:39.766067 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:07:39.836788 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:07:39.837400 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:07:39.846919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7e472fcf-d157-4fa1-8823-a2b62f745249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f893a737f70>]}
[0m23:07:39.863212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7e472fcf-d157-4fa1-8823-a2b62f745249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f893a64ba00>]}
[0m23:07:39.863920 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:07:39.864453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e472fcf-d157-4fa1-8823-a2b62f745249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f893a64b970>]}
[0m23:07:39.866345 [info ] [MainThread]: 
[0m23:07:39.867399 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:07:39.868868 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:07:39.895660 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:07:39.896312 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:07:39.896788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:07:39.901483 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:07:39.902344 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:07:40.419765 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:07:40.426831 [debug] [ThreadPool]: On list_dev: Close
[0m23:07:40.431555 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:07:40.447391 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:07:40.448087 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:07:40.448668 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:07:40.449521 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:07:40.450143 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:07:40.808965 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:40.811043 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:07:40.812192 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:07:40.878638 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:40.888511 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:07:40.943005 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:07:40.975893 [debug] [MainThread]: Using redshift connection "master"
[0m23:07:40.976635 [debug] [MainThread]: On master: BEGIN
[0m23:07:40.977210 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:07:40.978081 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:07:40.978686 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:07:41.512034 [debug] [MainThread]: SQL status: SUCCESS in 1.0 seconds
[0m23:07:41.514981 [debug] [MainThread]: Using redshift connection "master"
[0m23:07:41.517199 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:07:41.631892 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:41.635426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7e472fcf-d157-4fa1-8823-a2b62f745249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f893a3fb130>]}
[0m23:07:41.636639 [debug] [MainThread]: On master: ROLLBACK
[0m23:07:41.728458 [debug] [MainThread]: Using redshift connection "master"
[0m23:07:41.730973 [debug] [MainThread]: On master: BEGIN
[0m23:07:41.767190 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:41.769478 [debug] [MainThread]: On master: COMMIT
[0m23:07:41.771690 [debug] [MainThread]: Using redshift connection "master"
[0m23:07:41.773433 [debug] [MainThread]: On master: COMMIT
[0m23:07:41.853828 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:41.856612 [debug] [MainThread]: On master: Close
[0m23:07:41.861136 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:07:41.862207 [info ] [MainThread]: 
[0m23:07:41.867996 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:07:41.869375 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:07:41.871397 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:07:41.872421 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:07:41.881928 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:07:41.884396 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:07:41.873051 => 23:07:41.883671
[0m23:07:41.885324 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:07:41.988965 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:41.989695 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp230741936227"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from stg_outcome
  );
[0m23:07:41.990254 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:07:41.990992 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:07:41.991666 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:07:42.631919 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:07:42.670803 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:42.671527 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:07:42.719037 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:42.719899 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:42.721033 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp230741936227'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp230741936227'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp230741936227'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:07:42.874518 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:42.913392 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:42.914555 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:07:43.058749 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:43.102660 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:43.103645 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:07:43.221194 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:43.264833 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:07:43.272180 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:43.272837 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp230741936227"
            where (
                
                    "dim_outcome__dbt_tmp230741936227".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp230741936227".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp230741936227".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:07:43.397163 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:43.399935 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:43.401579 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp230741936227"
    )
[0m23:07:43.483229 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:43.523479 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:07:43.524384 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:07:43.524990 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:07:44.088387 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:07:44.092345 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:07:41.885840 => 23:07:44.091786
[0m23:07:44.093091 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:07:44.095235 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7e472fcf-d157-4fa1-8823-a2b62f745249', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f893a87b9a0>]}
[0m23:07:44.097242 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.22s]
[0m23:07:44.098984 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:07:44.101243 [debug] [MainThread]: Using redshift connection "master"
[0m23:07:44.101880 [debug] [MainThread]: On master: BEGIN
[0m23:07:44.102685 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:07:44.103738 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:07:44.104315 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:07:44.547242 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:44.550247 [debug] [MainThread]: On master: COMMIT
[0m23:07:44.552515 [debug] [MainThread]: Using redshift connection "master"
[0m23:07:44.553905 [debug] [MainThread]: On master: COMMIT
[0m23:07:44.603623 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:07:44.606438 [debug] [MainThread]: On master: Close
[0m23:07:44.610049 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:07:44.611522 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:07:44.613107 [info ] [MainThread]: 
[0m23:07:44.614146 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.75 seconds (4.75s).
[0m23:07:44.615967 [debug] [MainThread]: Command end result
[0m23:07:44.637443 [info ] [MainThread]: 
[0m23:07:44.638278 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:07:44.638894 [info ] [MainThread]: 
[0m23:07:44.639572 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:07:44.643363 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.6787257, "process_user_time": 4.451459, "process_kernel_time": 0.412715, "process_mem_max_rss": "126939136", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:07:44.644594 [debug] [MainThread]: Command `dbt run` succeeded at 23:07:44.644357 after 5.68 seconds
[0m23:07:44.645274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8939737d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f895998b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f895998bb20>]}
[0m23:07:44.645928 [debug] [MainThread]: Flushing usage events
[0m23:08:22.113005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc70d87d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc718b1e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc718dea90>]}


============================== 23:08:22.119675 | 4f7204d2-5144-4d32-8b1f-4df4d84e9925 ==============================
[0m23:08:22.119675 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:08:22.120507 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select dim_outcome', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:08:22.639407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4f7204d2-5144-4d32-8b1f-4df4d84e9925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc718de4c0>]}
[0m23:08:22.759215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4f7204d2-5144-4d32-8b1f-4df4d84e9925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc507d9190>]}
[0m23:08:22.761448 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:08:22.777985 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:08:22.849968 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:08:22.850577 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:08:22.860161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4f7204d2-5144-4d32-8b1f-4df4d84e9925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc61e4ff70>]}
[0m23:08:22.874940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4f7204d2-5144-4d32-8b1f-4df4d84e9925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc61d63a00>]}
[0m23:08:22.875685 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:08:22.876203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f7204d2-5144-4d32-8b1f-4df4d84e9925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc61d63970>]}
[0m23:08:22.878150 [info ] [MainThread]: 
[0m23:08:22.879237 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:08:22.880754 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:08:22.905987 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:08:22.906613 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:08:22.907080 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:08:22.911631 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:08:22.912412 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:08:23.418694 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:08:23.423949 [debug] [ThreadPool]: On list_dev: Close
[0m23:08:23.430508 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:08:23.456260 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:08:23.457398 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:08:23.458296 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:08:23.459521 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:08:23.460316 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:08:23.780653 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:23.782176 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:08:23.783365 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:08:23.848012 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:23.853490 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:08:23.903798 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:08:23.945924 [debug] [MainThread]: Using redshift connection "master"
[0m23:08:23.946633 [debug] [MainThread]: On master: BEGIN
[0m23:08:23.947089 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:08:23.948143 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:08:23.948853 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:08:24.299386 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:24.301147 [debug] [MainThread]: Using redshift connection "master"
[0m23:08:24.304381 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:08:24.402177 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:24.404184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4f7204d2-5144-4d32-8b1f-4df4d84e9925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc61b92130>]}
[0m23:08:24.404871 [debug] [MainThread]: On master: ROLLBACK
[0m23:08:24.483146 [debug] [MainThread]: Using redshift connection "master"
[0m23:08:24.483852 [debug] [MainThread]: On master: BEGIN
[0m23:08:24.502887 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:24.503773 [debug] [MainThread]: On master: COMMIT
[0m23:08:24.504653 [debug] [MainThread]: Using redshift connection "master"
[0m23:08:24.505340 [debug] [MainThread]: On master: COMMIT
[0m23:08:24.548755 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:24.549792 [debug] [MainThread]: On master: Close
[0m23:08:24.551917 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:08:24.552668 [info ] [MainThread]: 
[0m23:08:24.557359 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:08:24.558469 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:08:24.559992 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:08:24.560818 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:08:24.568534 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:08:24.570141 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:08:24.561291 => 23:08:24.569605
[0m23:08:24.570934 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:08:24.672077 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:24.672804 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp230824619067"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from stg_outcome
  );
[0m23:08:24.673364 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:08:24.674118 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:08:24.674671 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:08:25.065096 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:25.105636 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:25.106490 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:08:25.158359 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:25.159545 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:25.160948 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp230824619067'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp230824619067'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp230824619067'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:08:25.313479 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:25.351408 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:25.352640 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:08:25.497585 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:25.542477 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:25.543541 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:08:25.667258 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:25.709304 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:08:25.716909 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:25.717623 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp230824619067"
            where (
                
                    "dim_outcome__dbt_tmp230824619067".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp230824619067".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp230824619067".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:08:26.176392 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:26.179853 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:26.182119 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp230824619067"
    )
[0m23:08:34.162230 [debug] [Thread-1  ]: SQL status: SUCCESS in 8.0 seconds
[0m23:08:34.202224 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:08:34.203192 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:08:34.203791 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:08:34.981071 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:08:34.986933 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:08:24.571401 => 23:08:34.985842
[0m23:08:34.988570 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:08:34.991330 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f7204d2-5144-4d32-8b1f-4df4d84e9925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc61e77b50>]}
[0m23:08:34.993803 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 10.43s]
[0m23:08:34.995691 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:08:34.999785 [debug] [MainThread]: Using redshift connection "master"
[0m23:08:35.000773 [debug] [MainThread]: On master: BEGIN
[0m23:08:35.001766 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:08:35.002883 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:08:35.003634 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:08:35.320329 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:35.322182 [debug] [MainThread]: On master: COMMIT
[0m23:08:35.323601 [debug] [MainThread]: Using redshift connection "master"
[0m23:08:35.325065 [debug] [MainThread]: On master: COMMIT
[0m23:08:35.373718 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:08:35.376096 [debug] [MainThread]: On master: Close
[0m23:08:35.379589 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:08:35.380682 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:08:35.381701 [info ] [MainThread]: 
[0m23:08:35.382669 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 12.50 seconds (12.50s).
[0m23:08:35.384361 [debug] [MainThread]: Command end result
[0m23:08:35.407433 [info ] [MainThread]: 
[0m23:08:35.408289 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:08:35.409127 [info ] [MainThread]: 
[0m23:08:35.409867 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:08:35.413840 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.408583, "process_user_time": 4.457366, "process_kernel_time": 0.397255, "process_mem_max_rss": "120528896", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:08:35.414940 [debug] [MainThread]: Command `dbt run` succeeded at 23:08:35.414702 after 13.41 seconds
[0m23:08:35.415590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc70d87d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc61ecea00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc61ece850>]}
[0m23:08:35.416238 [debug] [MainThread]: Flushing usage events
[0m23:09:22.120401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b00b50be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b019c1dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b019e9070>]}


============================== 23:09:22.127231 | 8a098503-6cbe-4596-90cc-f79f289d0a2a ==============================
[0m23:09:22.127231 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:09:22.128146 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select dim_outcome', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:09:22.688961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a098503-6cbe-4596-90cc-f79f289d0a2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b019bc310>]}
[0m23:09:22.809031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8a098503-6cbe-4596-90cc-f79f289d0a2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7af01eb3d0>]}
[0m23:09:22.811256 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:09:22.827785 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:09:22.898411 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:09:22.899020 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:09:22.908531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a098503-6cbe-4596-90cc-f79f289d0a2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b01d47fa0>]}
[0m23:09:22.923961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a098503-6cbe-4596-90cc-f79f289d0a2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ae2313a30>]}
[0m23:09:22.924649 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:09:22.925171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a098503-6cbe-4596-90cc-f79f289d0a2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ae23139a0>]}
[0m23:09:22.927062 [info ] [MainThread]: 
[0m23:09:22.928101 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:09:22.929546 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:09:22.954643 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:09:22.955258 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:09:22.955733 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:09:22.960292 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:09:22.961191 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:09:23.473555 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:09:23.480830 [debug] [ThreadPool]: On list_dev: Close
[0m23:09:23.487047 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:09:23.505376 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:09:23.506068 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:09:23.506646 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:09:23.507542 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:09:23.508164 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:09:23.835340 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:23.838111 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:09:23.839620 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:09:23.901386 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:23.908707 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:09:23.958612 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:09:23.990559 [debug] [MainThread]: Using redshift connection "master"
[0m23:09:23.991243 [debug] [MainThread]: On master: BEGIN
[0m23:09:23.991813 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:09:23.992699 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:09:23.993310 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:09:24.343581 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:24.344520 [debug] [MainThread]: Using redshift connection "master"
[0m23:09:24.345370 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:09:24.450335 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:24.455042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a098503-6cbe-4596-90cc-f79f289d0a2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ae21b9eb0>]}
[0m23:09:24.456458 [debug] [MainThread]: On master: ROLLBACK
[0m23:09:24.526541 [debug] [MainThread]: Using redshift connection "master"
[0m23:09:24.528477 [debug] [MainThread]: On master: BEGIN
[0m23:09:24.554215 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:24.556570 [debug] [MainThread]: On master: COMMIT
[0m23:09:24.558863 [debug] [MainThread]: Using redshift connection "master"
[0m23:09:24.560628 [debug] [MainThread]: On master: COMMIT
[0m23:09:24.606304 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:24.608878 [debug] [MainThread]: On master: Close
[0m23:09:24.612897 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:09:24.614287 [info ] [MainThread]: 
[0m23:09:24.620071 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:09:24.621413 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:09:24.623296 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:09:24.624343 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:09:24.633682 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:09:24.635912 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:09:24.624971 => 23:09:24.635285
[0m23:09:24.636740 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:09:24.741144 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:24.741887 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp230924687763"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,case when traded_ind then 1 else 0 end as traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from stg_outcome
  );
[0m23:09:24.742451 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:09:24.743204 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:09:24.743774 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:09:25.198458 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:25.241858 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:25.242708 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:09:25.292906 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:25.293844 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:25.295057 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp230924687763'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp230924687763'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp230924687763'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:09:25.451019 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:25.490141 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:25.491440 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:09:25.637970 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:25.683832 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:25.684939 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:09:25.804479 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:25.844230 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:09:25.850762 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:25.851481 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp230924687763"
            where (
                
                    "dim_outcome__dbt_tmp230924687763".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp230924687763".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp230924687763".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:09:26.001454 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:26.004513 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:26.006200 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp230924687763"
    )
[0m23:09:26.265530 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:26.308186 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:09:26.309231 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:09:26.309919 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:09:27.002718 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:09:27.008131 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:09:24.637191 => 23:09:27.007256
[0m23:09:27.009566 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:09:27.012552 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a098503-6cbe-4596-90cc-f79f289d0a2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b01ef6ca0>]}
[0m23:09:27.015156 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 2.39s]
[0m23:09:27.016850 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:09:27.020110 [debug] [MainThread]: Using redshift connection "master"
[0m23:09:27.020968 [debug] [MainThread]: On master: BEGIN
[0m23:09:27.021748 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:09:27.022861 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:09:27.023603 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:09:27.358704 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:27.361508 [debug] [MainThread]: On master: COMMIT
[0m23:09:27.363945 [debug] [MainThread]: Using redshift connection "master"
[0m23:09:27.365572 [debug] [MainThread]: On master: COMMIT
[0m23:09:27.418277 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:09:27.420730 [debug] [MainThread]: On master: Close
[0m23:09:27.423840 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:09:27.425247 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:09:27.426740 [info ] [MainThread]: 
[0m23:09:27.427778 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.50 seconds (4.50s).
[0m23:09:27.429671 [debug] [MainThread]: Command end result
[0m23:09:27.452398 [info ] [MainThread]: 
[0m23:09:27.453269 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:09:27.453908 [info ] [MainThread]: 
[0m23:09:27.454578 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:09:27.458500 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.4422197, "process_user_time": 4.45789, "process_kernel_time": 0.397308, "process_mem_max_rss": "126672896", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:09:27.459747 [debug] [MainThread]: Command `dbt run` succeeded at 23:09:27.459477 after 5.44 seconds
[0m23:09:27.460428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b00b50be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b01ed6c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b01ed6a00>]}
[0m23:09:27.461133 [debug] [MainThread]: Flushing usage events
[0m23:10:03.202450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd660f77d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd661b42e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd661b6ca90>]}


============================== 23:10:03.209278 | efd89f32-f349-43eb-8bd8-5281eafdf40e ==============================
[0m23:10:03.209278 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:10:03.210162 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_outcome', 'send_anonymous_usage_stats': 'True'}
[0m23:10:03.782704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'efd89f32-f349-43eb-8bd8-5281eafdf40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd661b6c4c0>]}
[0m23:10:03.906347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'efd89f32-f349-43eb-8bd8-5281eafdf40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd640a98190>]}
[0m23:10:03.908558 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:10:03.926633 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:10:03.998332 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:10:03.999273 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m23:10:04.197879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'efd89f32-f349-43eb-8bd8-5281eafdf40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd661ccfd30>]}
[0m23:10:04.213285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'efd89f32-f349-43eb-8bd8-5281eafdf40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6517eba00>]}
[0m23:10:04.214019 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:10:04.214607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'efd89f32-f349-43eb-8bd8-5281eafdf40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6517eb970>]}
[0m23:10:04.216956 [info ] [MainThread]: 
[0m23:10:04.218125 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:10:04.219665 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:10:04.246603 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:10:04.247434 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:10:04.247970 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:10:04.252620 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:10:04.253190 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:10:04.757742 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:10:04.766917 [debug] [ThreadPool]: On list_dev: Close
[0m23:10:04.774927 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:10:04.796434 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:10:04.797406 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:10:04.798075 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:10:04.799089 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:10:04.799792 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:10:05.127171 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:05.130215 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:10:05.132251 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:10:05.196270 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:05.201473 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:10:05.252707 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:10:05.297119 [debug] [MainThread]: Using redshift connection "master"
[0m23:10:05.298058 [debug] [MainThread]: On master: BEGIN
[0m23:10:05.298744 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:10:05.299756 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:10:05.300483 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:10:05.628386 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:05.630171 [debug] [MainThread]: Using redshift connection "master"
[0m23:10:05.631615 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:10:05.730520 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:05.734421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'efd89f32-f349-43eb-8bd8-5281eafdf40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd630346c10>]}
[0m23:10:05.735902 [debug] [MainThread]: On master: ROLLBACK
[0m23:10:05.803657 [debug] [MainThread]: Using redshift connection "master"
[0m23:10:05.805787 [debug] [MainThread]: On master: BEGIN
[0m23:10:05.829544 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:05.831215 [debug] [MainThread]: On master: COMMIT
[0m23:10:05.832309 [debug] [MainThread]: Using redshift connection "master"
[0m23:10:05.833130 [debug] [MainThread]: On master: COMMIT
[0m23:10:05.877820 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:05.879140 [debug] [MainThread]: On master: Close
[0m23:10:05.881715 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:10:05.882867 [info ] [MainThread]: 
[0m23:10:05.890093 [debug] [Thread-1  ]: Began running node model.tipico.dim_outcome
[0m23:10:05.892759 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_outcome .................... [RUN]
[0m23:10:05.896256 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_outcome)
[0m23:10:05.898381 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_outcome
[0m23:10:05.909689 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_outcome"
[0m23:10:05.911527 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (compile): 23:10:05.899518 => 23:10:05.911027
[0m23:10:05.912257 [debug] [Thread-1  ]: Began executing node model.tipico.dim_outcome
[0m23:10:06.007172 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:06.007911 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

    
  
    

  create temporary table
    "dim_outcome__dbt_tmp231005955369"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally



select distinct 
root_id
,market_id
,outcome_id
,"name"
,traded_ind
,true_odds
,format_decimal
,format_american
,status
,SYSDATE as tm_created
,SYSDATE as tm_updated
from stg_outcome
  );
[0m23:10:06.008503 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:10:06.009270 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:10:06.009804 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:10:06.733593 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:10:06.791333 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:06.792212 [debug] [Thread-1  ]: On model.tipico.dim_outcome: BEGIN
[0m23:10:06.836364 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:06.837414 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:06.838825 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome__dbt_tmp231005955369'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome__dbt_tmp231005955369'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_outcome__dbt_tmp231005955369'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:10:06.986806 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:07.022965 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:07.023967 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:10:07.170474 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:07.227390 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:07.228732 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_outcome'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_outcome'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_outcome'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:10:07.346245 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:07.395516 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_outcome"
[0m23:10:07.401278 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:07.402034 [debug] [Thread-1  ]: On model.tipico.dim_outcome: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_outcome"} */

      
        
            delete from "dev"."timothy_chan"."dim_outcome"
            using "dim_outcome__dbt_tmp231005955369"
            where (
                
                    "dim_outcome__dbt_tmp231005955369".root_id = "dev"."timothy_chan"."dim_outcome".root_id
                    and 
                
                    "dim_outcome__dbt_tmp231005955369".market_id = "dev"."timothy_chan"."dim_outcome".market_id
                    and 
                
                    "dim_outcome__dbt_tmp231005955369".outcome_id = "dev"."timothy_chan"."dim_outcome".outcome_id
                    
                
                
            );
[0m23:10:07.524126 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:07.525716 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:07.526928 [debug] [Thread-1  ]: On model.tipico.dim_outcome: insert into "dev"."timothy_chan"."dim_outcome" ("root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "outcome_id", "name", "traded_ind", "true_odds", "format_decimal", "format_american", "status", "tm_created", "tm_updated"
        from "dim_outcome__dbt_tmp231005955369"
    )
[0m23:10:10.523514 [debug] [Thread-1  ]: SQL status: SUCCESS in 3.0 seconds
[0m23:10:10.566048 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:10:10.566951 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_outcome"
[0m23:10:10.567502 [debug] [Thread-1  ]: On model.tipico.dim_outcome: COMMIT
[0m23:10:11.137185 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:10:11.140588 [debug] [Thread-1  ]: Timing info for model.tipico.dim_outcome (execute): 23:10:05.912624 => 23:10:11.139955
[0m23:10:11.141729 [debug] [Thread-1  ]: On model.tipico.dim_outcome: Close
[0m23:10:11.144383 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'efd89f32-f349-43eb-8bd8-5281eafdf40e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd651691820>]}
[0m23:10:11.146868 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_outcome ............... [[32mSUCCESS[0m in 5.25s]
[0m23:10:11.149074 [debug] [Thread-1  ]: Finished running node model.tipico.dim_outcome
[0m23:10:11.152681 [debug] [MainThread]: Using redshift connection "master"
[0m23:10:11.153765 [debug] [MainThread]: On master: BEGIN
[0m23:10:11.154766 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:10:11.156290 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:10:11.157531 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:10:11.473504 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:11.475193 [debug] [MainThread]: On master: COMMIT
[0m23:10:11.477055 [debug] [MainThread]: Using redshift connection "master"
[0m23:10:11.478261 [debug] [MainThread]: On master: COMMIT
[0m23:10:11.525130 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:10:11.526976 [debug] [MainThread]: On master: Close
[0m23:10:11.529372 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:10:11.530171 [debug] [MainThread]: Connection 'model.tipico.dim_outcome' was properly closed.
[0m23:10:11.531285 [info ] [MainThread]: 
[0m23:10:11.532514 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.31 seconds (7.31s).
[0m23:10:11.535105 [debug] [MainThread]: Command end result
[0m23:10:11.623380 [info ] [MainThread]: 
[0m23:10:11.624039 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:10:11.624513 [info ] [MainThread]: 
[0m23:10:11.625023 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:10:11.628072 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.537593, "process_user_time": 4.778576, "process_kernel_time": 0.41725, "process_mem_max_rss": "124796928", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:10:11.628930 [debug] [MainThread]: Command `dbt run` succeeded at 23:10:11.628732 after 8.54 seconds
[0m23:10:11.629491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd660f77d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd63044a880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd661c62460>]}
[0m23:10:11.630063 [debug] [MainThread]: Flushing usage events
[0m23:31:37.587782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7808fd3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829846fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829846c70>]}


============================== 23:31:37.594246 | eb301edc-2e2b-4bb9-aa58-ee3aa304a662 ==============================
[0m23:31:37.594246 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:31:37.595110 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/Users/tim/.dbt', 'log_path': '/Users/tim/tipico_git/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_market', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:31:38.106471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eb301edc-2e2b-4bb9-aa58-ee3aa304a662', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829836fd0>]}
[0m23:31:38.225656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eb301edc-2e2b-4bb9-aa58-ee3aa304a662', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78299f2580>]}
[0m23:31:38.227953 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:31:38.243761 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:31:38.315214 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:31:38.316156 [debug] [MainThread]: Partial parsing: updated file: tipico://models/dim_outcome.sql
[0m23:31:38.511138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb301edc-2e2b-4bb9-aa58-ee3aa304a662', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829e45f70>]}
[0m23:31:38.531159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb301edc-2e2b-4bb9-aa58-ee3aa304a662', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829caca60>]}
[0m23:31:38.531974 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:31:38.532527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb301edc-2e2b-4bb9-aa58-ee3aa304a662', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829cac9a0>]}
[0m23:31:38.534555 [info ] [MainThread]: 
[0m23:31:38.535794 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:31:38.537359 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:31:38.561827 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:31:38.562521 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:31:38.563037 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:31:38.567692 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:31:38.568521 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:31:39.112718 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:31:39.117326 [debug] [ThreadPool]: On list_dev: Close
[0m23:31:39.122138 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:31:39.137396 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:31:39.138061 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:31:39.138608 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:31:39.140824 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:31:39.141414 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:31:39.469972 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:39.470642 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:31:39.471186 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:31:39.542999 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:39.545545 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:31:39.596370 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:31:39.623004 [debug] [MainThread]: Using redshift connection "master"
[0m23:31:39.623680 [debug] [MainThread]: On master: BEGIN
[0m23:31:39.624171 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:31:39.624932 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:31:39.625460 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:31:40.090912 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:40.092654 [debug] [MainThread]: Using redshift connection "master"
[0m23:31:40.093729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:31:40.189999 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:40.193429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb301edc-2e2b-4bb9-aa58-ee3aa304a662', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829997df0>]}
[0m23:31:40.194657 [debug] [MainThread]: On master: ROLLBACK
[0m23:31:40.260120 [debug] [MainThread]: Using redshift connection "master"
[0m23:31:40.261169 [debug] [MainThread]: On master: BEGIN
[0m23:31:40.284293 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:40.285379 [debug] [MainThread]: On master: COMMIT
[0m23:31:40.286479 [debug] [MainThread]: Using redshift connection "master"
[0m23:31:40.287360 [debug] [MainThread]: On master: COMMIT
[0m23:31:40.339609 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:40.340511 [debug] [MainThread]: On master: Close
[0m23:31:40.342445 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:31:40.343272 [info ] [MainThread]: 
[0m23:31:40.347538 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m23:31:40.348530 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m23:31:40.349782 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m23:31:40.350451 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m23:31:40.356959 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m23:31:40.359367 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 23:31:40.350864 => 23:31:40.358932
[0m23:31:40.360000 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m23:31:40.463947 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:40.464855 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp233140407774"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable  then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m23:31:40.465453 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:31:40.466374 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:31:40.467086 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:31:40.977638 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:31:41.020541 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:41.021367 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m23:31:41.066973 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:41.067888 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:41.068872 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp233140407774'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp233140407774'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp233140407774'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:31:41.215692 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:41.237871 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:41.238753 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:31:41.391745 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:41.417226 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:41.418093 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:31:41.532093 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:41.559305 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m23:31:41.564455 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:41.565143 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp233140407774"
            where (
                
                    "dim_market__dbt_tmp233140407774".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp233140407774".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m23:31:41.683883 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:41.685142 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:41.686310 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp233140407774"
    )
[0m23:31:41.771037 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:41.798392 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m23:31:41.799401 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m23:31:41.800017 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m23:31:42.436499 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:31:42.438348 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 23:31:40.360364 => 23:31:42.437966
[0m23:31:42.438974 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m23:31:42.440577 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb301edc-2e2b-4bb9-aa58-ee3aa304a662', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829b5df40>]}
[0m23:31:42.442275 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.09s]
[0m23:31:42.443190 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m23:31:42.445519 [debug] [MainThread]: Using redshift connection "master"
[0m23:31:42.446098 [debug] [MainThread]: On master: BEGIN
[0m23:31:42.446586 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:31:42.447837 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:31:42.448388 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:31:42.762042 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:42.763055 [debug] [MainThread]: On master: COMMIT
[0m23:31:42.763904 [debug] [MainThread]: Using redshift connection "master"
[0m23:31:42.764498 [debug] [MainThread]: On master: COMMIT
[0m23:31:42.811893 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:31:42.813032 [debug] [MainThread]: On master: Close
[0m23:31:42.814990 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:31:42.815730 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m23:31:42.818864 [info ] [MainThread]: 
[0m23:31:42.819749 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.28 seconds (4.28s).
[0m23:31:42.825402 [debug] [MainThread]: Command end result
[0m23:31:42.941289 [info ] [MainThread]: 
[0m23:31:42.942170 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:31:42.942691 [info ] [MainThread]: 
[0m23:31:42.943273 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:31:42.948298 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.475291, "process_user_time": 4.651599, "process_kernel_time": 0.465331, "process_mem_max_rss": "121516032", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:31:42.949551 [debug] [MainThread]: Command `dbt run` succeeded at 23:31:42.949212 after 5.48 seconds
[0m23:31:42.950524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7808fd3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7829a9b520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f782944fdc0>]}
[0m23:31:42.951221 [debug] [MainThread]: Flushing usage events
[0m23:33:15.349709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e30db3700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e00343e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e003435b0>]}


============================== 23:33:15.356840 | a7288b1a-34fe-426e-a1ae-cd97d3ae753e ==============================
[0m23:33:15.356840 [info ] [MainThread]: Running with dbt=1.7.0
[0m23:33:15.357708 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_event', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:33:15.891629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a7288b1a-34fe-426e-a1ae-cd97d3ae753e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e00343640>]}
[0m23:33:16.010565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a7288b1a-34fe-426e-a1ae-cd97d3ae753e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e21851c70>]}
[0m23:33:16.012763 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m23:33:16.028909 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m23:33:16.100154 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:33:16.100761 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:33:16.110348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7288b1a-34fe-426e-a1ae-cd97d3ae753e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e219ea0d0>]}
[0m23:33:16.127640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7288b1a-34fe-426e-a1ae-cd97d3ae753e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e10e79a60>]}
[0m23:33:16.128401 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m23:33:16.128950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7288b1a-34fe-426e-a1ae-cd97d3ae753e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e10e79970>]}
[0m23:33:16.130893 [info ] [MainThread]: 
[0m23:33:16.132164 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m23:33:16.134538 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m23:33:16.160293 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m23:33:16.161021 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m23:33:16.161614 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:33:16.167783 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:33:16.168922 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:33:16.718620 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m23:33:16.721453 [debug] [ThreadPool]: On list_dev: Close
[0m23:33:16.725310 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m23:33:16.739747 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:33:16.740534 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m23:33:16.741032 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:33:16.742090 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:33:16.742616 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:33:17.066781 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:17.067521 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m23:33:17.068080 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m23:33:17.134570 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:17.137218 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m23:33:17.186100 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m23:33:17.202710 [debug] [MainThread]: Using redshift connection "master"
[0m23:33:17.203309 [debug] [MainThread]: On master: BEGIN
[0m23:33:17.203781 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:33:17.204478 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:33:17.204981 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:33:17.525071 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:17.527851 [debug] [MainThread]: Using redshift connection "master"
[0m23:33:17.529515 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m23:33:17.625621 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:17.632247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7288b1a-34fe-426e-a1ae-cd97d3ae753e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e2186af70>]}
[0m23:33:17.634995 [debug] [MainThread]: On master: ROLLBACK
[0m23:33:17.702383 [debug] [MainThread]: Using redshift connection "master"
[0m23:33:17.703711 [debug] [MainThread]: On master: BEGIN
[0m23:33:17.726725 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:17.728166 [debug] [MainThread]: On master: COMMIT
[0m23:33:17.729499 [debug] [MainThread]: Using redshift connection "master"
[0m23:33:17.739269 [debug] [MainThread]: On master: COMMIT
[0m23:33:17.789976 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:17.790906 [debug] [MainThread]: On master: Close
[0m23:33:17.792566 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:33:17.793238 [info ] [MainThread]: 
[0m23:33:17.797292 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m23:33:17.798268 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m23:33:17.799652 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m23:33:17.800572 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m23:33:17.806601 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m23:33:17.808526 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 23:33:17.800964 => 23:33:17.808106
[0m23:33:17.809141 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m23:33:17.912160 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:17.912916 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp233317858607"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m23:33:17.913510 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m23:33:17.914297 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:33:17.914870 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:33:18.295367 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:18.349863 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:18.350848 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m23:33:18.397317 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:18.398402 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:18.399817 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp233317858607'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp233317858607'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp233317858607'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m23:33:18.548745 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:18.596223 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:18.597474 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:33:18.745771 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:18.786452 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:18.787425 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m23:33:18.902360 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:18.927047 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m23:33:18.931371 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:18.931988 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp233317858607"
            where (
                
                    "dim_event__dbt_tmp233317858607".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m23:33:19.050759 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:19.051775 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:19.052558 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp233317858607"
    )
[0m23:33:19.132325 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:19.163649 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m23:33:19.164416 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m23:33:19.164971 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m23:33:19.797378 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m23:33:19.800969 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 23:33:17.809500 => 23:33:19.800144
[0m23:33:19.802317 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m23:33:19.804757 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7288b1a-34fe-426e-a1ae-cd97d3ae753e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e317a4670>]}
[0m23:33:19.807331 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.01s]
[0m23:33:19.808906 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m23:33:19.811782 [debug] [MainThread]: Using redshift connection "master"
[0m23:33:19.812630 [debug] [MainThread]: On master: BEGIN
[0m23:33:19.813388 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:33:19.814531 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m23:33:19.815310 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m23:33:20.139212 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:20.139927 [debug] [MainThread]: On master: COMMIT
[0m23:33:20.140553 [debug] [MainThread]: Using redshift connection "master"
[0m23:33:20.141044 [debug] [MainThread]: On master: COMMIT
[0m23:33:20.197198 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m23:33:20.197867 [debug] [MainThread]: On master: Close
[0m23:33:20.199103 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:33:20.199605 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m23:33:20.200203 [info ] [MainThread]: 
[0m23:33:20.200772 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.07 seconds (4.07s).
[0m23:33:20.201779 [debug] [MainThread]: Command end result
[0m23:33:20.216688 [info ] [MainThread]: 
[0m23:33:20.217384 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:33:20.217895 [info ] [MainThread]: 
[0m23:33:20.218458 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:33:20.221508 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.984804, "process_user_time": 4.401539, "process_kernel_time": 0.400741, "process_mem_max_rss": "114978816", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m23:33:20.222373 [debug] [MainThread]: Command `dbt run` succeeded at 23:33:20.222166 after 4.99 seconds
[0m23:33:20.222978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e30db3700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e2192e340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7e10e79370>]}
[0m23:33:20.223597 [debug] [MainThread]: Flushing usage events
[0m00:18:39.641480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8008c25d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8009be6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8009bddeb0>]}


============================== 00:18:39.648047 | 920b54a1-f033-4c5d-b7e1-4251512b312b ==============================
[0m00:18:39.648047 [info ] [MainThread]: Running with dbt=1.7.0
[0m00:18:39.648877 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'fail_fast': 'False', 'profiles_dir': '/Users/tim/.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select dim_market', 'send_anonymous_usage_stats': 'True'}
[0m00:18:40.103083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '920b54a1-f033-4c5d-b7e1-4251512b312b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8009bd2b20>]}
[0m00:18:40.225327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '920b54a1-f033-4c5d-b7e1-4251512b312b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8009c01f10>]}
[0m00:18:40.227736 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m00:18:40.243714 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m00:18:40.318118 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:18:40.318653 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:18:40.328757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '920b54a1-f033-4c5d-b7e1-4251512b312b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8009e88f40>]}
[0m00:18:40.345969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '920b54a1-f033-4c5d-b7e1-4251512b312b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8019e8e880>]}
[0m00:18:40.346682 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m00:18:40.347186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '920b54a1-f033-4c5d-b7e1-4251512b312b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8019e8e7c0>]}
[0m00:18:40.349111 [info ] [MainThread]: 
[0m00:18:40.350153 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:18:40.351608 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m00:18:40.376582 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m00:18:40.377111 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m00:18:40.377554 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:18:40.381952 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:18:40.382710 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:18:40.880488 [debug] [ThreadPool]: SQL status: SUCCESS in 1.0 seconds
[0m00:18:40.886680 [debug] [ThreadPool]: On list_dev: Close
[0m00:18:40.892775 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m00:18:40.920380 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m00:18:40.921428 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m00:18:40.922082 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:18:40.923139 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:18:40.923837 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:18:41.253584 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:41.255008 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m00:18:41.256061 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m00:18:41.327687 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:41.338293 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m00:18:41.397316 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m00:18:41.442004 [debug] [MainThread]: Using redshift connection "master"
[0m00:18:41.442996 [debug] [MainThread]: On master: BEGIN
[0m00:18:41.443649 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:18:41.444699 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:18:41.445367 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:18:41.760136 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:41.761573 [debug] [MainThread]: Using redshift connection "master"
[0m00:18:41.762796 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m00:18:41.872509 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:41.881607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '920b54a1-f033-4c5d-b7e1-4251512b312b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7fe8131f40>]}
[0m00:18:41.884345 [debug] [MainThread]: On master: ROLLBACK
[0m00:18:41.958938 [debug] [MainThread]: Using redshift connection "master"
[0m00:18:41.961670 [debug] [MainThread]: On master: BEGIN
[0m00:18:41.990813 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:41.992309 [debug] [MainThread]: On master: COMMIT
[0m00:18:41.993965 [debug] [MainThread]: Using redshift connection "master"
[0m00:18:41.995638 [debug] [MainThread]: On master: COMMIT
[0m00:18:42.046027 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:42.047836 [debug] [MainThread]: On master: Close
[0m00:18:42.051277 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:18:42.052720 [info ] [MainThread]: 
[0m00:18:42.059616 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m00:18:42.061272 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m00:18:42.063592 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m00:18:42.064545 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m00:18:42.077025 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m00:18:42.079386 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 00:18:42.065166 => 00:18:42.078884
[0m00:18:42.080012 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m00:18:42.182360 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:42.183103 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp001842128809"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable  then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m00:18:42.183672 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:18:42.184415 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:18:42.184946 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:18:42.578188 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:42.632825 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:42.633731 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m00:18:42.682850 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:42.683792 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:42.685139 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp001842128809'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp001842128809'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp001842128809'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m00:18:42.839513 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:42.889390 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:42.890632 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m00:18:43.043666 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:43.090915 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:43.092105 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m00:18:43.211718 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:43.248427 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m00:18:43.253409 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:43.253992 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp001842128809"
            where (
                
                    "dim_market__dbt_tmp001842128809".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp001842128809".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m00:18:43.374874 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:43.376912 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:43.378394 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp001842128809"
    )
[0m00:18:43.465514 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:43.514080 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m00:18:43.515243 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:18:43.515941 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m00:18:44.049939 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m00:18:44.053095 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 00:18:42.080372 => 00:18:44.052339
[0m00:18:44.054400 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m00:18:44.056990 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '920b54a1-f033-4c5d-b7e1-4251512b312b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8009ff5d60>]}
[0m00:18:44.059728 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 1.99s]
[0m00:18:44.061737 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m00:18:44.065202 [debug] [MainThread]: Using redshift connection "master"
[0m00:18:44.066070 [debug] [MainThread]: On master: BEGIN
[0m00:18:44.066845 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:18:44.068067 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:18:44.068934 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:18:44.398213 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:44.399466 [debug] [MainThread]: On master: COMMIT
[0m00:18:44.400563 [debug] [MainThread]: Using redshift connection "master"
[0m00:18:44.401353 [debug] [MainThread]: On master: COMMIT
[0m00:18:44.450808 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:18:44.452773 [debug] [MainThread]: On master: Close
[0m00:18:44.456557 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:18:44.457825 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m00:18:44.459718 [info ] [MainThread]: 
[0m00:18:44.461673 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.11 seconds (4.11s).
[0m00:18:44.465376 [debug] [MainThread]: Command end result
[0m00:18:44.496745 [info ] [MainThread]: 
[0m00:18:44.497791 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:18:44.498476 [info ] [MainThread]: 
[0m00:18:44.499220 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:18:44.503949 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.976749, "process_user_time": 4.528684, "process_kernel_time": 0.412218, "process_mem_max_rss": "130326528", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:18:44.505098 [debug] [MainThread]: Command `dbt run` succeeded at 00:18:44.504859 after 4.98 seconds
[0m00:18:44.505798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8008c25d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8019e8e7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8019ffd9a0>]}
[0m00:18:44.506481 [debug] [MainThread]: Flushing usage events
[0m00:21:08.871487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf92ddd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febb8066c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febb805ceb0>]}


============================== 00:21:08.881561 | bdc210a9-16a6-4b4e-a99c-1091d4f632c8 ==============================
[0m00:21:08.881561 [info ] [MainThread]: Running with dbt=1.7.0
[0m00:21:08.882696 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/tim/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/Users/tim/tipico_git/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select dim_market', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:21:09.365123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bdc210a9-16a6-4b4e-a99c-1091d4f632c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febe859ab20>]}
[0m00:21:09.486765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bdc210a9-16a6-4b4e-a99c-1091d4f632c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febb8082f10>]}
[0m00:21:09.488907 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m00:21:09.505145 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m00:21:09.574632 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:21:09.575217 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:21:09.584786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bdc210a9-16a6-4b4e-a99c-1091d4f632c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febd98f8f40>]}
[0m00:21:09.599913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bdc210a9-16a6-4b4e-a99c-1091d4f632c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febe878e880>]}
[0m00:21:09.600618 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m00:21:09.601122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdc210a9-16a6-4b4e-a99c-1091d4f632c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febe878e7c0>]}
[0m00:21:09.603065 [info ] [MainThread]: 
[0m00:21:09.604134 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:21:09.605575 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m00:21:09.630189 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m00:21:09.630746 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m00:21:09.631231 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:21:09.635694 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:09.636191 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:10.124923 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:10.130146 [debug] [ThreadPool]: On list_dev: Close
[0m00:21:10.135138 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m00:21:10.152282 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m00:21:10.152948 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m00:21:10.153489 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:21:10.154391 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:10.155004 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:10.499508 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:10.500599 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m00:21:10.505762 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m00:21:10.581981 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:10.585829 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m00:21:10.645365 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m00:21:10.667547 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:10.668357 [debug] [MainThread]: On master: BEGIN
[0m00:21:10.668938 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:21:10.669944 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:10.670589 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:11.016395 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:11.018552 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:11.019568 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m00:21:11.119585 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:11.123756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bdc210a9-16a6-4b4e-a99c-1091d4f632c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febe8649be0>]}
[0m00:21:11.126133 [debug] [MainThread]: On master: ROLLBACK
[0m00:21:11.202331 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:11.204379 [debug] [MainThread]: On master: BEGIN
[0m00:21:11.235458 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:11.237788 [debug] [MainThread]: On master: COMMIT
[0m00:21:11.239634 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:11.240715 [debug] [MainThread]: On master: COMMIT
[0m00:21:11.297533 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:11.298533 [debug] [MainThread]: On master: Close
[0m00:21:11.300265 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:21:11.300992 [info ] [MainThread]: 
[0m00:21:11.305343 [debug] [Thread-1  ]: Began running node model.tipico.dim_market
[0m00:21:11.306515 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_market ..................... [RUN]
[0m00:21:11.307951 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_market)
[0m00:21:11.308638 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_market
[0m00:21:11.316452 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_market"
[0m00:21:11.317657 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (compile): 00:21:11.309067 => 00:21:11.317260
[0m00:21:11.318250 [debug] [Thread-1  ]: Began executing node model.tipico.dim_market
[0m00:21:11.418389 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:11.419088 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

    
  
    

  create temporary table
    "dim_market__dbt_tmp002111364458"
    
    
    
  as (
    -- Create dim_market model, insert/update data incrementally


select distinct 
root_id
,market_id
,"name"
,"type"
,parameters
,status
,case when most_balanced_line then 1 else 0 end as  most_balanced_line
,case when is_sgp_eligable  then 1 else 0 end as is_sgp_eligable
,SYSDATE tm_created
,SYSDATE tm_updated
from "dev"."timothy_chan"."stg_market"
  );
[0m00:21:11.419636 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:21:11.420371 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:11.420896 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:11.813330 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:11.867209 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:11.868088 [debug] [Thread-1  ]: On model.tipico.dim_market: BEGIN
[0m00:21:11.921078 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:11.922208 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:11.923533 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market__dbt_tmp002111364458'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market__dbt_tmp002111364458'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_market__dbt_tmp002111364458'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m00:21:12.081598 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:12.128516 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:12.129862 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m00:21:12.280824 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:12.327948 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:12.328965 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_market'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_market'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_market'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m00:21:12.449131 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:12.497511 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_market"
[0m00:21:12.503351 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:12.504085 [debug] [Thread-1  ]: On model.tipico.dim_market: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_market"} */

      
        
            delete from "dev"."timothy_chan"."dim_market"
            using "dim_market__dbt_tmp002111364458"
            where (
                
                    "dim_market__dbt_tmp002111364458".root_id = "dev"."timothy_chan"."dim_market".root_id
                    and 
                
                    "dim_market__dbt_tmp002111364458".market_id = "dev"."timothy_chan"."dim_market".market_id
                    
                
                
            );
[0m00:21:12.629767 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:12.631327 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:12.632379 [debug] [Thread-1  ]: On model.tipico.dim_market: insert into "dev"."timothy_chan"."dim_market" ("root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated")
    (
        select "root_id", "market_id", "name", "type", "parameters", "status", "most_balanced_line", "is_sgp_eligable", "tm_created", "tm_updated"
        from "dim_market__dbt_tmp002111364458"
    )
[0m00:21:12.710899 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:12.762376 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m00:21:12.763584 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_market"
[0m00:21:12.764272 [debug] [Thread-1  ]: On model.tipico.dim_market: COMMIT
[0m00:21:13.382536 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m00:21:13.387281 [debug] [Thread-1  ]: Timing info for model.tipico.dim_market (execute): 00:21:11.318599 => 00:21:13.386217
[0m00:21:13.388685 [debug] [Thread-1  ]: On model.tipico.dim_market: Close
[0m00:21:13.390822 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bdc210a9-16a6-4b4e-a99c-1091d4f632c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febd9996f70>]}
[0m00:21:13.392894 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_market ................ [[32mSUCCESS[0m in 2.08s]
[0m00:21:13.394216 [debug] [Thread-1  ]: Finished running node model.tipico.dim_market
[0m00:21:13.396969 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:13.397717 [debug] [MainThread]: On master: BEGIN
[0m00:21:13.398371 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:21:13.399391 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:13.400079 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:13.737280 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:13.738776 [debug] [MainThread]: On master: COMMIT
[0m00:21:13.740279 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:13.741120 [debug] [MainThread]: On master: COMMIT
[0m00:21:13.790871 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:13.792141 [debug] [MainThread]: On master: Close
[0m00:21:13.794351 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:21:13.795219 [debug] [MainThread]: Connection 'model.tipico.dim_market' was properly closed.
[0m00:21:13.796213 [info ] [MainThread]: 
[0m00:21:13.797112 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.19 seconds (4.19s).
[0m00:21:13.799229 [debug] [MainThread]: Command end result
[0m00:21:13.822825 [info ] [MainThread]: 
[0m00:21:13.823604 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:21:13.824125 [info ] [MainThread]: 
[0m00:21:13.824711 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:21:13.828353 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.237814, "process_user_time": 4.63584, "process_kernel_time": 0.40611, "process_mem_max_rss": "124358656", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:21:13.829314 [debug] [MainThread]: Command `dbt run` succeeded at 00:21:13.829102 after 5.24 seconds
[0m00:21:13.829884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf92ddd00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febe878e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7febf9d2ed90>]}
[0m00:21:13.830456 [debug] [MainThread]: Flushing usage events
[0m00:21:20.250217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd048fad670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd049a042e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd049a1c370>]}


============================== 00:21:20.256244 | 64df9a9b-c09d-4288-8272-2acbe4a28b04 ==============================
[0m00:21:20.256244 [info ] [MainThread]: Running with dbt=1.7.0
[0m00:21:20.257064 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/Users/tim/tipico_git/logs', 'profiles_dir': '/Users/tim/.dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select dim_event', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m00:21:20.662624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64df9a9b-c09d-4288-8272-2acbe4a28b04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069c20fa0>]}
[0m00:21:20.782210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '64df9a9b-c09d-4288-8272-2acbe4a28b04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd049a4b0a0>]}
[0m00:21:20.783768 [info ] [MainThread]: Registered adapter: redshift=1.7.7
[0m00:21:20.799271 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m00:21:20.868379 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:21:20.868962 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:21:20.878488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '64df9a9b-c09d-4288-8272-2acbe4a28b04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069e80ee0>]}
[0m00:21:20.893071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64df9a9b-c09d-4288-8272-2acbe4a28b04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069d95820>]}
[0m00:21:20.893753 [info ] [MainThread]: Found 7 models, 11 sources, 0 exposures, 0 metrics, 467 macros, 0 groups, 0 semantic models
[0m00:21:20.894270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64df9a9b-c09d-4288-8272-2acbe4a28b04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069d95760>]}
[0m00:21:20.896112 [info ] [MainThread]: 
[0m00:21:20.897161 [debug] [MainThread]: Acquiring new redshift connection 'master'
[0m00:21:20.898658 [debug] [ThreadPool]: Acquiring new redshift connection 'list_dev'
[0m00:21:20.922978 [debug] [ThreadPool]: Using redshift connection "list_dev"
[0m00:21:20.923515 [debug] [ThreadPool]: On list_dev: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev"} */

    select distinct nspname from pg_namespace
[0m00:21:20.923978 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:21:20.928494 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:20.928994 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:21.412915 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:21.421188 [debug] [ThreadPool]: On list_dev: Close
[0m00:21:21.428430 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_dev, now list_dev_timothy_chan)
[0m00:21:21.453511 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m00:21:21.454609 [debug] [ThreadPool]: On list_dev_timothy_chan: BEGIN
[0m00:21:21.455748 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:21:21.457384 [debug] [ThreadPool]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:21.458186 [debug] [ThreadPool]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:21.779730 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:21.781544 [debug] [ThreadPool]: Using redshift connection "list_dev_timothy_chan"
[0m00:21:21.782813 [debug] [ThreadPool]: On list_dev_timothy_chan: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "list_dev_timothy_chan"} */
select
        table_catalog as database,
        table_name as name,
        table_schema as schema,
        'table' as type
    from information_schema.tables
    where table_schema ilike 'timothy_chan'
    and table_type = 'BASE TABLE'
    union all
    select
      table_catalog as database,
      table_name as name,
      table_schema as schema,
      case
        when view_definition ilike '%create materialized view%'
          then 'materialized_view'
        else 'view'
      end as type
    from information_schema.views
    where table_schema ilike 'timothy_chan'
[0m00:21:21.851954 [debug] [ThreadPool]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:21.858977 [debug] [ThreadPool]: On list_dev_timothy_chan: ROLLBACK
[0m00:21:21.918862 [debug] [ThreadPool]: On list_dev_timothy_chan: Close
[0m00:21:21.958057 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:21.958968 [debug] [MainThread]: On master: BEGIN
[0m00:21:21.959659 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:21:21.960681 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:21.961374 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:22.297719 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:22.300177 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:22.302258 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "connection_name": "master"} */
with
    relation as (
        select
            pg_class.oid as relation_id,
            pg_class.relname as relation_name,
            pg_class.relnamespace as schema_id,
            pg_namespace.nspname as schema_name,
            pg_class.relkind as relation_type
        from pg_class
        join pg_namespace
          on pg_class.relnamespace = pg_namespace.oid
        where pg_namespace.nspname != 'information_schema'
          and pg_namespace.nspname not like 'pg\_%'
    ),
    dependency as (
        select distinct
            coalesce(pg_rewrite.ev_class, pg_depend.objid) as dep_relation_id,
            pg_depend.refobjid as ref_relation_id,
            pg_depend.refclassid as ref_class_id
        from pg_depend
        left join pg_rewrite
          on pg_depend.objid = pg_rewrite.oid
        where coalesce(pg_rewrite.ev_class, pg_depend.objid) != pg_depend.refobjid
    )

select distinct
    dep.schema_name as dependent_schema,
    dep.relation_name as dependent_name,
    ref.schema_name as referenced_schema,
    ref.relation_name as referenced_name
from dependency
join relation ref
    on dependency.ref_relation_id = ref.relation_id
join relation dep
    on dependency.dep_relation_id = dep.relation_id
[0m00:21:22.399425 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:22.404957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64df9a9b-c09d-4288-8272-2acbe4a28b04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069c77850>]}
[0m00:21:22.407108 [debug] [MainThread]: On master: ROLLBACK
[0m00:21:22.484651 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:22.487028 [debug] [MainThread]: On master: BEGIN
[0m00:21:22.512851 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:22.513695 [debug] [MainThread]: On master: COMMIT
[0m00:21:22.514424 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:22.514989 [debug] [MainThread]: On master: COMMIT
[0m00:21:22.566346 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:22.568153 [debug] [MainThread]: On master: Close
[0m00:21:22.570780 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:21:22.571707 [info ] [MainThread]: 
[0m00:21:22.577112 [debug] [Thread-1  ]: Began running node model.tipico.dim_event
[0m00:21:22.578544 [info ] [Thread-1  ]: 1 of 1 START sql incremental model timothy_chan.dim_event ...................... [RUN]
[0m00:21:22.580418 [debug] [Thread-1  ]: Re-using an available connection from the pool (formerly list_dev_timothy_chan, now model.tipico.dim_event)
[0m00:21:22.581392 [debug] [Thread-1  ]: Began compiling node model.tipico.dim_event
[0m00:21:22.590244 [debug] [Thread-1  ]: Writing injected SQL for node "model.tipico.dim_event"
[0m00:21:22.592330 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (compile): 00:21:22.581906 => 00:21:22.591750
[0m00:21:22.593130 [debug] [Thread-1  ]: Began executing node model.tipico.dim_event
[0m00:21:22.693206 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:22.693888 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

    
  
    

  create temporary table
    "dim_event__dbt_tmp002122641128"
    
    
    
  as (
    -- Create dim_event model, insert/update data incrementally


SELECT distinct 
root_id,
start_time,
message_time,
match_state,
sport_type,
status,
market_count,
"name",
"type",
last_modified_time,
SYSDATE as tm_created,
SYSDATE as tm_updated
from "dev"."timothy_chan"."stg_event"
  );
[0m00:21:22.694427 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m00:21:22.695160 [debug] [Thread-1  ]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:22.695689 [debug] [Thread-1  ]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:23.067933 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:23.127401 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:23.128273 [debug] [Thread-1  ]: On model.tipico.dim_event: BEGIN
[0m00:21:23.184126 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:23.185087 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:23.186385 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event__dbt_tmp002122641128'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event__dbt_tmp002122641128'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'None'
        and tablename = 'dim_event__dbt_tmp002122641128'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    order by ordinal_position
[0m00:21:23.338526 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:23.385838 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:23.387228 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m00:21:23.535686 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:23.569763 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:23.570623 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      with bound_views as (
        select
          ordinal_position,
          table_schema,
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

        from information_schema."columns"
        where table_name = 'dim_event'
    ),

    unbound_views as (
      select
        ordinal_position,
        view_schema,
        col_name,
        case
          when col_type ilike 'character varying%' then
            'character varying'
          when col_type ilike 'numeric%' then 'numeric'
          else col_type
        end as col_type,
        case
          when col_type like 'character%'
          then nullif(REGEXP_SUBSTR(col_type, '[0-9]+'), '')::int
          else null
        end as character_maximum_length,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when col_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(col_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale

      from pg_get_late_binding_view_cols()
      cols(view_schema name, view_name name, col_name name,
           col_type varchar, ordinal_position int)
      where view_name = 'dim_event'
    ),

    external_views as (
      select
        columnnum,
        schemaname,
        columnname,
        case
          when external_type ilike 'character varying%' or external_type ilike 'varchar%'
          then 'character varying'
          when external_type ilike 'numeric%' then 'numeric'
          else external_type
        end as external_type,
        case
          when external_type like 'character%' or external_type like 'varchar%'
          then nullif(
            REGEXP_SUBSTR(external_type, '[0-9]+'),
            '')::int
          else null
        end as character_maximum_length,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 1),
            '')::int
          else null
        end as numeric_precision,
        case
          when external_type like 'numeric%'
          then nullif(
            SPLIT_PART(REGEXP_SUBSTR(external_type, '[0-9,]+'), ',', 2),
            '')::int
          else null
        end as numeric_scale
      from
        pg_catalog.svv_external_columns
      where
        schemaname = 'timothy_chan'
        and tablename = 'dim_event'

    ),

    unioned as (
      select * from bound_views
      union all
      select * from unbound_views
      union all
      select * from external_views
    )

    select
      column_name,
      data_type,
      character_maximum_length,
      numeric_precision,
      numeric_scale

    from unioned
    
    where table_schema = 'timothy_chan'
    
    order by ordinal_position
[0m00:21:23.687642 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:23.729948 [debug] [Thread-1  ]: Writing runtime sql for node "model.tipico.dim_event"
[0m00:21:23.735881 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:23.736459 [debug] [Thread-1  ]: On model.tipico.dim_event: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "tipico", "target_name": "dev", "node_id": "model.tipico.dim_event"} */

      
        
            delete from "dev"."timothy_chan"."dim_event"
            using "dim_event__dbt_tmp002122641128"
            where (
                
                    "dim_event__dbt_tmp002122641128".root_id = "dev"."timothy_chan"."dim_event".root_id
                    
                
                
            );
[0m00:21:23.861617 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:23.863701 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:23.865329 [debug] [Thread-1  ]: On model.tipico.dim_event: insert into "dev"."timothy_chan"."dim_event" ("root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated")
    (
        select "root_id", "start_time", "message_time", "match_state", "sport_type", "status", "market_count", "name", "type", "last_modified_time", "tm_created", "tm_updated"
        from "dim_event__dbt_tmp002122641128"
    )
[0m00:21:23.959696 [debug] [Thread-1  ]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:24.007076 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m00:21:24.008106 [debug] [Thread-1  ]: Using redshift connection "model.tipico.dim_event"
[0m00:21:24.008765 [debug] [Thread-1  ]: On model.tipico.dim_event: COMMIT
[0m00:21:24.750675 [debug] [Thread-1  ]: SQL status: SUCCESS in 1.0 seconds
[0m00:21:24.758128 [debug] [Thread-1  ]: Timing info for model.tipico.dim_event (execute): 00:21:22.593545 => 00:21:24.756669
[0m00:21:24.760521 [debug] [Thread-1  ]: On model.tipico.dim_event: Close
[0m00:21:24.764825 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64df9a9b-c09d-4288-8272-2acbe4a28b04', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069e8ddf0>]}
[0m00:21:24.768473 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model timothy_chan.dim_event ................. [[32mSUCCESS[0m in 2.18s]
[0m00:21:24.770864 [debug] [Thread-1  ]: Finished running node model.tipico.dim_event
[0m00:21:24.776003 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:24.777374 [debug] [MainThread]: On master: BEGIN
[0m00:21:24.778390 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:21:24.779687 [debug] [MainThread]: Redshift adapter: Establishing connection using ssl with `sslmode` set to 'prefer'.To connect without ssl, set `sslmode` to 'disable'.
[0m00:21:24.780541 [debug] [MainThread]: Redshift adapter: Connecting to redshift with username/password based auth...
[0m00:21:25.115718 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:25.117272 [debug] [MainThread]: On master: COMMIT
[0m00:21:25.119323 [debug] [MainThread]: Using redshift connection "master"
[0m00:21:25.121680 [debug] [MainThread]: On master: COMMIT
[0m00:21:25.181131 [debug] [MainThread]: SQL status: SUCCESS in 0.0 seconds
[0m00:21:25.183874 [debug] [MainThread]: On master: Close
[0m00:21:25.188711 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:21:25.190093 [debug] [MainThread]: Connection 'model.tipico.dim_event' was properly closed.
[0m00:21:25.191230 [info ] [MainThread]: 
[0m00:21:25.192251 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 4.29 seconds (4.29s).
[0m00:21:25.194164 [debug] [MainThread]: Command end result
[0m00:21:25.221947 [info ] [MainThread]: 
[0m00:21:25.222921 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:21:25.223632 [info ] [MainThread]: 
[0m00:21:25.224392 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m00:21:25.228148 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.084592, "process_user_time": 4.50008, "process_kernel_time": 0.382466, "process_mem_max_rss": "130281472", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m00:21:25.229230 [debug] [MainThread]: Command `dbt run` succeeded at 00:21:25.228987 after 5.09 seconds
[0m00:21:25.229945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd048fad670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069c60f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd069f006d0>]}
[0m00:21:25.230647 [debug] [MainThread]: Flushing usage events
